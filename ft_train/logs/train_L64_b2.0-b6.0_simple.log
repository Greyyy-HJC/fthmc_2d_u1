 
>>> PBS_NODEFILE content:
sophia-gpu-14.lab.alcf.anl.gov
1n*1t
Tue Jul 22 02:33:26 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.127.05             Driver Version: 550.127.05     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:07:00.0 Off |                    0 |
| N/A   22C    P0             54W /  400W |       1MiB /  40960MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA A100-SXM4-40GB          Off |   00000000:0F:00.0 Off |                    0 |
| N/A   22C    P0             52W /  400W |       1MiB /  40960MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2024 NVIDIA Corporation
Built on Thu_Mar_28_02:18:24_PDT_2024
Cuda compilation tools, release 12.4, V12.4.131
Build cuda_12.4.r12.4/compiler.34097967_0
Start time: 2025-07-22 02:33:26
Python 3.9.18
Python path: /lus/eagle/projects/fthmc/software/ml/bin/python
PYTHONPATH: /eagle/fthmc/run
You are using a CUDA device ('NVIDIA A100-SXM4-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 2 processes
----------------------------------------------------------------------------------------------------

============================================================
>>> CUDA device count: 2
PyTorch version: 2.5.0+cu124
CUDA available: True
>>> Arguments:
Lattice size: 64x64
Minimum beta: 2.0
Maximum beta: 2.0
Beta gap: 0.5
Number of epochs: 32
Batch size: 128
Number of subsets: 8
Number of workers: 0
Model tag: simple
Save tag: simple
Random seed: 2008
Identity initialization: True
Check Jacobian: False
Continue training: False
============================================================
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2
Trying to use torch.compile for optimized computation...
Successfully initialized torch.compile
>>> Training from scratch
Loaded data shape: torch.Size([4096, 2, 64, 64])
Training data shape: torch.Size([3276, 2, 64, 64])
Testing data shape: torch.Size([820, 2, 64, 64])

>>> Training the model at beta =  2.0

>>> Training the model at beta = 2.0

Training epochs:   0%|          | 0/32 [00:00<?, ?it/s]Training epochs:   0%|          | 0/32 [00:00<?, ?it/s]

Epoch 1/32:   0%|          | 0/13 [00:00<?, ?it/s][AEpoch 1/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 1/32:   8%|â–Š         | 1/13 [00:11<02:18, 11.54s/it][A
Epoch 1/32:   8%|â–Š         | 1/13 [00:11<02:18, 11.54s/it][A
Epoch 1/32:  15%|â–ˆâ–Œ        | 2/13 [00:12<00:58,  5.30s/it][A
Epoch 1/32:  15%|â–ˆâ–Œ        | 2/13 [00:12<00:58,  5.30s/it][A
Epoch 1/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:13<00:33,  3.31s/it][A
Epoch 1/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:13<00:33,  3.31s/it][A
Epoch 1/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:14<00:21,  2.44s/it][A
Epoch 1/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:14<00:21,  2.44s/it][A
Epoch 1/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:15<00:15,  1.92s/it][A
Epoch 1/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:15<00:15,  1.92s/it][A
Epoch 1/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:16<00:11,  1.61s/it][A
Epoch 1/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:16<00:11,  1.61s/it][A
Epoch 1/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:17<00:08,  1.42s/it][A
Epoch 1/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:17<00:08,  1.42s/it][A

Epoch 1/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:18<00:06,  1.29s/it][AEpoch 1/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:18<00:06,  1.29s/it][A
Epoch 1/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:19<00:04,  1.20s/it][A
Epoch 1/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:19<00:04,  1.21s/it][A
Epoch 1/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:20<00:03,  1.16s/it][A
Epoch 1/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:20<00:03,  1.16s/it][A
Epoch 1/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:21<00:02,  1.14s/it][A
Epoch 1/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:21<00:02,  1.14s/it][A
Epoch 1/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:22<00:01,  1.12s/it][A
Epoch 1/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:22<00:01,  1.12s/it][A
Epoch 1/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:23<00:00,  1.02s/it][AEpoch 1/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:23<00:00,  1.81s/it]

Epoch 1/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:23<00:00,  1.02s/it][AEpoch 1/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:23<00:00,  1.81s/it]

[Î²=2.0] Epoch 1 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=1.026e-01
  layer model_7__forward_module.module.conv2 act-std: mean=1.969e-02
  layer model_6__forward_module.module.conv1 act-std: mean=8.297e-02
  layer model_6__forward_module.module.conv2 act-std: mean=1.422e-02
  layer model_5__forward_module.module.conv1 act-std: mean=9.230e-02
  layer model_5__forward_module.module.conv2 act-std: mean=1.935e-02
  layer model_4__forward_module.module.conv1 act-std: mean=8.546e-02
  layer model_4__forward_module.module.conv2 act-std: mean=1.692e-02
  layer model_3__forward_module.module.conv1 act-std: mean=8.511e-02
  layer model_3__forward_module.module.conv2 act-std: mean=2.140e-02
  layer model_2__forward_module.module.conv1 act-std: mean=1.149e-01
  layer model_2__forward_module.module.conv2 act-std: mean=2.498e-02
  layer model_1__forward_module.module.conv1 act-std: mean=1.210e-01
  layer model_1__forward_module.module.conv2 act-std: mean=2.740e-02
  layer model_0__forward_module.module.conv1 act-std: mean=1.065e-01
  layer model_0__forward_module.module.conv2 act-std: mean=2.112e-02
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.214e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=2.755e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=9.334e-01

  param model_0__forward_module.module.conv2.bias grad-norm: mean=1.688e+00
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.496e+00Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  param model_1__forward_module.module.conv1.bias grad-norm: mean=3.391e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.109e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=1.713e+00
  param model_2__forward_module.module.conv1.weight grad-norm: mean=1.365e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=3.088e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.029e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.701e+00
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.342e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=3.030e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=9.693e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.686e+00
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.107e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=2.497e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=8.096e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.695e+00
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.065e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=2.398e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=8.538e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.683e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=9.683e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=2.176e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=7.225e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.682e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.162e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.615e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=8.929e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.684e+00

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  2.71it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  2.70it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  2.72it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  2.72it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  2.73it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  2.73it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.85it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.80it/s]
Epoch 1/32 - Train Loss: 44.566641 - Test Loss: 37.136654

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.83it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.79it/s]
Training epochs:   3%|â–Ž         | 1/32 [00:25<12:56, 25.04s/it]
Epoch 2/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:   3%|â–Ž         | 1/32 [00:25<12:56, 25.04s/it]
Epoch 2/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 2/32:   8%|â–Š         | 1/13 [00:01<00:15,  1.29s/it][A
Epoch 2/32:   8%|â–Š         | 1/13 [00:01<00:15,  1.29s/it][A
Epoch 2/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:13,  1.20s/it][A
Epoch 2/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:13,  1.20s/it][A
Epoch 2/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:03<00:11,  1.18s/it][A
Epoch 2/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:03<00:11,  1.18s/it][A

Epoch 2/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:04<00:10,  1.19s/it][AEpoch 2/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:04<00:10,  1.19s/it][A
Epoch 2/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:06<00:09,  1.20s/it][A
Epoch 2/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:06<00:09,  1.20s/it][A
Epoch 2/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:07<00:08,  1.23s/it][A
Epoch 2/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:07<00:08,  1.23s/it][A

Epoch 2/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:08<00:07,  1.24s/it][AEpoch 2/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:08<00:07,  1.24s/it][A
Epoch 2/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:09<00:06,  1.27s/it][A
Epoch 2/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:09<00:06,  1.27s/it][A
Epoch 2/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:11<00:05,  1.29s/it][A
Epoch 2/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:11<00:05,  1.30s/it][A
Epoch 2/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:12<00:03,  1.32s/it][A
Epoch 2/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:12<00:03,  1.32s/it][A
Epoch 2/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:13<00:02,  1.34s/it][A
Epoch 2/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:13<00:02,  1.34s/it][A

Epoch 2/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:15<00:01,  1.36s/it]Epoch 2/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:15<00:01,  1.36s/it][A[A

Epoch 2/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:16<00:00,  1.28s/it][AEpoch 2/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:16<00:00,  1.28s/it][AEpoch 2/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:16<00:00,  1.27s/it]
Epoch 2/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:16<00:00,  1.27s/it]

[Î²=2.0] Epoch 2 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=3.705e-01
  layer model_7__forward_module.module.conv2 act-std: mean=1.670e-01
  layer model_6__forward_module.module.conv1 act-std: mean=3.311e-01
  layer model_6__forward_module.module.conv2 act-std: mean=1.421e-01
  layer model_5__forward_module.module.conv1 act-std: mean=3.027e-01
  layer model_5__forward_module.module.conv2 act-std: mean=1.474e-01
  layer model_4__forward_module.module.conv1 act-std: mean=3.466e-01
  layer model_4__forward_module.module.conv2 act-std: mean=1.680e-01
  layer model_3__forward_module.module.conv1 act-std: mean=3.050e-01
  layer model_3__forward_module.module.conv2 act-std: mean=1.920e-01
  layer model_2__forward_module.module.conv1 act-std: mean=3.733e-01
  layer model_2__forward_module.module.conv2 act-std: mean=1.875e-01
  layer model_1__forward_module.module.conv1 act-std: mean=3.826e-01
  layer model_1__forward_module.module.conv2 act-std: mean=1.955e-01
  layer model_0__forward_module.module.conv1 act-std: mean=3.539e-01
  layer model_0__forward_module.module.conv2 act-std: mean=1.657e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.530e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=3.489e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.000e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=1.104e+00
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.898e+00
  param model_1__forward_module.module.conv1.bias grad-norm: mean=4.266e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.387e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=1.164e+00
  param model_2__forward_module.module.conv1.weight grad-norm: mean=1.890e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=4.120e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.923e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=9.621e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=2.281e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=4.927e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.214e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.011e+00
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.053e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=4.550e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.099e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.123e+00
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.409e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=3.149e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=1.611e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.022e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.743e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=3.814e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.814e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.080e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.930e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=4.151e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.893e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.024e+00

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.97it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.93it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.97it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.94it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.97it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.95it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.12it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.06it/s]
Training epochs:   6%|â–‹         | 2/32 [00:43<10:35, 21.17s/it]
Epoch 3/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.08it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.02it/s]
Epoch 2/32 - Train Loss: 38.088607 - Test Loss: 32.926444
Training epochs:   6%|â–‹         | 2/32 [00:43<10:35, 21.19s/it]
Epoch 3/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 3/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.46s/it][A
Epoch 3/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.43s/it][A
Epoch 3/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:15,  1.44s/it][A
Epoch 3/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:15,  1.42s/it][A
Epoch 3/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.42s/it][A
Epoch 3/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.41s/it][A

Epoch 3/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:12,  1.41s/it][AEpoch 3/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:12,  1.40s/it][A
Epoch 3/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.40s/it][A
Epoch 3/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.40s/it][A

Epoch 3/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:09,  1.39s/it][AEpoch 3/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:09,  1.39s/it][A
Epoch 3/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:09<00:08,  1.38s/it][A
Epoch 3/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:09<00:08,  1.38s/it][A
Epoch 3/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:06,  1.37s/it][A
Epoch 3/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:06,  1.37s/it][A

Epoch 3/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:12<00:05,  1.37s/it][AEpoch 3/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:12<00:05,  1.37s/it][A

Epoch 3/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:13<00:04,  1.36s/it][AEpoch 3/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:13<00:04,  1.36s/it][A
Epoch 3/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:15<00:02,  1.36s/it][A
Epoch 3/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:15<00:02,  1.36s/it][A

Epoch 3/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:16<00:01,  1.35s/it][AEpoch 3/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:16<00:01,  1.35s/it][A
Epoch 3/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.23s/it][AEpoch 3/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.34s/it]

[Î²=2.0] Epoch 3 summary:

  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=4.866e-01
  layer model_7__forward_module.module.conv2 act-std: mean=2.478e-01
  layer model_6__forward_module.module.conv1 act-std: mean=4.657e-01
  layer model_6__forward_module.module.conv2 act-std: mean=2.435e-01
Epoch 3/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.23s/it]  layer model_5__forward_module.module.conv1 act-std: mean=4.176e-01[A
  layer model_5__forward_module.module.conv2 act-std: mean=2.467e-01
  layer model_4__forward_module.module.conv1 act-std: mean=4.727e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.750e-01
  layer model_3__forward_module.module.conv1 act-std: mean=3.696e-01
  layer model_3__forward_module.module.conv2 act-std: mean=2.583e-01
Epoch 3/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.35s/it]  layer model_2__forward_module.module.conv1 act-std: mean=4.718e-01

  layer model_2__forward_module.module.conv2 act-std: mean=2.709e-01
  layer model_1__forward_module.module.conv1 act-std: mean=4.897e-01
  layer model_1__forward_module.module.conv2 act-std: mean=2.947e-01
  layer model_0__forward_module.module.conv1 act-std: mean=4.870e-01
  layer model_0__forward_module.module.conv2 act-std: mean=2.838e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=6.442e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.270e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.099e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=4.206e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=8.556e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.569e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.285e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=4.642e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=8.948e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.871e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=9.909e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.883e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.101e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.330e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.109e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.305e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.305e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=2.504e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=1.630e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=5.964e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=7.749e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.381e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=1.191e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=5.152e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.165e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=2.266e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.412e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.633e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.283e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.404e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.415e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=5.491e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  2.16it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  2.08it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  2.18it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  2.13it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  2.17it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  2.15it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.33it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.27it/s]
Training epochs:   9%|â–‰         | 3/32 [01:02<09:48, 20.30s/it]
Epoch 4/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.32it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.24it/s]
Epoch 3/32 - Train Loss: 34.990245 - Test Loss: 30.757028
Training epochs:   9%|â–‰         | 3/32 [01:02<09:48, 20.31s/it]
Epoch 4/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 4/32:   8%|â–Š         | 1/13 [00:01<00:16,  1.34s/it][A
Epoch 4/32:   8%|â–Š         | 1/13 [00:01<00:15,  1.32s/it][A

Epoch 4/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:14,  1.33s/it][AEpoch 4/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:14,  1.34s/it][A
Epoch 4/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:13,  1.33s/it][A
Epoch 4/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:03<00:13,  1.33s/it][A
Epoch 4/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:11,  1.33s/it][A
Epoch 4/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:11,  1.33s/it][A
Epoch 4/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:06<00:10,  1.33s/it][A
Epoch 4/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:06<00:10,  1.33s/it][A
Epoch 4/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:07<00:09,  1.33s/it][A
Epoch 4/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:07<00:09,  1.33s/it][A
Epoch 4/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:09<00:07,  1.33s/it][A
Epoch 4/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:09<00:07,  1.33s/it][A

Epoch 4/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:10<00:06,  1.33s/it][AEpoch 4/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:10<00:06,  1.33s/it][A
Epoch 4/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:11<00:05,  1.33s/it][A
Epoch 4/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:11<00:05,  1.33s/it][A
Epoch 4/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:13<00:04,  1.34s/it][A
Epoch 4/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:13<00:04,  1.34s/it][A

Epoch 4/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:14<00:02,  1.34s/it][AEpoch 4/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:14<00:02,  1.34s/it][A
Epoch 4/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:16<00:01,  1.34s/it][A
Epoch 4/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:15<00:01,  1.34s/it][A
Epoch 4/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:16<00:00,  1.23s/it][AEpoch 4/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:16<00:00,  1.31s/it]

Epoch 4/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:16<00:00,  1.23s/it][AEpoch 4/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:16<00:00,  1.31s/it]

[Î²=2.0] Epoch 4 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=5.036e-01
  layer model_7__forward_module.module.conv2 act-std: mean=2.801e-01
  layer model_6__forward_module.module.conv1 act-std: mean=5.161e-01
  layer model_6__forward_module.module.conv2 act-std: mean=3.354e-01
  layer model_5__forward_module.module.conv1 act-std: mean=4.412e-01
  layer model_5__forward_module.module.conv2 act-std: mean=2.969e-01
  layer model_4__forward_module.module.conv1 act-std: mean=4.912e-01
  layer model_4__forward_module.module.conv2 act-std: mean=3.246e-01
  layer model_3__forward_module.module.conv1 act-std: mean=4.115e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.360e-01
  layer model_2__forward_module.module.conv1 act-std: mean=5.273e-01
  layer model_2__forward_module.module.conv2 act-std: mean=3.469e-01
  layer model_1__forward_module.module.conv1 act-std: mean=5.210e-01
  layer model_1__forward_module.module.conv2 act-std: mean=3.512e-01
  layer model_0__forward_module.module.conv1 act-std: mean=5.562e-01
  layer model_0__forward_module.module.conv2 act-std: mean=3.920e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=4.098e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=9.941e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=3.843e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=1.576e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=4.206e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=9.764e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=3.786e-01

  param model_1__forward_module.module.conv2.bias grad-norm: mean=1.742e-01
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  param model_2__forward_module.module.conv1.weight grad-norm: mean=5.309e-01[A
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.168e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=3.359e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.517e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=6.263e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.361e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=3.705e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.725e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=5.017e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.149e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.202e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.622e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=3.462e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=8.344e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.696e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.449e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=5.026e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.080e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=3.414e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.586e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=5.043e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.224e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.295e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.818e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  2.09it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  2.07it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  2.11it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  2.06it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  2.12it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  2.10it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.29it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.22it/s]
Epoch 4/32 - Train Loss: 33.910060 - Test Loss: 30.572710

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.28it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.20it/s]
Training epochs:  12%|â–ˆâ–Ž        | 4/32 [01:21<09:11, 19.71s/it]
Epoch 5/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  12%|â–ˆâ–Ž        | 4/32 [01:21<09:12, 19.72s/it]
Epoch 5/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 5/32:   8%|â–Š         | 1/13 [00:01<00:16,  1.34s/it]Epoch 5/32:   8%|â–Š         | 1/13 [00:01<00:16,  1.35s/it][A[A
Epoch 5/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:14,  1.35s/it][A
Epoch 5/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:14,  1.34s/it][A
Epoch 5/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:13,  1.35s/it][A
Epoch 5/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:13,  1.34s/it][A
Epoch 5/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:12,  1.35s/it][A
Epoch 5/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:12,  1.35s/it][A
Epoch 5/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:06<00:10,  1.35s/it][A
Epoch 5/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:06<00:10,  1.35s/it][A

Epoch 5/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:09,  1.35s/it][AEpoch 5/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:09,  1.35s/it][A
Epoch 5/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:09<00:08,  1.35s/it][A
Epoch 5/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:09<00:08,  1.35s/it][A

Epoch 5/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:10<00:06,  1.35s/it][AEpoch 5/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:10<00:06,  1.35s/it][A
Epoch 5/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:12<00:05,  1.35s/it][A
Epoch 5/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:12<00:05,  1.35s/it][A
Epoch 5/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:13<00:04,  1.35s/it][A
Epoch 5/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:13<00:04,  1.35s/it][A
Epoch 5/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:14<00:02,  1.34s/it][A
Epoch 5/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:14<00:02,  1.34s/it][A
Epoch 5/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:16<00:01,  1.34s/it][A
Epoch 5/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:16<00:01,  1.34s/it][A
Epoch 5/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.24s/it][AEpoch 5/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.32s/it]

Epoch 5/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.24s/it][AEpoch 5/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.32s/it]

[Î²=2.0] Epoch 5 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=5.457e-01
  layer model_7__forward_module.module.conv2 act-std: mean=3.286e-01
  layer model_6__forward_module.module.conv1 act-std: mean=5.425e-01
  layer model_6__forward_module.module.conv2 act-std: mean=3.682e-01
  layer model_5__forward_module.module.conv1 act-std: mean=4.685e-01
  layer model_5__forward_module.module.conv2 act-std: mean=3.388e-01
  layer model_4__forward_module.module.conv1 act-std: mean=5.229e-01
  layer model_4__forward_module.module.conv2 act-std: mean=3.655e-01
  layer model_3__forward_module.module.conv1 act-std: mean=4.417e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.731e-01
  layer model_2__forward_module.module.conv1 act-std: mean=5.616e-01
  layer model_2__forward_module.module.conv2 act-std: mean=3.820e-01
  layer model_1__forward_module.module.conv1 act-std: mean=5.437e-01
  layer model_1__forward_module.module.conv2 act-std: mean=3.773e-01
  layer model_0__forward_module.module.conv1 act-std: mean=5.894e-01
  layer model_0__forward_module.module.conv2 act-std: mean=4.380e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=3.979e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=5.468e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.933e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=9.178e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=4.152e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=4.674e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=3.264e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=1.230e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=4.680e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=5.638e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.312e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=7.082e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=5.339e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=6.048e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.556e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=8.466e-02

  param model_4__forward_module.module.conv1.weight grad-norm: mean=3.779e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=3.059e-02Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.318e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=9.411e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=3.009e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=3.118e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=1.392e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=5.155e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=4.396e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=5.313e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=2.735e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.051e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=4.103e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=3.611e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.543e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=5.670e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  2.15it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  2.14it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  2.14it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  2.08it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  2.13it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  2.09it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.30it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.23it/s]
Training epochs:  16%|â–ˆâ–Œ        | 5/32 [01:40<08:45, 19.45s/it]
Epoch 6/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.27it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.20it/s]
Epoch 5/32 - Train Loss: 33.740646 - Test Loss: 30.389776
Training epochs:  16%|â–ˆâ–Œ        | 5/32 [01:40<08:45, 19.45s/it]
Epoch 6/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 6/32:   8%|â–Š         | 1/13 [00:01<00:16,  1.37s/it][AEpoch 6/32:   8%|â–Š         | 1/13 [00:01<00:16,  1.34s/it][A
Epoch 6/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:14,  1.34s/it][A
Epoch 6/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:14,  1.35s/it][A
Epoch 6/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:13,  1.34s/it][A
Epoch 6/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:13,  1.35s/it][A

Epoch 6/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:12,  1.34s/it][AEpoch 6/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:11,  1.33s/it][A

Epoch 6/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:06<00:10,  1.33s/it][AEpoch 6/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:06<00:10,  1.34s/it][A
Epoch 6/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:09,  1.33s/it][A
Epoch 6/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:09,  1.34s/it][A

Epoch 6/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:09<00:07,  1.33s/it][AEpoch 6/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:09<00:07,  1.33s/it][A

Epoch 6/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:10<00:06,  1.33s/it][AEpoch 6/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:10<00:06,  1.33s/it][A

Epoch 6/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:12<00:05,  1.33s/it][AEpoch 6/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:11<00:05,  1.33s/it][A
Epoch 6/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:13<00:03,  1.33s/it][A
Epoch 6/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:13<00:03,  1.33s/it][A
Epoch 6/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:14<00:02,  1.33s/it][A
Epoch 6/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:14<00:02,  1.33s/it][A

Epoch 6/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:15<00:01,  1.33s/it][AEpoch 6/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:15<00:01,  1.33s/it][A

Epoch 6/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:16<00:00,  1.22s/it][AEpoch 6/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:16<00:00,  1.31s/it]
Epoch 6/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:16<00:00,  1.22s/it][AEpoch 6/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:16<00:00,  1.30s/it]

[Î²=2.0] Epoch 6 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=5.561e-01
  layer model_7__forward_module.module.conv2 act-std: mean=3.110e-01
  layer model_6__forward_module.module.conv1 act-std: mean=5.336e-01
  layer model_6__forward_module.module.conv2 act-std: mean=3.222e-01
  layer model_5__forward_module.module.conv1 act-std: mean=4.796e-01
  layer model_5__forward_module.module.conv2 act-std: mean=3.364e-01
  layer model_4__forward_module.module.conv1 act-std: mean=5.342e-01
  layer model_4__forward_module.module.conv2 act-std: mean=3.537e-01
  layer model_3__forward_module.module.conv1 act-std: mean=4.394e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.299e-01
  layer model_2__forward_module.module.conv1 act-std: mean=5.626e-01
  layer model_2__forward_module.module.conv2 act-std: mean=3.431e-01
  layer model_1__forward_module.module.conv1 act-std: mean=5.426e-01
  layer model_1__forward_module.module.conv2 act-std: mean=3.431e-01
  layer model_0__forward_module.module.conv1 act-std: mean=5.777e-01
  layer model_0__forward_module.module.conv2 act-std: mean=3.839e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.651e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=2.678e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.022e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.667e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=2.814e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=3.214e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.245e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=5.850e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=2.761e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=4.514e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.510e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=6.642e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.190e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=5.875e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.849e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=8.377e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.866e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=5.756e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=1.686e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=8.110e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.038e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=3.568e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=1.173e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=5.795e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=2.893e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=5.864e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=2.037e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=9.116e-02

  param model_7__forward_module.module.conv1.weight grad-norm: mean=2.785e-01
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  param model_7__forward_module.module.conv1.bias grad-norm: mean=5.723e-02[A
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.711e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=8.078e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  2.18it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  2.15it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  2.20it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  2.16it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  2.19it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  2.16it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.35it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.29it/s]
Training epochs:  19%|â–ˆâ–‰        | 6/32 [01:59<08:19, 19.20s/it]
Epoch 7/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.33it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.26it/s]
Epoch 6/32 - Train Loss: 33.572978 - Test Loss: 30.248365
Training epochs:  19%|â–ˆâ–‰        | 6/32 [01:59<08:19, 19.21s/it]
Epoch 7/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 7/32:   8%|â–Š         | 1/13 [00:01<00:15,  1.33s/it][A
Epoch 7/32:   8%|â–Š         | 1/13 [00:01<00:16,  1.36s/it][A

Epoch 7/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:14,  1.34s/it][AEpoch 7/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:14,  1.33s/it][A

Epoch 7/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:03<00:13,  1.33s/it][AEpoch 7/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:13,  1.33s/it][A

Epoch 7/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:11,  1.33s/it][AEpoch 7/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:11,  1.33s/it][A
Epoch 7/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:06<00:10,  1.33s/it][A
Epoch 7/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:06<00:10,  1.33s/it][A
Epoch 7/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:07<00:09,  1.33s/it][A
Epoch 7/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:07<00:09,  1.33s/it][A

Epoch 7/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:09<00:07,  1.33s/it][AEpoch 7/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:09<00:07,  1.33s/it][A
Epoch 7/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:10<00:06,  1.33s/it][A
Epoch 7/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:10<00:06,  1.33s/it][A
Epoch 7/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:11<00:05,  1.33s/it][A
Epoch 7/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:11<00:05,  1.33s/it][A
Epoch 7/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:13<00:03,  1.33s/it][A
Epoch 7/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:13<00:03,  1.33s/it][A
Epoch 7/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:14<00:02,  1.33s/it][A
Epoch 7/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:14<00:02,  1.33s/it][A
Epoch 7/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:15<00:01,  1.33s/it][A
Epoch 7/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:15<00:01,  1.33s/it][A

Epoch 7/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:16<00:00,  1.22s/it][AEpoch 7/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:16<00:00,  1.22s/it][AEpoch 7/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:16<00:00,  1.30s/it]
Epoch 7/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:16<00:00,  1.30s/it]

[Î²=2.0] Epoch 7 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=5.860e-01
  layer model_7__forward_module.module.conv2 act-std: mean=3.234e-01
  layer model_6__forward_module.module.conv1 act-std: mean=5.532e-01
  layer model_6__forward_module.module.conv2 act-std: mean=3.216e-01
  layer model_5__forward_module.module.conv1 act-std: mean=4.975e-01
  layer model_5__forward_module.module.conv2 act-std: mean=3.409e-01
  layer model_4__forward_module.module.conv1 act-std: mean=5.572e-01
  layer model_4__forward_module.module.conv2 act-std: mean=3.592e-01
  layer model_3__forward_module.module.conv1 act-std: mean=4.497e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.181e-01
  layer model_2__forward_module.module.conv1 act-std: mean=5.752e-01
  layer model_2__forward_module.module.conv2 act-std: mean=3.283e-01
  layer model_1__forward_module.module.conv1 act-std: mean=5.497e-01
  layer model_1__forward_module.module.conv2 act-std: mean=3.259e-01
  layer model_0__forward_module.module.conv1 act-std: mean=5.764e-01
  layer model_0__forward_module.module.conv2 act-std: mean=3.544e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.345e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=3.558e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.009e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.541e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=2.609e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=3.648e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=8.091e-02
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.670e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=2.865e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=2.397e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=7.611e-02
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.913e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.312e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.015e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=7.541e-02
  param model_3__forward_module.module.conv2.bias grad-norm: mean=2.072e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.670e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=2.774e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=9.051e-02
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.895e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.991e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=2.586e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=9.037e-02
  param model_5__forward_module.module.conv2.bias grad-norm: mean=4.307e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.159e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=2.188e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.037e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=3.640e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=2.932e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=3.231e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.099e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=3.979e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  2.11it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  2.08it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  2.14it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  2.12it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  2.15it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  2.11it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.33it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.25it/s]
Training epochs:  22%|â–ˆâ–ˆâ–       | 7/32 [02:18<07:56, 19.06s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.32it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.24it/s]
Epoch 7/32 - Train Loss: 33.394186 - Test Loss: 30.126839

Epoch 8/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  22%|â–ˆâ–ˆâ–       | 7/32 [02:18<07:56, 19.06s/it]
Epoch 8/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 8/32:   8%|â–Š         | 1/13 [00:01<00:16,  1.34s/it][A
Epoch 8/32:   8%|â–Š         | 1/13 [00:01<00:15,  1.33s/it][A

Epoch 8/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:14,  1.33s/it][AEpoch 8/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:14,  1.34s/it][A

Epoch 8/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:03<00:13,  1.33s/it][AEpoch 8/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:13,  1.33s/it][A
Epoch 8/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:11,  1.33s/it][A
Epoch 8/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:11,  1.33s/it][A
Epoch 8/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:06<00:10,  1.33s/it][A
Epoch 8/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:06<00:10,  1.33s/it][A

Epoch 8/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:07<00:09,  1.33s/it][AEpoch 8/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:07<00:09,  1.33s/it][A

Epoch 8/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:09<00:07,  1.33s/it][AEpoch 8/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:09<00:07,  1.33s/it][A
Epoch 8/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:10<00:06,  1.33s/it][A
Epoch 8/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:10<00:06,  1.33s/it][A
Epoch 8/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:11<00:05,  1.33s/it][A
Epoch 8/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:11<00:05,  1.33s/it][A

Epoch 8/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:13<00:03,  1.33s/it][AEpoch 8/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:13<00:03,  1.33s/it][A

Epoch 8/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:14<00:02,  1.33s/it][AEpoch 8/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:14<00:02,  1.33s/it][A

Epoch 8/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:15<00:01,  1.33s/it][AEpoch 8/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:15<00:01,  1.33s/it][A
Epoch 8/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:16<00:00,  1.22s/it][AEpoch 8/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:16<00:00,  1.30s/it]


[Î²=2.0] Epoch 8 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=6.145e-01
  layer model_7__forward_module.module.conv2 act-std: mean=3.313e-01
  layer model_6__forward_module.module.conv1 act-std: mean=5.722e-01
  layer model_6__forward_module.module.conv2 act-std: mean=3.183e-01
  layer model_5__forward_module.module.conv1 act-std: mean=5.176e-01
  layer model_5__forward_module.module.conv2 act-std: mean=3.476e-01
Epoch 8/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:16<00:00,  1.22s/it]  layer model_4__forward_module.module.conv1 act-std: mean=5.804e-01[A
  layer model_4__forward_module.module.conv2 act-std: mean=3.664e-01
  layer model_3__forward_module.module.conv1 act-std: mean=4.597e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.072e-01
  layer model_2__forward_module.module.conv1 act-std: mean=5.924e-01
  layer model_2__forward_module.module.conv2 act-std: mean=3.192e-01
  layer model_1__forward_module.module.conv1 act-std: mean=5.674e-01Epoch 8/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:16<00:00,  1.30s/it]

  layer model_1__forward_module.module.conv2 act-std: mean=3.240e-01
  layer model_0__forward_module.module.conv1 act-std: mean=5.934e-01
  layer model_0__forward_module.module.conv2 act-std: mean=3.545e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.216e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=3.146e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.081e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.139e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=2.498e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.978e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=8.365e-02
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.968e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=2.472e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=3.622e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.186e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.107e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=2.918e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=3.429e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.195e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=2.728e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.422e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=3.405e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=9.446e-02
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.253e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.741e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=2.661e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=9.309e-02
  param model_5__forward_module.module.conv2.bias grad-norm: mean=3.534e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=2.660e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=3.615e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.362e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=2.645e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=2.710e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.883e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.158e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=2.053e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  2.22it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  2.19it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  2.18it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  2.15it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  2.16it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  2.15it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.33it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.27it/s]
Epoch 8/32 - Train Loss: 33.287424 - Test Loss: 29.999831

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.33it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.26it/s]
Training epochs:  25%|â–ˆâ–ˆâ–Œ       | 8/32 [02:36<07:34, 18.95s/it]
Epoch 9/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  25%|â–ˆâ–ˆâ–Œ       | 8/32 [02:36<07:34, 18.96s/it]
Epoch 9/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 9/32:   8%|â–Š         | 1/13 [00:01<00:15,  1.32s/it][A
Epoch 9/32:   8%|â–Š         | 1/13 [00:01<00:15,  1.32s/it][A

Epoch 9/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:14,  1.33s/it][AEpoch 9/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:14,  1.33s/it][A

Epoch 9/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:03<00:13,  1.33s/it][AEpoch 9/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:03<00:13,  1.33s/it][A

Epoch 9/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:11,  1.32s/it][AEpoch 9/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:11,  1.33s/it][A

Epoch 9/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:06<00:10,  1.33s/it][AEpoch 9/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:06<00:10,  1.33s/it][A

Epoch 9/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:07<00:09,  1.33s/it][AEpoch 9/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:07<00:09,  1.33s/it][A
Epoch 9/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:09<00:07,  1.33s/it][A
Epoch 9/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:09<00:07,  1.33s/it][A

Epoch 9/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:10<00:06,  1.33s/it][AEpoch 9/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:10<00:06,  1.33s/it][A

Epoch 9/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:11<00:05,  1.33s/it][AEpoch 9/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:11<00:05,  1.33s/it][A

Epoch 9/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:13<00:03,  1.33s/it][AEpoch 9/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:13<00:03,  1.33s/it][A
Epoch 9/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:14<00:02,  1.33s/it][A
Epoch 9/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:14<00:02,  1.33s/it][A
Epoch 9/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:15<00:01,  1.33s/it][A
Epoch 9/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:15<00:01,  1.33s/it][A
Epoch 9/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:16<00:00,  1.22s/it][AEpoch 9/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:16<00:00,  1.30s/it]

Epoch 9/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:16<00:00,  1.22s/it][AEpoch 9/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:16<00:00,  1.30s/it]

[Î²=2.0] Epoch 9 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=6.408e-01
  layer model_7__forward_module.module.conv2 act-std: mean=3.367e-01
  layer model_6__forward_module.module.conv1 act-std: mean=5.971e-01
  layer model_6__forward_module.module.conv2 act-std: mean=3.251e-01
  layer model_5__forward_module.module.conv1 act-std: mean=5.393e-01
  layer model_5__forward_module.module.conv2 act-std: mean=3.562e-01
  layer model_4__forward_module.module.conv1 act-std: mean=6.029e-01
  layer model_4__forward_module.module.conv2 act-std: mean=3.736e-01
  layer model_3__forward_module.module.conv1 act-std: mean=4.713e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.036e-01
  layer model_2__forward_module.module.conv1 act-std: mean=6.150e-01

  layer model_2__forward_module.module.conv2 act-std: mean=3.218e-01
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  layer model_1__forward_module.module.conv1 act-std: mean=5.855e-01[A
  layer model_1__forward_module.module.conv2 act-std: mean=3.235e-01
  layer model_0__forward_module.module.conv1 act-std: mean=6.130e-01
  layer model_0__forward_module.module.conv2 act-std: mean=3.616e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.029e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=2.365e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.028e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=1.719e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=2.268e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.670e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=9.176e-02
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.059e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=2.354e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=2.302e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.090e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.452e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=2.796e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.223e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.252e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.611e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.268e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.996e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=8.111e-02
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.629e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.616e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=2.074e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=8.370e-02
  param model_5__forward_module.module.conv2.bias grad-norm: mean=2.292e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=2.821e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=2.232e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.363e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.892e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=2.799e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.443e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.320e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.836e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  2.18it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  2.15it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  2.16it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  2.14it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  2.16it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  2.15it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.31it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.25it/s]
Training epochs:  28%|â–ˆâ–ˆâ–Š       | 9/32 [02:55<07:14, 18.88s/it]

Epoch 10/32:   0%|          | 0/13 [00:00<?, ?it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.30it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.24it/s]
Epoch 9/32 - Train Loss: 33.132789 - Test Loss: 29.865133
Training epochs:  28%|â–ˆâ–ˆâ–Š       | 9/32 [02:55<07:14, 18.88s/it]
Epoch 10/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 10/32:   8%|â–Š         | 1/13 [00:01<00:15,  1.33s/it][A
Epoch 10/32:   8%|â–Š         | 1/13 [00:01<00:16,  1.34s/it][A
Epoch 10/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:14,  1.33s/it][A
Epoch 10/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:14,  1.33s/it][A

Epoch 10/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:03<00:13,  1.33s/it]Epoch 10/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:13,  1.34s/it][A[A
Epoch 10/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:11,  1.33s/it][A
Epoch 10/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:11,  1.33s/it][A
Epoch 10/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:06<00:10,  1.33s/it][A
Epoch 10/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:06<00:10,  1.33s/it][A
Epoch 10/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:07<00:09,  1.33s/it][A
Epoch 10/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:07<00:09,  1.33s/it][A

Epoch 10/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:09<00:07,  1.33s/it][AEpoch 10/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:09<00:07,  1.33s/it][A

Epoch 10/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:10<00:06,  1.33s/it][AEpoch 10/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:10<00:06,  1.33s/it][A
Epoch 10/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:11<00:05,  1.33s/it][A
Epoch 10/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:11<00:05,  1.33s/it][A

Epoch 10/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:13<00:03,  1.33s/it][AEpoch 10/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:13<00:03,  1.33s/it][A
Epoch 10/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:14<00:02,  1.33s/it][A
Epoch 10/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:14<00:02,  1.33s/it][A
Epoch 10/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:15<00:01,  1.33s/it][A
Epoch 10/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:15<00:01,  1.33s/it][A
Epoch 10/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:16<00:00,  1.22s/it][AEpoch 10/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:16<00:00,  1.30s/it]

Epoch 10/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:16<00:00,  1.22s/it][AEpoch 10/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:16<00:00,  1.30s/it]

[Î²=2.0] Epoch 10 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=6.619e-01
  layer model_7__forward_module.module.conv2 act-std: mean=3.342e-01
  layer model_6__forward_module.module.conv1 act-std: mean=6.191e-01
  layer model_6__forward_module.module.conv2 act-std: mean=3.241e-01
  layer model_5__forward_module.module.conv1 act-std: mean=5.603e-01
  layer model_5__forward_module.module.conv2 act-std: mean=3.618e-01
  layer model_4__forward_module.module.conv1 act-std: mean=6.230e-01
  layer model_4__forward_module.module.conv2 act-std: mean=3.754e-01
  layer model_3__forward_module.module.conv1 act-std: mean=4.822e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.018e-01
  layer model_2__forward_module.module.conv1 act-std: mean=6.364e-01
  layer model_2__forward_module.module.conv2 act-std: mean=3.234e-01
  layer model_1__forward_module.module.conv1 act-std: mean=6.049e-01
  layer model_1__forward_module.module.conv2 act-std: mean=3.255e-01
  layer model_0__forward_module.module.conv1 act-std: mean=6.313e-01
  layer model_0__forward_module.module.conv2 act-std: mean=3.677e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.875e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=2.394e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.134e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=1.625e-02

  param model_1__forward_module.module.conv1.weight grad-norm: mean=2.097e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.872e-02Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.105e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.243e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=2.137e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=2.477e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.257e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.772e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=2.532e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.499e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.438e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.563e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.074e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=2.306e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=1.021e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.842e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.495e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.850e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=8.710e-02
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.883e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=2.665e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=2.578e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.596e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=2.074e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=2.792e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.638e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.525e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=2.412e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  2.16it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  2.16it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  2.17it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  2.17it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  2.18it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  2.16it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.34it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.27it/s]
Training epochs:  31%|â–ˆâ–ˆâ–ˆâ–      | 10/32 [03:14<06:54, 18.83s/it]
Epoch 11/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.32it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.26it/s]
Epoch 10/32 - Train Loss: 32.982866 - Test Loss: 29.726177
Training epochs:  31%|â–ˆâ–ˆâ–ˆâ–      | 10/32 [03:14<06:54, 18.83s/it]
Epoch 11/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 11/32:   8%|â–Š         | 1/13 [00:01<00:16,  1.33s/it][A
Epoch 11/32:   8%|â–Š         | 1/13 [00:01<00:16,  1.35s/it][A

Epoch 11/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:14,  1.33s/it][AEpoch 11/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:14,  1.34s/it][A
Epoch 11/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:13,  1.33s/it][A
Epoch 11/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:03<00:13,  1.33s/it][A
Epoch 11/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:11,  1.33s/it][A
Epoch 11/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:11,  1.33s/it][A

Epoch 11/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:06<00:10,  1.33s/it][AEpoch 11/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:06<00:10,  1.32s/it][A
Epoch 11/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:07<00:09,  1.33s/it][A
Epoch 11/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:07<00:09,  1.33s/it][A

Epoch 11/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:09<00:07,  1.33s/it][AEpoch 11/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:09<00:07,  1.33s/it][A
Epoch 11/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:10<00:06,  1.33s/it][A
Epoch 11/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:10<00:06,  1.33s/it][A

Epoch 11/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:11<00:05,  1.33s/it]Epoch 11/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:11<00:05,  1.33s/it][A[A

Epoch 11/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:13<00:03,  1.33s/it][AEpoch 11/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:13<00:03,  1.33s/it][A
Epoch 11/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:14<00:02,  1.33s/it][A
Epoch 11/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:14<00:02,  1.33s/it][A
Epoch 11/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:15<00:01,  1.33s/it][A
Epoch 11/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:15<00:01,  1.33s/it][A
Epoch 11/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:16<00:00,  1.22s/it][AEpoch 11/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:16<00:00,  1.30s/it]

Epoch 11/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:16<00:00,  1.22s/it][AEpoch 11/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:16<00:00,  1.30s/it]

[Î²=2.0] Epoch 11 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=6.799e-01
  layer model_7__forward_module.module.conv2 act-std: mean=3.289e-01
  layer model_6__forward_module.module.conv1 act-std: mean=6.411e-01
  layer model_6__forward_module.module.conv2 act-std: mean=3.217e-01
  layer model_5__forward_module.module.conv1 act-std: mean=5.802e-01
  layer model_5__forward_module.module.conv2 act-std: mean=3.661e-01
  layer model_4__forward_module.module.conv1 act-std: mean=6.426e-01
  layer model_4__forward_module.module.conv2 act-std: mean=3.771e-01
  layer model_3__forward_module.module.conv1 act-std: mean=4.926e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.035e-01
  layer model_2__forward_module.module.conv1 act-std: mean=6.568e-01
  layer model_2__forward_module.module.conv2 act-std: mean=3.282e-01
  layer model_1__forward_module.module.conv1 act-std: mean=6.252e-01
  layer model_1__forward_module.module.conv2 act-std: mean=3.312e-01
  layer model_0__forward_module.module.conv1 act-std: mean=6.485e-01
  layer model_0__forward_module.module.conv2 act-std: mean=3.753e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.681e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.999e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.151e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=1.553e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.900e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.336e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.126e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=1.978e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=1.948e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=2.768e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.323e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.918e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=2.324e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.609e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.488e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.818e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.944e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.932e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=1.037e-01

  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.783e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.368e-01Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.625e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=9.049e-02
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.843e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=2.617e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=2.553e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.668e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=2.539e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=2.675e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.486e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.614e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=3.049e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  2.17it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  2.14it/s][A

Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  2.16it/s][AEvaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  2.16it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  2.17it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  2.15it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.34it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.27it/s]
Epoch 11/32 - Train Loss: 32.827900 - Test Loss: 29.585988

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.33it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.26it/s]
Training epochs:  34%|â–ˆâ–ˆâ–ˆâ–      | 11/32 [03:32<06:34, 18.79s/it]Training epochs:  34%|â–ˆâ–ˆâ–ˆâ–      | 11/32 [03:32<06:34, 18.79s/it]
Epoch 12/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 12/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 12/32:   8%|â–Š         | 1/13 [00:01<00:15,  1.32s/it][AEpoch 12/32:   8%|â–Š         | 1/13 [00:01<00:15,  1.32s/it][A
Epoch 12/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:14,  1.33s/it][A
Epoch 12/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:14,  1.33s/it][A

Epoch 12/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:03<00:13,  1.32s/it][AEpoch 12/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:03<00:13,  1.32s/it][A
Epoch 12/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:11,  1.32s/it][A
Epoch 12/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:11,  1.33s/it][A

Epoch 12/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:06<00:10,  1.33s/it][AEpoch 12/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:06<00:10,  1.33s/it][A

Epoch 12/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:07<00:09,  1.33s/it][AEpoch 12/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:07<00:09,  1.33s/it][A
Epoch 12/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:09<00:07,  1.33s/it][A
Epoch 12/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:09<00:07,  1.33s/it][A

Epoch 12/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:10<00:06,  1.32s/it][AEpoch 12/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:10<00:06,  1.33s/it][A
Epoch 12/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:11<00:05,  1.33s/it][A
Epoch 12/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:11<00:05,  1.33s/it][A
Epoch 12/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:13<00:03,  1.33s/it][A
Epoch 12/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:13<00:03,  1.33s/it][A
Epoch 12/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:14<00:02,  1.33s/it][A
Epoch 12/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:14<00:02,  1.33s/it][A
Epoch 12/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:15<00:01,  1.32s/it][A
Epoch 12/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:15<00:01,  1.32s/it][A
Epoch 12/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:16<00:00,  1.22s/it][AEpoch 12/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:16<00:00,  1.30s/it]

[Î²=2.0] Epoch 12 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=6.956e-01
  layer model_7__forward_module.module.conv2 act-std: mean=3.235e-01
  layer model_6__forward_module.module.conv1 act-std: mean=6.642e-01
  layer model_6__forward_module.module.conv2 act-std: mean=3.192e-01
  layer model_5__forward_module.module.conv1 act-std: mean=5.991e-01
  layer model_5__forward_module.module.conv2 act-std: mean=3.701e-01
  layer model_4__forward_module.module.conv1 act-std: mean=6.612e-01
  layer model_4__forward_module.module.conv2 act-std: mean=3.776e-01
  layer model_3__forward_module.module.conv1 act-std: mean=5.025e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.085e-01
  layer model_2__forward_module.module.conv1 act-std: mean=6.768e-01
  layer model_2__forward_module.module.conv2 act-std: mean=3.392e-01
  layer model_1__forward_module.module.conv1 act-std: mean=6.446e-01
  layer model_1__forward_module.module.conv2 act-std: mean=3.387e-01
  layer model_0__forward_module.module.conv1 act-std: mean=6.650e-01
  layer model_0__forward_module.module.conv2 act-std: mean=3.869e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.473e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.833e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.152e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=1.593e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.699e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.320e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.180e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=1.933e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=1.673e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.810e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.235e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.909e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=2.050e-01

  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.823e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.427e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.825e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.705e-01
Epoch 12/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:16<00:00,  1.22s/it]  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.707e-02[A
  param model_4__forward_module.module.conv2.weight grad-norm: mean=1.081e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.346e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.281e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.461e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=8.943e-02
Epoch 12/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:16<00:00,  1.30s/it]  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.630e-02

  param model_6__forward_module.module.conv1.weight grad-norm: mean=2.466e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=2.250e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.651e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=3.041e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=2.525e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.332e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.602e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=3.725e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  2.15it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  2.12it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  2.15it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  2.14it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  2.12it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  2.12it/s][A

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.30it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.24it/s]
Epoch 12/32 - Train Loss: 32.665095 - Test Loss: 29.452167
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.31it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.24it/s]
Training epochs:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 12/32 [03:51<06:15, 18.76s/it]Training epochs:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 12/32 [03:51<06:15, 18.76s/it]
Epoch 13/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 13/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 13/32:   8%|â–Š         | 1/13 [00:01<00:15,  1.33s/it][A
Epoch 13/32:   8%|â–Š         | 1/13 [00:01<00:15,  1.33s/it][A

Epoch 13/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:14,  1.34s/it][AEpoch 13/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:14,  1.34s/it][A

Epoch 13/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:13,  1.34s/it][AEpoch 13/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:13,  1.33s/it][A
Epoch 13/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:12,  1.34s/it][A
Epoch 13/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:12,  1.34s/it][A
Epoch 13/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:06<00:10,  1.35s/it][A
Epoch 13/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:06<00:10,  1.35s/it][A

Epoch 13/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:09,  1.35s/it][AEpoch 13/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:09,  1.36s/it][A

Epoch 13/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:09<00:08,  1.36s/it][AEpoch 13/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:09<00:08,  1.36s/it][A
Epoch 13/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:10<00:06,  1.36s/it][A
Epoch 13/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:10<00:06,  1.36s/it][A

Epoch 13/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:12<00:05,  1.36s/it][AEpoch 13/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:12<00:05,  1.36s/it][A
Epoch 13/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:13<00:04,  1.36s/it][A
Epoch 13/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:13<00:04,  1.36s/it][A

Epoch 13/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:14<00:02,  1.36s/it][AEpoch 13/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:14<00:02,  1.36s/it][A
Epoch 13/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:16<00:01,  1.36s/it][A
Epoch 13/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:16<00:01,  1.36s/it][A
Epoch 13/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.25s/it][AEpoch 13/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.33s/it]

Epoch 13/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.25s/it][AEpoch 13/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.33s/it]

[Î²=2.0] Epoch 13 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=7.088e-01
  layer model_7__forward_module.module.conv2 act-std: mean=3.181e-01

  layer model_6__forward_module.module.conv1 act-std: mean=6.882e-01
  layer model_6__forward_module.module.conv2 act-std: mean=3.150e-01Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  layer model_5__forward_module.module.conv1 act-std: mean=6.179e-01
  layer model_5__forward_module.module.conv2 act-std: mean=3.744e-01
  layer model_4__forward_module.module.conv1 act-std: mean=6.801e-01
  layer model_4__forward_module.module.conv2 act-std: mean=3.801e-01
  layer model_3__forward_module.module.conv1 act-std: mean=5.119e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.150e-01
  layer model_2__forward_module.module.conv1 act-std: mean=6.941e-01
  layer model_2__forward_module.module.conv2 act-std: mean=3.525e-01
  layer model_1__forward_module.module.conv1 act-std: mean=6.635e-01
  layer model_1__forward_module.module.conv2 act-std: mean=3.498e-01
  layer model_0__forward_module.module.conv1 act-std: mean=6.807e-01
  layer model_0__forward_module.module.conv2 act-std: mean=4.018e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.295e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.624e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.117e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=1.611e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.533e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.037e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.169e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=1.942e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=1.425e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.675e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.185e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.741e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.757e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.816e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.379e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.719e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.596e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.515e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=1.089e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.503e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.219e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.314e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=9.052e-02
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.703e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=2.165e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=2.262e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.613e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=3.093e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=2.269e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.171e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.511e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.223e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A

Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  2.07it/s][AEvaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  2.05it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  2.03it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  2.01it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  2.03it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  2.03it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.21it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.14it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.20it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.14it/s]
Epoch 13/32 - Train Loss: 32.524077 - Test Loss: 29.331734
Training epochs:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 13/32 [04:10<05:58, 18.88s/it]
Epoch 14/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 13/32 [04:10<05:58, 18.88s/it]
Epoch 14/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 14/32:   8%|â–Š         | 1/13 [00:01<00:16,  1.37s/it][A
Epoch 14/32:   8%|â–Š         | 1/13 [00:01<00:16,  1.36s/it][A
Epoch 14/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:15,  1.37s/it][A
Epoch 14/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:14,  1.36s/it][A
Epoch 14/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:13,  1.36s/it][A
Epoch 14/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:13,  1.36s/it][A

Epoch 14/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:12,  1.37s/it][AEpoch 14/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:12,  1.37s/it][A
Epoch 14/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:06<00:10,  1.37s/it][A
Epoch 14/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:06<00:10,  1.37s/it][A

Epoch 14/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:09,  1.38s/it][AEpoch 14/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:09,  1.37s/it][A
Epoch 14/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:09<00:08,  1.38s/it][A
Epoch 14/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:09<00:08,  1.38s/it][A
Epoch 14/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:10<00:06,  1.38s/it][A
Epoch 14/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:10<00:06,  1.38s/it][A
Epoch 14/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:12<00:05,  1.38s/it][A
Epoch 14/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:12<00:05,  1.38s/it][A
Epoch 14/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:13<00:04,  1.38s/it][A
Epoch 14/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:13<00:04,  1.38s/it][A
Epoch 14/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:15<00:02,  1.38s/it][A
Epoch 14/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:15<00:02,  1.38s/it][A
Epoch 14/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:16<00:01,  1.38s/it][A
Epoch 14/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:16<00:01,  1.38s/it][A
Epoch 14/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.27s/it][AEpoch 14/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.35s/it]

[Î²=2.0] Epoch 14 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=7.197e-01

  layer model_7__forward_module.module.conv2 act-std: mean=3.125e-01
  layer model_6__forward_module.module.conv1 act-std: mean=7.142e-01
  layer model_6__forward_module.module.conv2 act-std: mean=3.128e-01
  layer model_5__forward_module.module.conv1 act-std: mean=6.367e-01
  layer model_5__forward_module.module.conv2 act-std: mean=3.766e-01
  layer model_4__forward_module.module.conv1 act-std: mean=6.973e-01
  layer model_4__forward_module.module.conv2 act-std: mean=3.813e-01
  layer model_3__forward_module.module.conv1 act-std: mean=5.214e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.240e-01
  layer model_2__forward_module.module.conv1 act-std: mean=7.088e-01
  layer model_2__forward_module.module.conv2 act-std: mean=3.680e-01
  layer model_1__forward_module.module.conv1 act-std: mean=6.806e-01
  layer model_1__forward_module.module.conv2 act-std: mean=3.620e-01
  layer model_0__forward_module.module.conv1 act-std: mean=6.952e-01
  layer model_0__forward_module.module.conv2 act-std: mean=4.203e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.177e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.353e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.033e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=1.647e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.391e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.609e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.105e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=1.649e-02Epoch 14/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.27s/it]
[A  param model_2__forward_module.module.conv1.weight grad-norm: mean=1.233e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.470e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.089e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.416e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.640e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.851e-02
Epoch 14/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.35s/it]  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.260e-01

  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.825e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.550e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.424e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=1.079e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.763e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.196e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.520e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=9.531e-02
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.690e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=2.035e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=2.571e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.495e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=3.601e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=2.094e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.634e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.401e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.580e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A

Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  2.01it/s][AEvaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  2.01it/s][A

Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  2.04it/s][AEvaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  2.04it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  2.05it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  2.05it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.21it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.14it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.20it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.14it/s]
Epoch 14/32 - Train Loss: 32.395406 - Test Loss: 29.223761
Training epochs:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 14/32 [04:30<05:42, 19.04s/it]Training epochs:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 14/32 [04:30<05:42, 19.03s/it]
Epoch 15/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 15/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 15/32:   8%|â–Š         | 1/13 [00:01<00:16,  1.38s/it][AEpoch 15/32:   8%|â–Š         | 1/13 [00:01<00:16,  1.38s/it][A

Epoch 15/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:16,  1.47s/it][AEpoch 15/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:16,  1.47s/it][A
Epoch 15/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.43s/it][A
Epoch 15/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.43s/it][A

Epoch 15/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:12,  1.41s/it][AEpoch 15/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:12,  1.41s/it][A

Epoch 15/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.40s/it][AEpoch 15/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.40s/it][A
Epoch 15/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:09,  1.39s/it][A
Epoch 15/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:09,  1.39s/it][A
Epoch 15/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:09<00:08,  1.39s/it][A
Epoch 15/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:09<00:08,  1.39s/it][A
Epoch 15/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:06,  1.39s/it][A
Epoch 15/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:06,  1.39s/it][A
Epoch 15/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:12<00:05,  1.39s/it][A
Epoch 15/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:12<00:05,  1.39s/it][A

Epoch 15/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:13<00:04,  1.39s/it][AEpoch 15/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:13<00:04,  1.39s/it][A

Epoch 15/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:15<00:02,  1.39s/it][AEpoch 15/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:15<00:02,  1.39s/it][A
Epoch 15/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:16<00:01,  1.39s/it][A
Epoch 15/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:16<00:01,  1.39s/it][A
Epoch 15/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.28s/it][A
Epoch 15/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.37s/it]
Epoch 15/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.28s/it][AEpoch 15/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.37s/it]

[Î²=2.0] Epoch 15 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=7.280e-01
  layer model_7__forward_module.module.conv2 act-std: mean=3.064e-01
  layer model_6__forward_module.module.conv1 act-std: mean=7.383e-01
  layer model_6__forward_module.module.conv2 act-std: mean=3.104e-01
  layer model_5__forward_module.module.conv1 act-std: mean=6.569e-01
  layer model_5__forward_module.module.conv2 act-std: mean=3.789e-01
  layer model_4__forward_module.module.conv1 act-std: mean=7.117e-01
  layer model_4__forward_module.module.conv2 act-std: mean=3.796e-01
  layer model_3__forward_module.module.conv1 act-std: mean=5.296e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.308e-01
  layer model_2__forward_module.module.conv1 act-std: mean=7.217e-01
  layer model_2__forward_module.module.conv2 act-std: mean=3.858e-01
  layer model_1__forward_module.module.conv1 act-std: mean=6.956e-01
  layer model_1__forward_module.module.conv2 act-std: mean=3.745e-01
  layer model_0__forward_module.module.conv1 act-std: mean=7.074e-01
  layer model_0__forward_module.module.conv2 act-std: mean=4.382e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.071e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.419e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=9.752e-02
  param model_0__forward_module.module.conv2.bias grad-norm: mean=1.450e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.396e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.833e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.093e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=1.834e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=1.182e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.468e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=9.905e-02
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.439e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.368e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.473e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.163e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.505e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.525e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.804e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=1.156e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=2.221e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.149e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.127e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=9.351e-02

  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.659e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.938e-01Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  param model_6__forward_module.module.conv1.bias grad-norm: mean=2.892e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.402e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=3.757e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.704e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.986e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.282e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.539e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  2.06it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  2.04it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  2.05it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  2.02it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  2.05it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  2.03it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.19it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.14it/s]
Training epochs:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 15/32 [04:49<05:26, 19.23s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.19it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.12it/s]
Epoch 15/32 - Train Loss: 32.294538 - Test Loss: 29.129132

Epoch 16/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 15/32 [04:49<05:26, 19.23s/it]
Epoch 16/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 16/32:   8%|â–Š         | 1/13 [00:01<00:16,  1.39s/it][A
Epoch 16/32:   8%|â–Š         | 1/13 [00:01<00:16,  1.38s/it][A

Epoch 16/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:15,  1.38s/it][AEpoch 16/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:15,  1.38s/it][A
Epoch 16/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:13,  1.38s/it][A
Epoch 16/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:13,  1.38s/it][A
Epoch 16/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:12,  1.38s/it][A
Epoch 16/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:12,  1.38s/it][A
Epoch 16/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:06<00:11,  1.39s/it][A
Epoch 16/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:06<00:11,  1.38s/it][A
Epoch 16/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:09,  1.39s/it][A
Epoch 16/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:09,  1.39s/it][A

Epoch 16/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:09<00:08,  1.39s/it][AEpoch 16/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:09<00:08,  1.39s/it][A
Epoch 16/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:06,  1.38s/it][A
Epoch 16/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:06,  1.38s/it][A
Epoch 16/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:12<00:05,  1.38s/it][A
Epoch 16/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:12<00:05,  1.38s/it][A

Epoch 16/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:13<00:04,  1.38s/it][AEpoch 16/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:13<00:04,  1.38s/it][A
Epoch 16/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:15<00:02,  1.38s/it][A
Epoch 16/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:15<00:02,  1.38s/it][A
Epoch 16/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:16<00:01,  1.38s/it][A
Epoch 16/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:16<00:01,  1.38s/it][A

Epoch 16/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.27s/it]Epoch 16/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.27s/it][A[AEpoch 16/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.36s/it]
Epoch 16/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.35s/it]

[Î²=2.0] Epoch 16 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=7.354e-01
  layer model_7__forward_module.module.conv2 act-std: mean=3.017e-01
  layer model_6__forward_module.module.conv1 act-std: mean=7.571e-01
  layer model_6__forward_module.module.conv2 act-std: mean=3.102e-01
  layer model_5__forward_module.module.conv1 act-std: mean=6.780e-01
  layer model_5__forward_module.module.conv2 act-std: mean=3.778e-01
  layer model_4__forward_module.module.conv1 act-std: mean=7.253e-01
  layer model_4__forward_module.module.conv2 act-std: mean=3.778e-01
  layer model_3__forward_module.module.conv1 act-std: mean=5.378e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.397e-01
  layer model_2__forward_module.module.conv1 act-std: mean=7.324e-01
  layer model_2__forward_module.module.conv2 act-std: mean=4.007e-01
  layer model_1__forward_module.module.conv1 act-std: mean=7.087e-01
  layer model_1__forward_module.module.conv2 act-std: mean=3.859e-01
  layer model_0__forward_module.module.conv1 act-std: mean=7.190e-01
  layer model_0__forward_module.module.conv2 act-std: mean=4.573e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=9.281e-02
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.051e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=8.894e-02
  param model_0__forward_module.module.conv2.bias grad-norm: mean=1.354e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.229e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.473e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.026e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=1.335e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=1.010e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.085e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=9.073e-02
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.438e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.250e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.236e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.070e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.862e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.435e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.430e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=1.136e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=2.075e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.129e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.031e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=9.667e-02
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.368e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.531e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=2.145e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.276e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=3.445e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.596e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.294e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.240e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.399e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  2.07it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  2.05it/s][A

Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  2.07it/s][AEvaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  2.07it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  2.06it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  2.06it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.23it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.16it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.23it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.16it/s]
Epoch 16/32 - Train Loss: 32.200267 - Test Loss: 29.039297
Training epochs:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 16/32 [05:09<05:08, 19.31s/it]Training epochs:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 16/32 [05:09<05:08, 19.31s/it]
Epoch 17/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 17/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 17/32:   8%|â–Š         | 1/13 [00:01<00:16,  1.38s/it][A
Epoch 17/32:   8%|â–Š         | 1/13 [00:01<00:16,  1.39s/it][A

Epoch 17/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:15,  1.38s/it][AEpoch 17/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:15,  1.38s/it][A
Epoch 17/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:13,  1.38s/it][A
Epoch 17/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:13,  1.38s/it][A
Epoch 17/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:12,  1.38s/it][A
Epoch 17/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:12,  1.38s/it][A
Epoch 17/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:06<00:11,  1.38s/it][A
Epoch 17/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:06<00:11,  1.38s/it][A
Epoch 17/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:09,  1.38s/it][A
Epoch 17/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:09,  1.38s/it][A
Epoch 17/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:09<00:08,  1.38s/it][A
Epoch 17/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:09<00:08,  1.38s/it][A
Epoch 17/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:06,  1.38s/it][A
Epoch 17/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:06,  1.38s/it][A
Epoch 17/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:12<00:05,  1.38s/it][A
Epoch 17/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:12<00:05,  1.38s/it][A

Epoch 17/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:13<00:04,  1.38s/it][AEpoch 17/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:13<00:04,  1.38s/it][A

Epoch 17/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:15<00:02,  1.39s/it]Epoch 17/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:15<00:02,  1.38s/it][A[A
Epoch 17/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:16<00:01,  1.38s/it][A
Epoch 17/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:16<00:01,  1.38s/it][A

Epoch 17/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.28s/it][AEpoch 17/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.28s/it][AEpoch 17/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.36s/it]
Epoch 17/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.36s/it]

[Î²=2.0] Epoch 17 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=7.419e-01
  layer model_7__forward_module.module.conv2 act-std: mean=2.971e-01
  layer model_6__forward_module.module.conv1 act-std: mean=7.690e-01
  layer model_6__forward_module.module.conv2 act-std: mean=3.058e-01
  layer model_5__forward_module.module.conv1 act-std: mean=7.009e-01
  layer model_5__forward_module.module.conv2 act-std: mean=3.764e-01
  layer model_4__forward_module.module.conv1 act-std: mean=7.373e-01
  layer model_4__forward_module.module.conv2 act-std: mean=3.746e-01
  layer model_3__forward_module.module.conv1 act-std: mean=5.449e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.463e-01
  layer model_2__forward_module.module.conv1 act-std: mean=7.432e-01
  layer model_2__forward_module.module.conv2 act-std: mean=4.158e-01
  layer model_1__forward_module.module.conv1 act-std: mean=7.207e-01
  layer model_1__forward_module.module.conv2 act-std: mean=3.976e-01
  layer model_0__forward_module.module.conv1 act-std: mean=7.293e-01
  layer model_0__forward_module.module.conv2 act-std: mean=4.738e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=8.567e-02
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.022e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=8.432e-02
  param model_0__forward_module.module.conv2.bias grad-norm: mean=1.440e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.150e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.397e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.006e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=1.413e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=1.109e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.508e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=8.818e-02
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.988e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.466e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.169e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.047e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=2.394e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.453e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.710e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=1.207e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=2.312e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.273e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.458e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=1.029e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.886e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.956e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=3.426e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.345e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=3.816e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.604e-01

  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.321e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.243e-01Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.336e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  2.07it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  2.04it/s][A

Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  2.04it/s][AEvaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  2.03it/s][A

Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  2.01it/s][AEvaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  2.02it/s][A

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.18it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.12it/s]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.17it/s][AEpoch 17/32 - Train Loss: 32.086353 - Test Loss: 28.951057
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.12it/s]
Training epochs:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 17/32 [05:28<04:50, 19.38s/it]Training epochs:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 17/32 [05:28<04:50, 19.37s/it]
Epoch 18/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 18/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 18/32:   8%|â–Š         | 1/13 [00:01<00:16,  1.38s/it][A
Epoch 18/32:   8%|â–Š         | 1/13 [00:01<00:16,  1.38s/it][A
Epoch 18/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:15,  1.39s/it][A
Epoch 18/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:15,  1.39s/it][A

Epoch 18/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:13,  1.39s/it][AEpoch 18/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:13,  1.39s/it][A
Epoch 18/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:12,  1.39s/it][A
Epoch 18/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:12,  1.39s/it][A

Epoch 18/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:06<00:11,  1.39s/it][AEpoch 18/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:06<00:11,  1.39s/it][A
Epoch 18/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:09,  1.39s/it][A
Epoch 18/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:09,  1.39s/it][A

Epoch 18/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:09<00:08,  1.39s/it][AEpoch 18/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:09<00:08,  1.39s/it][A

Epoch 18/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:06,  1.39s/it][AEpoch 18/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:06,  1.39s/it][A
Epoch 18/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:12<00:05,  1.39s/it]
[AEpoch 18/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:12<00:05,  1.39s/it][A
Epoch 18/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:13<00:04,  1.39s/it][A
Epoch 18/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:13<00:04,  1.39s/it][A

Epoch 18/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:15<00:02,  1.39s/it]Epoch 18/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:15<00:02,  1.39s/it][A[A
Epoch 18/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:16<00:01,  1.39s/it][A
Epoch 18/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:16<00:01,  1.39s/it][A

Epoch 18/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.28s/it][AEpoch 18/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.28s/it]Epoch 18/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.36s/it][A
Epoch 18/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.36s/it]

[Î²=2.0] Epoch 18 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=7.476e-01
  layer model_7__forward_module.module.conv2 act-std: mean=2.947e-01
  layer model_6__forward_module.module.conv1 act-std: mean=7.771e-01
  layer model_6__forward_module.module.conv2 act-std: mean=3.037e-01
  layer model_5__forward_module.module.conv1 act-std: mean=7.240e-01
  layer model_5__forward_module.module.conv2 act-std: mean=3.732e-01
  layer model_4__forward_module.module.conv1 act-std: mean=7.494e-01
  layer model_4__forward_module.module.conv2 act-std: mean=3.734e-01
  layer model_3__forward_module.module.conv1 act-std: mean=5.520e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.544e-01
  layer model_2__forward_module.module.conv1 act-std: mean=7.537e-01
  layer model_2__forward_module.module.conv2 act-std: mean=4.291e-01
  layer model_1__forward_module.module.conv1 act-std: mean=7.316e-01
  layer model_1__forward_module.module.conv2 act-std: mean=4.090e-01
  layer model_0__forward_module.module.conv1 act-std: mean=7.397e-01
  layer model_0__forward_module.module.conv2 act-std: mean=4.912e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=7.920e-02
  param model_0__forward_module.module.conv1.bias grad-norm: mean=7.814e-03
  param model_0__forward_module.module.conv2.weight grad-norm: mean=8.170e-02
  param model_0__forward_module.module.conv2.bias grad-norm: mean=1.388e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.206e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.501e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=9.881e-02
  param model_1__forward_module.module.conv2.bias grad-norm: mean=1.651e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=1.076e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.511e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=8.523e-02
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.890e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.387e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.085e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=9.910e-02
  param model_3__forward_module.module.conv2.bias grad-norm: mean=2.322e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.412e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.788e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=1.218e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=2.206e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.267e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.475e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=1.102e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.655e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.807e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=2.772e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.330e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=3.360e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.781e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.872e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.242e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.383e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  2.01it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  2.01it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.98it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.98it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  2.00it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  2.00it/s][A

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.17it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.10it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.18it/s]
[AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.10it/s]
Epoch 18/32 - Train Loss: 31.994310 - Test Loss: 28.865379
Training epochs:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 18/32 [05:48<04:32, 19.45s/it]Training epochs:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 18/32 [05:48<04:32, 19.45s/it]

Epoch 19/32:   0%|          | 0/13 [00:00<?, ?it/s][AEpoch 19/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 19/32:   8%|â–Š         | 1/13 [00:01<00:16,  1.40s/it][AEpoch 19/32:   8%|â–Š         | 1/13 [00:01<00:16,  1.40s/it][A
Epoch 19/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:15,  1.40s/it][A
Epoch 19/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:15,  1.40s/it][A

Epoch 19/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.41s/it][AEpoch 19/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.41s/it][A
Epoch 19/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:12,  1.42s/it][A
Epoch 19/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:12,  1.42s/it][A

Epoch 19/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.41s/it][AEpoch 19/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.41s/it][A

Epoch 19/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:09,  1.41s/it][AEpoch 19/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:09,  1.41s/it][A
Epoch 19/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:09<00:08,  1.41s/it][A
Epoch 19/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:09<00:08,  1.41s/it][A
Epoch 19/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.41s/it][A
Epoch 19/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.41s/it][A
Epoch 19/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:12<00:05,  1.41s/it][A
Epoch 19/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:12<00:05,  1.41s/it][A
Epoch 19/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.40s/it][A
Epoch 19/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.40s/it][A

Epoch 19/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:15<00:02,  1.40s/it][AEpoch 19/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:15<00:02,  1.40s/it][A
Epoch 19/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:16<00:01,  1.40s/it][A
Epoch 19/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:16<00:01,  1.41s/it][A

Epoch 19/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.29s/it][AEpoch 19/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.38s/it]
Epoch 19/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.29s/it][A
[Î²=2.0] Epoch 19 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=7.522e-01
  layer model_7__forward_module.module.conv2 act-std: mean=2.935e-01
  layer model_6__forward_module.module.conv1 act-std: mean=7.830e-01
Epoch 19/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.38s/it]  layer model_6__forward_module.module.conv2 act-std: mean=2.993e-01

  layer model_5__forward_module.module.conv1 act-std: mean=7.482e-01
  layer model_5__forward_module.module.conv2 act-std: mean=3.722e-01
  layer model_4__forward_module.module.conv1 act-std: mean=7.621e-01
  layer model_4__forward_module.module.conv2 act-std: mean=3.765e-01
  layer model_3__forward_module.module.conv1 act-std: mean=5.578e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.620e-01
  layer model_2__forward_module.module.conv1 act-std: mean=7.635e-01
  layer model_2__forward_module.module.conv2 act-std: mean=4.399e-01
  layer model_1__forward_module.module.conv1 act-std: mean=7.423e-01
  layer model_1__forward_module.module.conv2 act-std: mean=4.199e-01
  layer model_0__forward_module.module.conv1 act-std: mean=7.502e-01
  layer model_0__forward_module.module.conv2 act-std: mean=5.079e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=8.416e-02
  param model_0__forward_module.module.conv1.bias grad-norm: mean=9.314e-03
  param model_0__forward_module.module.conv2.weight grad-norm: mean=7.571e-02
  param model_0__forward_module.module.conv2.bias grad-norm: mean=1.442e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.096e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.153e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=9.337e-02
  param model_1__forward_module.module.conv2.bias grad-norm: mean=1.507e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=1.013e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.165e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=8.307e-02
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.781e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.288e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.666e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=9.674e-02
  param model_3__forward_module.module.conv2.bias grad-norm: mean=2.250e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.300e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.452e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=1.171e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.898e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.231e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.098e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=1.105e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.411e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.443e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=2.096e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.256e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=2.589e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.703e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.720e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.196e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=3.836e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  2.01it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.99it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  2.02it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.98it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  2.02it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.98it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.20it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.13it/s]
Training epochs:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 19/32 [06:08<04:14, 19.56s/it]
Epoch 20/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.16it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.09it/s]
Epoch 19/32 - Train Loss: 31.914241 - Test Loss: 28.779634
Training epochs:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 19/32 [06:08<04:14, 19.57s/it]
Epoch 20/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 20/32:   8%|â–Š         | 1/13 [00:01<00:16,  1.41s/it][AEpoch 20/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.45s/it][A
Epoch 20/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:15,  1.41s/it][A
Epoch 20/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:15,  1.43s/it][A
Epoch 20/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.42s/it][A
Epoch 20/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.41s/it][A
Epoch 20/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:12,  1.41s/it][A
Epoch 20/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:12,  1.41s/it][A
Epoch 20/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.41s/it][A
Epoch 20/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.41s/it][A
Epoch 20/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:09,  1.40s/it][A
Epoch 20/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:09,  1.41s/it][A
Epoch 20/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:09<00:08,  1.40s/it][A
Epoch 20/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:09<00:08,  1.40s/it][A

Epoch 20/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.40s/it][AEpoch 20/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.40s/it][A

Epoch 20/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:12<00:05,  1.41s/it][AEpoch 20/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:12<00:05,  1.41s/it][A
Epoch 20/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.40s/it][A
Epoch 20/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.41s/it][A
Epoch 20/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:15<00:02,  1.40s/it][A
Epoch 20/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:15<00:02,  1.41s/it][A

Epoch 20/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:16<00:01,  1.41s/it][AEpoch 20/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:16<00:01,  1.41s/it][A
Epoch 20/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.30s/it][AEpoch 20/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.38s/it]

[Î²=2.0] Epoch 20 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=7.568e-01
  layer model_7__forward_module.module.conv2 act-std: mean=2.928e-01
  layer model_6__forward_module.module.conv1 act-std: mean=7.902e-01
  layer model_6__forward_module.module.conv2 act-std: mean=2.965e-01
  layer model_5__forward_module.module.conv1 act-std: mean=7.732e-01
  layer model_5__forward_module.module.conv2 act-std: mean=3.720e-01
  layer model_4__forward_module.module.conv1 act-std: mean=7.743e-01
  layer model_4__forward_module.module.conv2 act-std: mean=3.796e-01
  layer model_3__forward_module.module.conv1 act-std: mean=5.626e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.699e-01
  layer model_2__forward_module.module.conv1 act-std: mean=7.730e-01
  layer model_2__forward_module.module.conv2 act-std: mean=4.485e-01
  layer model_1__forward_module.module.conv1 act-std: mean=7.527e-01
  layer model_1__forward_module.module.conv2 act-std: mean=4.306e-01
  layer model_0__forward_module.module.conv1 act-std: mean=7.594e-01
  layer model_0__forward_module.module.conv2 act-std: mean=5.199e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=8.037e-02
  param model_0__forward_module.module.conv1.bias grad-norm: mean=9.955e-03
  param model_0__forward_module.module.conv2.weight grad-norm: mean=7.815e-02
  param model_0__forward_module.module.conv2.bias grad-norm: mean=1.509e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.089e-01

  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.418e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=9.535e-02
  param model_1__forward_module.module.conv2.bias grad-norm: mean=1.675e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=1.091e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.397e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=8.461e-02
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.841e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.571e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.646e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=9.800e-02
Epoch 20/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.30s/it]  param model_3__forward_module.module.conv2.bias grad-norm: mean=2.526e-02[A
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.506e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=2.399e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=1.183e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=2.258e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.395e-01
Epoch 20/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.38s/it]  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.708e-02

  param model_5__forward_module.module.conv2.weight grad-norm: mean=1.169e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.959e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.679e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=2.588e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.321e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=2.463e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.875e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=3.192e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.204e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=3.865e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.97it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.96it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.99it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.97it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.98it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.98it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.13it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.07it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.13it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.07it/s]
Epoch 20/32 - Train Loss: 31.805806 - Test Loss: 28.696774
Training epochs:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 20/32 [06:28<03:55, 19.66s/it]Training epochs:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 20/32 [06:28<03:55, 19.66s/it]
Epoch 21/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 21/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 21/32:   8%|â–Š         | 1/13 [00:01<00:16,  1.41s/it][A
Epoch 21/32:   8%|â–Š         | 1/13 [00:01<00:16,  1.41s/it][A
Epoch 21/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:15,  1.41s/it][A
Epoch 21/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:15,  1.41s/it][A

Epoch 21/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.41s/it][AEpoch 21/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.41s/it][A
Epoch 21/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:12,  1.41s/it][A
Epoch 21/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:12,  1.41s/it][A
Epoch 21/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.41s/it][A
Epoch 21/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.41s/it][A

Epoch 21/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:09,  1.41s/it]Epoch 21/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:09,  1.41s/it][A[A
Epoch 21/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:09<00:08,  1.41s/it][A
Epoch 21/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:09<00:08,  1.41s/it][A

Epoch 21/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.41s/it][AEpoch 21/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.41s/it][A
Epoch 21/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:12<00:05,  1.42s/it][A
Epoch 21/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:12<00:05,  1.42s/it][A
Epoch 21/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.41s/it][A
Epoch 21/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.41s/it][A

Epoch 21/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:15<00:02,  1.41s/it][AEpoch 21/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:15<00:02,  1.41s/it][A

Epoch 21/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:16<00:01,  1.41s/it][AEpoch 21/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:16<00:01,  1.41s/it][A

Epoch 21/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.29s/it][AEpoch 21/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.29s/it][AEpoch 21/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.38s/it]
Epoch 21/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.38s/it]

[Î²=2.0] Epoch 21 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=7.624e-01
  layer model_7__forward_module.module.conv2 act-std: mean=2.931e-01
  layer model_6__forward_module.module.conv1 act-std: mean=7.975e-01
  layer model_6__forward_module.module.conv2 act-std: mean=2.944e-01
  layer model_5__forward_module.module.conv1 act-std: mean=8.003e-01
  layer model_5__forward_module.module.conv2 act-std: mean=3.722e-01
  layer model_4__forward_module.module.conv1 act-std: mean=7.856e-01
  layer model_4__forward_module.module.conv2 act-std: mean=3.846e-01
  layer model_3__forward_module.module.conv1 act-std: mean=5.670e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.787e-01
  layer model_2__forward_module.module.conv1 act-std: mean=7.826e-01
  layer model_2__forward_module.module.conv2 act-std: mean=4.568e-01
  layer model_1__forward_module.module.conv1 act-std: mean=7.630e-01
  layer model_1__forward_module.module.conv2 act-std: mean=4.414e-01
  layer model_0__forward_module.module.conv1 act-std: mean=7.703e-01
  layer model_0__forward_module.module.conv2 act-std: mean=5.367e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=7.950e-02
  param model_0__forward_module.module.conv1.bias grad-norm: mean=9.708e-03
  param model_0__forward_module.module.conv2.weight grad-norm: mean=7.515e-02
  param model_0__forward_module.module.conv2.bias grad-norm: mean=1.559e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.038e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.404e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=9.187e-02
  param model_1__forward_module.module.conv2.bias grad-norm: mean=1.521e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=1.088e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.351e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=8.748e-02
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.956e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.491e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.472e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=9.792e-02
  param model_3__forward_module.module.conv2.bias grad-norm: mean=2.488e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.320e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.972e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=1.112e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.910e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.423e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.881e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=1.168e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=2.017e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.577e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=2.308e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.323e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=2.217e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.521e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.240e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.135e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=3.160e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.99it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.94it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  2.01it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.97it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.99it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.98it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.18it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.10it/s]
Training epochs:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 21/32 [06:48<03:36, 19.72s/it]
Epoch 22/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.15it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.08it/s]
Epoch 21/32 - Train Loss: 31.710872 - Test Loss: 28.616784
Training epochs:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 21/32 [06:48<03:37, 19.73s/it]
Epoch 22/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 22/32:   8%|â–Š         | 1/13 [00:01<00:16,  1.39s/it][A
Epoch 22/32:   8%|â–Š         | 1/13 [00:01<00:16,  1.42s/it][A

Epoch 22/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:15,  1.42s/it][AEpoch 22/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:15,  1.41s/it][A
Epoch 22/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.41s/it][A
Epoch 22/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.41s/it][A
Epoch 22/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:12,  1.41s/it][A
Epoch 22/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:12,  1.41s/it][A

Epoch 22/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.40s/it][AEpoch 22/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.41s/it][A

Epoch 22/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:09,  1.40s/it][AEpoch 22/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:09,  1.40s/it][A

Epoch 22/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:09<00:08,  1.40s/it][AEpoch 22/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:09<00:08,  1.40s/it][A
Epoch 22/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.40s/it]
[AEpoch 22/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.40s/it][A

Epoch 22/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:12<00:05,  1.40s/it][AEpoch 22/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:12<00:05,  1.40s/it][A
Epoch 22/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.40s/it][A
Epoch 22/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.40s/it][A
Epoch 22/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:15<00:02,  1.40s/it][A
Epoch 22/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:15<00:02,  1.40s/it][A

Epoch 22/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:16<00:01,  1.40s/it][AEpoch 22/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:16<00:01,  1.40s/it][A
Epoch 22/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.29s/it][AEpoch 22/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.38s/it]

Epoch 22/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.29s/it][AEpoch 22/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.37s/it]

[Î²=2.0] Epoch 22 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=7.689e-01
  layer model_7__forward_module.module.conv2 act-std: mean=2.925e-01
  layer model_6__forward_module.module.conv1 act-std: mean=8.070e-01
  layer model_6__forward_module.module.conv2 act-std: mean=2.933e-01
  layer model_5__forward_module.module.conv1 act-std: mean=8.295e-01
  layer model_5__forward_module.module.conv2 act-std: mean=3.737e-01
  layer model_4__forward_module.module.conv1 act-std: mean=7.958e-01
  layer model_4__forward_module.module.conv2 act-std: mean=3.896e-01
  layer model_3__forward_module.module.conv1 act-std: mean=5.704e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.853e-01
  layer model_2__forward_module.module.conv1 act-std: mean=7.917e-01
  layer model_2__forward_module.module.conv2 act-std: mean=4.650e-01
  layer model_1__forward_module.module.conv1 act-std: mean=7.735e-01
  layer model_1__forward_module.module.conv2 act-std: mean=4.542e-01
  layer model_0__forward_module.module.conv1 act-std: mean=7.803e-01
  layer model_0__forward_module.module.conv2 act-std: mean=5.501e-01

  param model_0__forward_module.module.conv1.weight grad-norm: mean=7.552e-02
  param model_0__forward_module.module.conv1.bias grad-norm: mean=7.425e-03Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  param model_0__forward_module.module.conv2.weight grad-norm: mean=7.194e-02
  param model_0__forward_module.module.conv2.bias grad-norm: mean=1.355e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=9.850e-02
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.177e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=8.761e-02
  param model_1__forward_module.module.conv2.bias grad-norm: mean=1.493e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=1.021e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.186e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=8.529e-02
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.616e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.491e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.651e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=9.878e-02
  param model_3__forward_module.module.conv2.bias grad-norm: mean=2.266e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.350e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.949e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=1.069e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.978e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.352e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.732e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=1.130e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.749e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.881e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=3.089e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.412e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=2.646e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.525e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.968e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.104e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=2.939e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  2.00it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.96it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.99it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.95it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  2.00it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.97it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.16it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.09it/s]
Training epochs:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 22/32 [07:07<03:17, 19.75s/it]
Epoch 23/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.14it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.07it/s]
Epoch 22/32 - Train Loss: 31.602062 - Test Loss: 28.539069
Training epochs:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 22/32 [07:07<03:17, 19.76s/it]
Epoch 23/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 23/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.43s/it][A
Epoch 23/32:   8%|â–Š         | 1/13 [00:01<00:16,  1.40s/it][A
Epoch 23/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:15,  1.41s/it][A
Epoch 23/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:15,  1.40s/it][A

Epoch 23/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:13,  1.40s/it][AEpoch 23/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.41s/it][A
Epoch 23/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:12,  1.40s/it][A
Epoch 23/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:12,  1.40s/it][A

Epoch 23/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.40s/it][AEpoch 23/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.40s/it][A

Epoch 23/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:09,  1.40s/it][AEpoch 23/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:09,  1.40s/it][A
Epoch 23/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:09<00:08,  1.40s/it][A
Epoch 23/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:09<00:08,  1.40s/it][A

Epoch 23/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.40s/it][AEpoch 23/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.40s/it][A
Epoch 23/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:12<00:05,  1.40s/it][A
Epoch 23/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:12<00:05,  1.40s/it][A

Epoch 23/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.40s/it][AEpoch 23/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.40s/it][A
Epoch 23/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:15<00:02,  1.40s/it][A
Epoch 23/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:15<00:02,  1.40s/it][A
Epoch 23/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:16<00:01,  1.40s/it]
[AEpoch 23/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:16<00:01,  1.40s/it][A
Epoch 23/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.29s/it][AEpoch 23/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.37s/it]

[Î²=2.0] Epoch 23 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=7.760e-01
  layer model_7__forward_module.module.conv2 act-std: mean=2.916e-01
  layer model_6__forward_module.module.conv1 act-std: mean=8.178e-01
  layer model_6__forward_module.module.conv2 act-std: mean=2.894e-01
  layer model_5__forward_module.module.conv1 act-std: mean=8.578e-01
  layer model_5__forward_module.module.conv2 act-std: mean=3.765e-01
  layer model_4__forward_module.module.conv1 act-std: mean=8.046e-01

  layer model_4__forward_module.module.conv2 act-std: mean=3.973e-01
  layer model_3__forward_module.module.conv1 act-std: mean=5.741e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.923e-01
  layer model_2__forward_module.module.conv1 act-std: mean=8.006e-01
  layer model_2__forward_module.module.conv2 act-std: mean=4.737e-01
  layer model_1__forward_module.module.conv1 act-std: mean=7.835e-01
  layer model_1__forward_module.module.conv2 act-std: mean=4.659e-01Epoch 23/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.29s/it]
[A  layer model_0__forward_module.module.conv1 act-std: mean=7.897e-01
  layer model_0__forward_module.module.conv2 act-std: mean=5.624e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=8.053e-02
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.141e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=7.104e-02
  param model_0__forward_module.module.conv2.bias grad-norm: mean=1.340e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.055e-01Epoch 23/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.37s/it]

  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.556e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=8.699e-02
  param model_1__forward_module.module.conv2.bias grad-norm: mean=1.574e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=1.176e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.701e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=8.955e-02
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.823e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.498e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.554e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.002e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=2.214e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.732e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=3.155e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=1.135e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=2.520e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.398e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.913e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=1.097e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.880e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.134e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=6.226e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.881e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=3.967e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.702e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.262e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.121e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=2.803e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  2.03it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  2.01it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  2.00it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.98it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  2.00it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.99it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.16it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.10it/s]

Training epochs:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 23/32 [07:27<02:57, 19.76s/it]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.15it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.09it/s]
Epoch 23/32 - Train Loss: 31.545182 - Test Loss: 28.465461

Epoch 24/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 23/32 [07:27<02:57, 19.76s/it]
Epoch 24/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 24/32:   8%|â–Š         | 1/13 [00:01<00:16,  1.40s/it][A
Epoch 24/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.42s/it][A

Epoch 24/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:15,  1.41s/it][AEpoch 24/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:15,  1.41s/it][A

Epoch 24/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.41s/it][AEpoch 24/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.40s/it][A
Epoch 24/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:12,  1.41s/it][A
Epoch 24/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:12,  1.41s/it][A

Epoch 24/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.41s/it]Epoch 24/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.41s/it][A[A
Epoch 24/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:09,  1.41s/it][A
Epoch 24/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:09,  1.41s/it][A

Epoch 24/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:09<00:08,  1.41s/it][AEpoch 24/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:09<00:08,  1.41s/it][A

Epoch 24/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.40s/it][AEpoch 24/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.40s/it][A

Epoch 24/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:12<00:05,  1.40s/it][AEpoch 24/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:12<00:05,  1.40s/it][A

Epoch 24/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.40s/it][AEpoch 24/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.40s/it][A
Epoch 24/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:15<00:02,  1.41s/it][A
Epoch 24/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:15<00:02,  1.41s/it][A

Epoch 24/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:16<00:01,  1.41s/it][AEpoch 24/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:16<00:01,  1.41s/it][A
Epoch 24/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.29s/it][AEpoch 24/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.38s/it]

[Î²=2.0] Epoch 24 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=7.843e-01
  layer model_7__forward_module.module.conv2 act-std: mean=2.931e-01
  layer model_6__forward_module.module.conv1 act-std: mean=8.299e-01
  layer model_6__forward_module.module.conv2 act-std: mean=2.919e-01
  layer model_5__forward_module.module.conv1 act-std: mean=8.836e-01
  layer model_5__forward_module.module.conv2 act-std: mean=3.802e-01
  layer model_4__forward_module.module.conv1 act-std: mean=8.128e-01
  layer model_4__forward_module.module.conv2 act-std: mean=4.055e-01
  layer model_3__forward_module.module.conv1 act-std: mean=5.781e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.005e-01

  layer model_2__forward_module.module.conv1 act-std: mean=8.072e-01
  layer model_2__forward_module.module.conv2 act-std: mean=4.797e-01
  layer model_1__forward_module.module.conv1 act-std: mean=7.932e-01
  layer model_1__forward_module.module.conv2 act-std: mean=4.782e-01
  layer model_0__forward_module.module.conv1 act-std: mean=7.991e-01
Epoch 24/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.29s/it]  layer model_0__forward_module.module.conv2 act-std: mean=5.755e-01[A
  param model_0__forward_module.module.conv1.weight grad-norm: mean=6.881e-02
  param model_0__forward_module.module.conv1.bias grad-norm: mean=7.577e-03
  param model_0__forward_module.module.conv2.weight grad-norm: mean=6.792e-02
  param model_0__forward_module.module.conv2.bias grad-norm: mean=1.209e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=8.544e-02
  param model_1__forward_module.module.conv1.bias grad-norm: mean=8.773e-03
  param model_1__forward_module.module.conv2.weight grad-norm: mean=8.226e-02
Epoch 24/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.38s/it]  param model_1__forward_module.module.conv2.bias grad-norm: mean=1.395e-02

  param model_2__forward_module.module.conv1.weight grad-norm: mean=1.080e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.404e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=8.784e-02
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.725e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.199e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.773e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=9.858e-02
  param model_3__forward_module.module.conv2.bias grad-norm: mean=2.071e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.391e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=2.269e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=1.042e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.794e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.260e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.535e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=1.055e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.771e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.836e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=2.571e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.578e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=2.422e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.580e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.141e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.125e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=2.850e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A

Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  2.02it/s][AEvaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  2.02it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  2.01it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.99it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  2.03it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  2.01it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.21it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.13it/s]
Training epochs:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 24/32 [07:47<02:38, 19.77s/it]
Epoch 25/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.17it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.11it/s]
Epoch 24/32 - Train Loss: 31.456294 - Test Loss: 28.387535
Training epochs:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 24/32 [07:47<02:38, 19.78s/it]
Epoch 25/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 25/32:   8%|â–Š         | 1/13 [00:01<00:16,  1.39s/it][AEpoch 25/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.42s/it][A

Epoch 25/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:15,  1.41s/it][AEpoch 25/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:15,  1.42s/it][A
Epoch 25/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.40s/it][A
Epoch 25/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.41s/it][A

Epoch 25/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:12,  1.41s/it]Epoch 25/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:12,  1.40s/it][A[A
Epoch 25/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.41s/it][A
Epoch 25/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.41s/it][A

Epoch 25/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:09,  1.40s/it][AEpoch 25/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:09,  1.40s/it][A
Epoch 25/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:09<00:08,  1.40s/it][A
Epoch 25/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:09<00:08,  1.40s/it][A

Epoch 25/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:06,  1.40s/it][AEpoch 25/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:06,  1.40s/it][A

Epoch 25/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:12<00:05,  1.40s/it]Epoch 25/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:12<00:05,  1.40s/it][A[A
Epoch 25/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.40s/it][A
Epoch 25/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.40s/it][A

Epoch 25/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:15<00:02,  1.40s/it][AEpoch 25/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:15<00:02,  1.40s/it][A
Epoch 25/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:16<00:01,  1.40s/it][A
Epoch 25/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:16<00:01,  1.40s/it][A
Epoch 25/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.29s/it][AEpoch 25/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.38s/it]

Epoch 25/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.29s/it][AEpoch 25/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.37s/it]

[Î²=2.0] Epoch 25 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=7.930e-01
  layer model_7__forward_module.module.conv2 act-std: mean=2.934e-01
  layer model_6__forward_module.module.conv1 act-std: mean=8.451e-01
  layer model_6__forward_module.module.conv2 act-std: mean=2.935e-01
  layer model_5__forward_module.module.conv1 act-std: mean=9.057e-01
  layer model_5__forward_module.module.conv2 act-std: mean=3.851e-01
  layer model_4__forward_module.module.conv1 act-std: mean=8.221e-01
  layer model_4__forward_module.module.conv2 act-std: mean=4.159e-01
  layer model_3__forward_module.module.conv1 act-std: mean=5.825e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.072e-01
  layer model_2__forward_module.module.conv1 act-std: mean=8.136e-01
  layer model_2__forward_module.module.conv2 act-std: mean=4.872e-01
  layer model_1__forward_module.module.conv1 act-std: mean=8.023e-01
  layer model_1__forward_module.module.conv2 act-std: mean=4.873e-01
  layer model_0__forward_module.module.conv1 act-std: mean=8.081e-01
  layer model_0__forward_module.module.conv2 act-std: mean=5.875e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=6.379e-02
  param model_0__forward_module.module.conv1.bias grad-norm: mean=7.332e-03
  param model_0__forward_module.module.conv2.weight grad-norm: mean=7.112e-02
  param model_0__forward_module.module.conv2.bias grad-norm: mean=1.469e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=8.614e-02
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.172e-02

  param model_1__forward_module.module.conv2.weight grad-norm: mean=8.353e-02
  param model_1__forward_module.module.conv2.bias grad-norm: mean=1.529e-02Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  param model_2__forward_module.module.conv1.weight grad-norm: mean=9.811e-02
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.178e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=8.428e-02
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.843e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.299e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.112e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=9.907e-02
  param model_3__forward_module.module.conv2.bias grad-norm: mean=2.043e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.435e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=2.502e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=1.065e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.943e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.176e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.586e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=1.007e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.752e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=2.269e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=3.385e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.757e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=2.456e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.733e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.506e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.163e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=2.758e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  2.00it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.98it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  2.00it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  2.00it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  2.01it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  2.00it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.17it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.11it/s]
Training epochs:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 25/32 [08:07<02:18, 19.78s/it]
Epoch 26/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.15it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.09it/s]
Epoch 25/32 - Train Loss: 31.366467 - Test Loss: 28.308426
Training epochs:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 25/32 [08:07<02:18, 19.78s/it]
Epoch 26/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 26/32:   8%|â–Š         | 1/13 [00:01<00:16,  1.41s/it][A
Epoch 26/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.43s/it][A

Epoch 26/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:15,  1.41s/it][AEpoch 26/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:15,  1.42s/it][A
Epoch 26/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.41s/it][A
Epoch 26/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.41s/it][A
Epoch 26/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:12,  1.41s/it][A
Epoch 26/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:12,  1.40s/it][A

Epoch 26/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.41s/it][AEpoch 26/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.40s/it][A
Epoch 26/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:09,  1.41s/it][A
Epoch 26/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:09,  1.41s/it][A
Epoch 26/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:09<00:08,  1.40s/it][A
Epoch 26/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:09<00:08,  1.40s/it][A
Epoch 26/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.40s/it][A
Epoch 26/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.40s/it][A
Epoch 26/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:12<00:05,  1.40s/it][A
Epoch 26/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:12<00:05,  1.40s/it][A

Epoch 26/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.40s/it][AEpoch 26/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.40s/it][A
Epoch 26/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:15<00:02,  1.40s/it][A
Epoch 26/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:15<00:02,  1.40s/it][A
Epoch 26/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:16<00:01,  1.40s/it][A
Epoch 26/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:16<00:01,  1.40s/it][A
Epoch 26/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.29s/it][AEpoch 26/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.38s/it]

[Î²=2.0] Epoch 26 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=8.015e-01
  layer model_7__forward_module.module.conv2 act-std: mean=2.955e-01
  layer model_6__forward_module.module.conv1 act-std: mean=8.633e-01
  layer model_6__forward_module.module.conv2 act-std: mean=2.965e-01
  layer model_5__forward_module.module.conv1 act-std: mean=9.239e-01
  layer model_5__forward_module.module.conv2 act-std: mean=3.919e-01
  layer model_4__forward_module.module.conv1 act-std: mean=8.328e-01
  layer model_4__forward_module.module.conv2 act-std: mean=4.308e-01
  layer model_3__forward_module.module.conv1 act-std: mean=5.871e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.139e-01
  layer model_2__forward_module.module.conv1 act-std: mean=8.187e-01
  layer model_2__forward_module.module.conv2 act-std: mean=4.946e-01
  layer model_1__forward_module.module.conv1 act-std: mean=8.113e-01
  layer model_1__forward_module.module.conv2 act-std: mean=4.969e-01
  layer model_0__forward_module.module.conv1 act-std: mean=8.165e-01
  layer model_0__forward_module.module.conv2 act-std: mean=5.995e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=6.532e-02

  param model_0__forward_module.module.conv1.bias grad-norm: mean=9.355e-03
  param model_0__forward_module.module.conv2.weight grad-norm: mean=7.778e-02
  param model_0__forward_module.module.conv2.bias grad-norm: mean=1.673e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=8.490e-02
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.343e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=8.687e-02Epoch 26/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.29s/it]
[A  param model_1__forward_module.module.conv2.bias grad-norm: mean=1.740e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=1.189e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.908e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=8.888e-02
  param model_2__forward_module.module.conv2.bias grad-norm: mean=2.196e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.382e-01
Epoch 26/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.38s/it]  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.558e-02

  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.038e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=2.308e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.552e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=2.847e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=1.089e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=2.058e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.127e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.549e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=9.335e-02
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.811e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=2.340e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=3.258e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.927e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=2.761e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.796e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.321e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.222e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=2.675e-02


Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][AEvaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  2.04it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.98it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  2.03it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  2.00it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  2.04it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  2.01it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.19it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.13it/s]
Training epochs:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 26/32 [08:27<01:58, 19.78s/it]
Epoch 27/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.17it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.10it/s]
Epoch 26/32 - Train Loss: 31.284791 - Test Loss: 28.227410
Training epochs:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 26/32 [08:27<01:58, 19.79s/it]
Epoch 27/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 27/32:   8%|â–Š         | 1/13 [00:01<00:16,  1.39s/it][A
Epoch 27/32:   8%|â–Š         | 1/13 [00:01<00:16,  1.41s/it][A
Epoch 27/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:15,  1.40s/it][A
Epoch 27/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:15,  1.39s/it][A

Epoch 27/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.40s/it][AEpoch 27/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:13,  1.40s/it][A
Epoch 27/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:12,  1.40s/it][A
Epoch 27/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:12,  1.41s/it][A

Epoch 27/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.40s/it][AEpoch 27/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.41s/it][A
Epoch 27/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:09,  1.41s/it][A
Epoch 27/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:09,  1.41s/it][A
Epoch 27/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:09<00:08,  1.40s/it]
[AEpoch 27/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:09<00:08,  1.40s/it][A
Epoch 27/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.40s/it][A
Epoch 27/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.40s/it][A

Epoch 27/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:12<00:05,  1.41s/it][AEpoch 27/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:12<00:05,  1.41s/it][A
Epoch 27/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.40s/it][A
Epoch 27/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.40s/it][A

Epoch 27/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:15<00:02,  1.40s/it][AEpoch 27/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:15<00:02,  1.40s/it][A
Epoch 27/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:16<00:01,  1.41s/it][A
Epoch 27/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:16<00:01,  1.41s/it][A

Epoch 27/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.29s/it][AEpoch 27/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.29s/it][AEpoch 27/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.38s/it]
Epoch 27/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.38s/it]

[Î²=2.0] Epoch 27 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=8.119e-01
  layer model_7__forward_module.module.conv2 act-std: mean=2.981e-01
  layer model_6__forward_module.module.conv1 act-std: mean=8.837e-01
  layer model_6__forward_module.module.conv2 act-std: mean=3.039e-01
  layer model_5__forward_module.module.conv1 act-std: mean=9.387e-01
  layer model_5__forward_module.module.conv2 act-std: mean=3.985e-01
  layer model_4__forward_module.module.conv1 act-std: mean=8.445e-01
  layer model_4__forward_module.module.conv2 act-std: mean=4.445e-01
  layer model_3__forward_module.module.conv1 act-std: mean=5.923e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.214e-01
  layer model_2__forward_module.module.conv1 act-std: mean=8.224e-01
  layer model_2__forward_module.module.conv2 act-std: mean=4.994e-01
  layer model_1__forward_module.module.conv1 act-std: mean=8.203e-01
  layer model_1__forward_module.module.conv2 act-std: mean=5.071e-01
  layer model_0__forward_module.module.conv1 act-std: mean=8.247e-01
  layer model_0__forward_module.module.conv2 act-std: mean=6.121e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=7.405e-02
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.294e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=7.587e-02
  param model_0__forward_module.module.conv2.bias grad-norm: mean=1.822e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=9.546e-02
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.614e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=8.353e-02
  param model_1__forward_module.module.conv2.bias grad-norm: mean=1.996e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=1.060e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.550e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=8.833e-02
  param model_2__forward_module.module.conv2.bias grad-norm: mean=2.048e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.696e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=3.163e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.067e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=2.630e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.410e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=2.633e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=1.105e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=2.128e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.367e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=2.296e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=9.931e-02
  param model_5__forward_module.module.conv2.bias grad-norm: mean=2.159e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.284e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=5.875e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=2.387e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=3.819e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=2.252e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=3.257e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.355e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=3.260e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  2.02it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.99it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.97it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.96it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.99it/s]
[AEvaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  2.00it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.17it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.09it/s]
Epoch 27/32 - Train Loss: 31.189334 - Test Loss: 28.148975

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.15it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.09it/s]
Training epochs:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 27/32 [08:46<01:38, 19.79s/it]Training epochs:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 27/32 [08:46<01:38, 19.80s/it]
Epoch 28/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 28/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 28/32:   8%|â–Š         | 1/13 [00:01<00:16,  1.41s/it][A
Epoch 28/32:   8%|â–Š         | 1/13 [00:01<00:16,  1.41s/it][A
Epoch 28/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:15,  1.41s/it][A
Epoch 28/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:15,  1.41s/it][A
Epoch 28/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.41s/it][A
Epoch 28/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.41s/it][A

Epoch 28/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:12,  1.41s/it][AEpoch 28/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:12,  1.41s/it][A
Epoch 28/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.40s/it][A
Epoch 28/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.40s/it][A

Epoch 28/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:09,  1.40s/it][AEpoch 28/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:09,  1.40s/it][A
Epoch 28/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:09<00:08,  1.40s/it][A
Epoch 28/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:09<00:08,  1.40s/it][A
Epoch 28/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.40s/it][A
Epoch 28/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.40s/it][A

Epoch 28/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:12<00:05,  1.40s/it][AEpoch 28/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:12<00:05,  1.40s/it][A
Epoch 28/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.40s/it][A
Epoch 28/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.40s/it][A
Epoch 28/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:15<00:02,  1.41s/it][A
Epoch 28/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:15<00:02,  1.41s/it][A
Epoch 28/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:16<00:01,  1.41s/it][A
Epoch 28/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:16<00:01,  1.41s/it][A
Epoch 28/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.30s/it][A
Epoch 28/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.38s/it]
Epoch 28/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.30s/it][AEpoch 28/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.38s/it]

[Î²=2.0] Epoch 28 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=8.228e-01
  layer model_7__forward_module.module.conv2 act-std: mean=3.034e-01
  layer model_6__forward_module.module.conv1 act-std: mean=9.047e-01
  layer model_6__forward_module.module.conv2 act-std: mean=3.103e-01
  layer model_5__forward_module.module.conv1 act-std: mean=9.513e-01
  layer model_5__forward_module.module.conv2 act-std: mean=4.065e-01
  layer model_4__forward_module.module.conv1 act-std: mean=8.562e-01
  layer model_4__forward_module.module.conv2 act-std: mean=4.565e-01
  layer model_3__forward_module.module.conv1 act-std: mean=5.979e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.291e-01
  layer model_2__forward_module.module.conv1 act-std: mean=8.266e-01
  layer model_2__forward_module.module.conv2 act-std: mean=5.088e-01
  layer model_1__forward_module.module.conv1 act-std: mean=8.283e-01
  layer model_1__forward_module.module.conv2 act-std: mean=5.152e-01
  layer model_0__forward_module.module.conv1 act-std: mean=8.324e-01
  layer model_0__forward_module.module.conv2 act-std: mean=6.251e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=8.485e-02
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.679e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=7.347e-02
  param model_0__forward_module.module.conv2.bias grad-norm: mean=1.511e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=9.958e-02
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.850e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=8.312e-02
  param model_1__forward_module.module.conv2.bias grad-norm: mean=1.693e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=1.039e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.587e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=8.657e-02
  param model_2__forward_module.module.conv2.bias grad-norm: mean=2.127e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.456e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.688e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.098e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=2.423e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.342e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=4.947e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=1.416e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.449e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.344e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=2.306e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=9.963e-02
  param model_5__forward_module.module.conv2.bias grad-norm: mean=2.129e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=4.435e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=8.679e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=3.238e-01

  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.685e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=2.010e-01Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.000e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.405e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=2.735e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  2.00it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.98it/s][A

Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  2.00it/s][AEvaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:00,  2.00it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  2.02it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  2.01it/s][A

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.18it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.18it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.11it/s]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.11it/s]
Epoch 28/32 - Train Loss: 31.094915 - Test Loss: 28.074148
Training epochs:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 28/32 [09:06<01:19, 19.80s/it]Training epochs:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 28/32 [09:06<01:19, 19.81s/it]
Epoch 29/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 29/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 29/32:   8%|â–Š         | 1/13 [00:01<00:16,  1.41s/it][A
Epoch 29/32:   8%|â–Š         | 1/13 [00:01<00:16,  1.41s/it][A

Epoch 29/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:15,  1.40s/it][AEpoch 29/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:15,  1.40s/it][A
Epoch 29/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.40s/it][A
Epoch 29/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.40s/it][A
Epoch 29/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:12,  1.40s/it][A
Epoch 29/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:12,  1.40s/it][A
Epoch 29/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.41s/it][A
Epoch 29/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.41s/it][A
Epoch 29/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:09,  1.41s/it][A
Epoch 29/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:09,  1.41s/it][A
Epoch 29/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:09<00:08,  1.41s/it][A
Epoch 29/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:09<00:08,  1.41s/it][A
Epoch 29/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.41s/it][A
Epoch 29/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.41s/it][A

Epoch 29/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:12<00:05,  1.41s/it][AEpoch 29/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:12<00:05,  1.41s/it][A
Epoch 29/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.41s/it][A
Epoch 29/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.41s/it][A
Epoch 29/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:15<00:02,  1.41s/it][A
Epoch 29/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:15<00:02,  1.41s/it][A
Epoch 29/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:16<00:01,  1.41s/it][A
Epoch 29/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:16<00:01,  1.41s/it][A

Epoch 29/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.30s/it][AEpoch 29/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.30s/it][AEpoch 29/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.38s/it]
Epoch 29/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.38s/it]

[Î²=2.0] Epoch 29 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=8.351e-01
  layer model_7__forward_module.module.conv2 act-std: mean=3.084e-01
  layer model_6__forward_module.module.conv1 act-std: mean=9.234e-01
  layer model_6__forward_module.module.conv2 act-std: mean=3.146e-01
  layer model_5__forward_module.module.conv1 act-std: mean=9.624e-01
  layer model_5__forward_module.module.conv2 act-std: mean=4.158e-01
  layer model_4__forward_module.module.conv1 act-std: mean=8.657e-01
  layer model_4__forward_module.module.conv2 act-std: mean=4.654e-01
  layer model_3__forward_module.module.conv1 act-std: mean=6.031e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.364e-01
  layer model_2__forward_module.module.conv1 act-std: mean=8.295e-01
  layer model_2__forward_module.module.conv2 act-std: mean=5.156e-01
  layer model_1__forward_module.module.conv1 act-std: mean=8.360e-01
  layer model_1__forward_module.module.conv2 act-std: mean=5.263e-01
  layer model_0__forward_module.module.conv1 act-std: mean=8.407e-01
  layer model_0__forward_module.module.conv2 act-std: mean=6.423e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=6.713e-02
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.198e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=7.611e-02
  param model_0__forward_module.module.conv2.bias grad-norm: mean=1.703e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=9.595e-02
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.698e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=8.526e-02
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.108e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=1.165e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=2.258e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=8.747e-02
  param model_2__forward_module.module.conv2.bias grad-norm: mean=2.128e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.807e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=3.787e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.185e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=2.790e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.804e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=3.616e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=1.209e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=2.450e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.352e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=2.336e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=9.666e-02
  param model_5__forward_module.module.conv2.bias grad-norm: mean=2.331e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.514e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=6.798e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=2.576e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=4.317e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=2.373e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.628e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.516e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=3.017e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  2.00it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.98it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  2.02it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  2.00it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  2.00it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.99it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.15it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.09it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.15it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.09it/s]
Epoch 29/32 - Train Loss: 31.018736 - Test Loss: 28.003096
Training epochs:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 29/32 [09:26<00:59, 19.83s/it]
Epoch 30/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 29/32 [09:26<00:59, 19.83s/it]
Epoch 30/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 30/32:   8%|â–Š         | 1/13 [00:01<00:16,  1.40s/it][AEpoch 30/32:   8%|â–Š         | 1/13 [00:01<00:16,  1.41s/it][A
Epoch 30/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:15,  1.41s/it][A
Epoch 30/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:15,  1.41s/it][A
Epoch 30/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.41s/it][A
Epoch 30/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.41s/it][A
Epoch 30/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:12,  1.41s/it][A
Epoch 30/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:12,  1.41s/it][A
Epoch 30/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.41s/it][A
Epoch 30/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.41s/it][A

Epoch 30/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:09,  1.42s/it][AEpoch 30/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:09,  1.42s/it][A
Epoch 30/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:09<00:08,  1.42s/it][A
Epoch 30/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:09<00:08,  1.42s/it][A

Epoch 30/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.42s/it][AEpoch 30/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.42s/it][A
Epoch 30/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:12<00:05,  1.41s/it][A
Epoch 30/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:12<00:05,  1.41s/it][A

Epoch 30/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.41s/it][AEpoch 30/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.41s/it][A
Epoch 30/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:15<00:02,  1.41s/it][A
Epoch 30/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:15<00:02,  1.41s/it][A
Epoch 30/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:16<00:01,  1.41s/it][A
Epoch 30/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:16<00:01,  1.41s/it][A

Epoch 30/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.30s/it][AEpoch 30/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.38s/it]
Epoch 30/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.30s/it][AEpoch 30/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.38s/it]

[Î²=2.0] Epoch 30 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=8.486e-01
  layer model_7__forward_module.module.conv2 act-std: mean=3.159e-01
  layer model_6__forward_module.module.conv1 act-std: mean=9.384e-01
  layer model_6__forward_module.module.conv2 act-std: mean=3.200e-01
  layer model_5__forward_module.module.conv1 act-std: mean=9.737e-01
  layer model_5__forward_module.module.conv2 act-std: mean=4.240e-01
  layer model_4__forward_module.module.conv1 act-std: mean=8.740e-01
  layer model_4__forward_module.module.conv2 act-std: mean=4.703e-01
  layer model_3__forward_module.module.conv1 act-std: mean=6.078e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.420e-01
  layer model_2__forward_module.module.conv1 act-std: mean=8.327e-01
  layer model_2__forward_module.module.conv2 act-std: mean=5.260e-01
  layer model_1__forward_module.module.conv1 act-std: mean=8.424e-01
  layer model_1__forward_module.module.conv2 act-std: mean=5.369e-01
  layer model_0__forward_module.module.conv1 act-std: mean=8.474e-01
  layer model_0__forward_module.module.conv2 act-std: mean=6.556e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=6.588e-02
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.277e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=7.647e-02
  param model_0__forward_module.module.conv2.bias grad-norm: mean=1.510e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=8.666e-02
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.705e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=8.671e-02
  param model_1__forward_module.module.conv2.bias grad-norm: mean=1.767e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=7.891e-02
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.211e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=8.260e-02
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.585e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.307e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.324e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.112e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=2.227e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.804e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=3.584e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=1.302e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=2.573e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.281e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=2.062e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=9.651e-02
  param model_5__forward_module.module.conv2.bias grad-norm: mean=2.083e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=2.358e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=3.881e-02

  param model_6__forward_module.module.conv2.weight grad-norm: mean=2.215e-01
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  param model_6__forward_module.module.conv2.bias grad-norm: mean=3.104e-02[A
  param model_7__forward_module.module.conv1.weight grad-norm: mean=2.689e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=3.370e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.578e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=3.047e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  2.01it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  2.00it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:01,  2.00it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  2.00it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  2.00it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  2.00it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.16it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.10it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.14it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.08it/s]Training epochs:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 30/32 [09:46<00:39, 19.86s/it]
Epoch 30/32 - Train Loss: 30.942018 - Test Loss: 27.934061

Epoch 31/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 30/32 [09:46<00:39, 19.86s/it]
Epoch 31/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 31/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.42s/it][A
Epoch 31/32:   8%|â–Š         | 1/13 [00:01<00:16,  1.41s/it][A
Epoch 31/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:15,  1.41s/it][A
Epoch 31/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:15,  1.41s/it][A

Epoch 31/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.41s/it]Epoch 31/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.41s/it][A[A

Epoch 31/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:12,  1.41s/it][AEpoch 31/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:12,  1.41s/it][A

Epoch 31/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.42s/it][AEpoch 31/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.41s/it][A
Epoch 31/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:09,  1.41s/it][A
Epoch 31/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:09,  1.41s/it][A

Epoch 31/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:09<00:08,  1.41s/it][AEpoch 31/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:09<00:08,  1.41s/it][A

Epoch 31/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.41s/it][AEpoch 31/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.41s/it][A
Epoch 31/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:12<00:05,  1.41s/it][A
Epoch 31/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:12<00:05,  1.41s/it][A

Epoch 31/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.41s/it][AEpoch 31/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.41s/it][A
Epoch 31/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:15<00:02,  1.41s/it][A
Epoch 31/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:15<00:02,  1.41s/it][A

Epoch 31/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:16<00:01,  1.41s/it][AEpoch 31/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:16<00:01,  1.41s/it][A
Epoch 31/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.30s/it][AEpoch 31/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.39s/it]

Epoch 31/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.30s/it][AEpoch 31/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.39s/it]

[Î²=2.0] Epoch 31 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=8.631e-01
  layer model_7__forward_module.module.conv2 act-std: mean=3.261e-01
  layer model_6__forward_module.module.conv1 act-std: mean=9.519e-01
  layer model_6__forward_module.module.conv2 act-std: mean=3.225e-01
  layer model_5__forward_module.module.conv1 act-std: mean=9.856e-01
  layer model_5__forward_module.module.conv2 act-std: mean=4.323e-01

  layer model_4__forward_module.module.conv1 act-std: mean=8.804e-01
  layer model_4__forward_module.module.conv2 act-std: mean=4.755e-01Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  layer model_3__forward_module.module.conv1 act-std: mean=6.121e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.472e-01
  layer model_2__forward_module.module.conv1 act-std: mean=8.352e-01
  layer model_2__forward_module.module.conv2 act-std: mean=5.337e-01
  layer model_1__forward_module.module.conv1 act-std: mean=8.484e-01
  layer model_1__forward_module.module.conv2 act-std: mean=5.480e-01
  layer model_0__forward_module.module.conv1 act-std: mean=8.552e-01
  layer model_0__forward_module.module.conv2 act-std: mean=6.756e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=6.486e-02
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.138e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=7.876e-02
  param model_0__forward_module.module.conv2.bias grad-norm: mean=1.806e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=8.182e-02
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.570e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=8.788e-02
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.158e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=8.986e-02
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.576e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=8.726e-02
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.936e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.431e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.687e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.188e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=2.416e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.638e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=3.218e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=1.282e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=2.459e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.173e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.754e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=9.859e-02
  param model_5__forward_module.module.conv2.bias grad-norm: mean=2.103e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=2.440e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=4.255e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=2.228e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=3.213e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=2.690e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=3.129e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.621e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=3.245e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.99it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.97it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.95it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.94it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.96it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.95it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.13it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.06it/s]
Training epochs:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 31/32 [10:06<00:19, 19.89s/it]
Epoch 32/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.12it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.05it/s]
Epoch 31/32 - Train Loss: 30.859419 - Test Loss: 27.864954
Training epochs:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 31/32 [10:06<00:19, 19.89s/it]
Epoch 32/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 32/32:   8%|â–Š         | 1/13 [00:01<00:16,  1.41s/it][A
Epoch 32/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.43s/it][A
Epoch 32/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:15,  1.41s/it][A
Epoch 32/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:15,  1.42s/it][A
Epoch 32/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.41s/it][A
Epoch 32/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.41s/it][A
Epoch 32/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:13,  1.48s/it][A
Epoch 32/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:13,  1.48s/it][A
Epoch 32/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.45s/it][A
Epoch 32/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.46s/it][A

Epoch 32/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.44s/it][AEpoch 32/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.44s/it][A
Epoch 32/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.43s/it][A
Epoch 32/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.43s/it][A

Epoch 32/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.43s/it][AEpoch 32/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.43s/it][A
Epoch 32/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:12<00:05,  1.43s/it][A
Epoch 32/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:12<00:05,  1.43s/it][A
Epoch 32/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.42s/it][A
Epoch 32/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.42s/it][A
Epoch 32/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:15<00:02,  1.42s/it][A
Epoch 32/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:15<00:02,  1.42s/it][A

Epoch 32/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.42s/it][AEpoch 32/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.42s/it][A

Epoch 32/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.30s/it][AEpoch 32/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.30s/it][AEpoch 32/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.40s/it]

[Î²=2.0] Epoch 32 summary:
Epoch 32/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.40s/it]
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=8.780e-01
  layer model_7__forward_module.module.conv2 act-std: mean=3.390e-01
  layer model_6__forward_module.module.conv1 act-std: mean=9.641e-01
  layer model_6__forward_module.module.conv2 act-std: mean=3.234e-01
  layer model_5__forward_module.module.conv1 act-std: mean=9.982e-01
  layer model_5__forward_module.module.conv2 act-std: mean=4.404e-01
  layer model_4__forward_module.module.conv1 act-std: mean=8.875e-01
  layer model_4__forward_module.module.conv2 act-std: mean=4.804e-01
  layer model_3__forward_module.module.conv1 act-std: mean=6.154e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.491e-01
  layer model_2__forward_module.module.conv1 act-std: mean=8.381e-01
  layer model_2__forward_module.module.conv2 act-std: mean=5.441e-01
  layer model_1__forward_module.module.conv1 act-std: mean=8.541e-01
  layer model_1__forward_module.module.conv2 act-std: mean=5.647e-01
  layer model_0__forward_module.module.conv1 act-std: mean=8.624e-01
  layer model_0__forward_module.module.conv2 act-std: mean=6.923e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=5.998e-02
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.209e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=7.510e-02
  param model_0__forward_module.module.conv2.bias grad-norm: mean=1.465e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=9.159e-02
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.791e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=8.675e-02
  param model_1__forward_module.module.conv2.bias grad-norm: mean=1.979e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=9.853e-02
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.851e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=9.512e-02
  param model_2__forward_module.module.conv2.bias grad-norm: mean=2.172e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.601e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=3.135e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.248e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=2.749e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.488e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=2.745e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=1.249e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=2.013e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.894e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=3.750e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=1.218e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=3.083e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=2.050e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=3.441e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.928e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=2.733e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.591e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=6.173e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.869e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.398e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A

Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.98it/s][AEvaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.98it/s][A

Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.99it/s][AEvaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.98it/s][A

Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.98it/s]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.98it/s][A[A

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.14it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.08it/s]
Epoch 32/32 - Train Loss: 30.791843 - Test Loss: 27.803576
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.14it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.08it/s]
Training epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [10:26<00:00, 19.96s/it]Training epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [10:26<00:00, 19.58s/it]
Training epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [10:26<00:00, 19.96s/it]Training epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [10:26<00:00, 19.58s/it]
Loaded best models from epoch 32 with loss 27.751950

>>> Completed beta = 2.0
>>> Time for this beta: 0:10:27
>>> Total elapsed time: 0:10:29
==================================================
You are using a CUDA device ('NVIDIA A100-SXM4-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 2 processes
----------------------------------------------------------------------------------------------------

============================================================
>>> CUDA device count: 2
PyTorch version: 2.5.0+cu124
CUDA available: True
>>> Arguments:
Lattice size: 64x64
Minimum beta: 2.5
Maximum beta: 6.0
Beta gap: 0.5
Number of epochs: 32
Batch size: 128
Number of subsets: 8
Number of workers: 0
Model tag: simple
Save tag: simple
Random seed: 2008
Identity initialization: True
Check Jacobian: False
Continue training: True
============================================================
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2
Trying to use torch.compile for optimized computation...
Successfully initialized torch.compile
Loaded best models from epoch 32 with loss 27.751950
>>> Loaded the best model at beta = 2.0 to continue training
Loaded data shape: torch.Size([4096, 2, 64, 64])
Training data shape: torch.Size([3276, 2, 64, 64])
Testing data shape: torch.Size([820, 2, 64, 64])

>>> Training the model at beta =  2.5

>>> Training the model at beta = 2.5

Training epochs:   0%|          | 0/32 [00:00<?, ?it/s]Training epochs:   0%|          | 0/32 [00:00<?, ?it/s]

Epoch 1/32:   0%|          | 0/13 [00:00<?, ?it/s][AEpoch 1/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 1/32:   8%|â–Š         | 1/13 [00:12<02:28, 12.36s/it][A
Epoch 1/32:   8%|â–Š         | 1/13 [00:12<02:28, 12.36s/it][A
Epoch 1/32:  15%|â–ˆâ–Œ        | 2/13 [00:13<01:06,  6.05s/it][A
Epoch 1/32:  15%|â–ˆâ–Œ        | 2/13 [00:13<01:06,  6.05s/it][A
Epoch 1/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:15<00:39,  3.95s/it][A
Epoch 1/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:15<00:39,  3.95s/it][A
Epoch 1/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:16<00:26,  2.96s/it][A
Epoch 1/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:16<00:26,  2.96s/it][A
Epoch 1/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:18<00:19,  2.40s/it][A
Epoch 1/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:18<00:19,  2.40s/it][A
Epoch 1/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:19<00:14,  2.07s/it][A
Epoch 1/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:19<00:14,  2.07s/it][A

Epoch 1/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:21<00:11,  1.85s/it][AEpoch 1/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:21<00:11,  1.85s/it][A

Epoch 1/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:22<00:08,  1.71s/it][AEpoch 1/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:22<00:08,  1.71s/it][A

Epoch 1/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:23<00:06,  1.62s/it][AEpoch 1/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:23<00:06,  1.62s/it][A
Epoch 1/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:25<00:04,  1.57s/it][A
Epoch 1/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:25<00:04,  1.57s/it][A

Epoch 1/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:26<00:03,  1.52s/it][AEpoch 1/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:26<00:03,  1.52s/it][A
Epoch 1/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:28<00:01,  1.50s/it][A
Epoch 1/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:28<00:01,  1.50s/it][A

Epoch 1/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:29<00:00,  1.37s/it][AEpoch 1/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:29<00:00,  1.37s/it][AEpoch 1/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:29<00:00,  2.26s/it]
Epoch 1/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:29<00:00,  2.26s/it]

[Î²=2.5] Epoch 1 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=8.802e-01
  layer model_7__forward_module.module.conv2 act-std: mean=3.176e-01
  layer model_6__forward_module.module.conv1 act-std: mean=9.772e-01
  layer model_6__forward_module.module.conv2 act-std: mean=2.974e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.018e+00
  layer model_5__forward_module.module.conv2 act-std: mean=4.389e-01
  layer model_4__forward_module.module.conv1 act-std: mean=8.934e-01
  layer model_4__forward_module.module.conv2 act-std: mean=4.792e-01
  layer model_3__forward_module.module.conv1 act-std: mean=6.135e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.429e-01
  layer model_2__forward_module.module.conv1 act-std: mean=8.440e-01
  layer model_2__forward_module.module.conv2 act-std: mean=5.344e-01
  layer model_1__forward_module.module.conv1 act-std: mean=8.644e-01
  layer model_1__forward_module.module.conv2 act-std: mean=5.893e-01
  layer model_0__forward_module.module.conv1 act-std: mean=8.798e-01
  layer model_0__forward_module.module.conv2 act-std: mean=7.076e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=3.171e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=7.160e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.106e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=6.380e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=3.987e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=9.075e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.126e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=7.176e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=6.773e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.513e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=3.050e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.171e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=9.771e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.171e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=4.151e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.352e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.078e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=2.343e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=5.542e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.409e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=7.904e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.692e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=3.566e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.220e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.173e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=2.529e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=9.936e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.620e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.038e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.161e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=4.247e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.486e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.93it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.92it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.93it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.91it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.95it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.94it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.05it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.00it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  2.03it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.99it/s]
Epoch 1/32 - Train Loss: 36.041603 - Test Loss: 32.500082
Training epochs:   3%|â–Ž         | 1/32 [00:31<16:12, 31.38s/it]
Epoch 2/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:   3%|â–Ž         | 1/32 [00:31<16:13, 31.39s/it]
Epoch 2/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 2/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.44s/it][A
Epoch 2/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.45s/it][A

Epoch 2/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:15,  1.42s/it][AEpoch 2/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:15,  1.43s/it][A
Epoch 2/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.42s/it][A
Epoch 2/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.42s/it][A

Epoch 2/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:12,  1.42s/it][AEpoch 2/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:12,  1.42s/it][A

Epoch 2/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.43s/it][AEpoch 2/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.43s/it][A

Epoch 2/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.44s/it][AEpoch 2/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.44s/it][A
Epoch 2/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.44s/it][A
Epoch 2/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.44s/it][A

Epoch 2/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.44s/it][AEpoch 2/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.44s/it][A
Epoch 2/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:12<00:05,  1.45s/it][A
Epoch 2/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:12<00:05,  1.45s/it][A

Epoch 2/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.44s/it][AEpoch 2/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.44s/it][A
Epoch 2/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:15<00:02,  1.43s/it][A
Epoch 2/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:15<00:02,  1.43s/it][A
Epoch 2/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.43s/it][A
Epoch 2/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.43s/it][A
Epoch 2/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.32s/it][AEpoch 2/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.41s/it]

Epoch 2/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.32s/it][AEpoch 2/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.41s/it]

[Î²=2.5] Epoch 2 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=8.881e-01
  layer model_7__forward_module.module.conv2 act-std: mean=3.174e-01
  layer model_6__forward_module.module.conv1 act-std: mean=9.822e-01
  layer model_6__forward_module.module.conv2 act-std: mean=2.946e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.025e+00
  layer model_5__forward_module.module.conv2 act-std: mean=4.387e-01
  layer model_4__forward_module.module.conv1 act-std: mean=8.976e-01
  layer model_4__forward_module.module.conv2 act-std: mean=4.845e-01
  layer model_3__forward_module.module.conv1 act-std: mean=6.055e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.397e-01
  layer model_2__forward_module.module.conv1 act-std: mean=8.371e-01
  layer model_2__forward_module.module.conv2 act-std: mean=5.303e-01
  layer model_1__forward_module.module.conv1 act-std: mean=8.667e-01
  layer model_1__forward_module.module.conv2 act-std: mean=6.120e-01
  layer model_0__forward_module.module.conv1 act-std: mean=8.669e-01

  layer model_0__forward_module.module.conv2 act-std: mean=7.123e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.221e-01Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  param model_0__forward_module.module.conv1.bias grad-norm: mean=2.646e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.114e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.965e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.914e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=4.333e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.288e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.823e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.513e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=7.840e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.769e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=6.138e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=5.686e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.271e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.516e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=7.953e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=5.326e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.167e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.085e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=7.351e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=3.231e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=6.682e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=1.684e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=4.860e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=7.177e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.567e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=6.151e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.006e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=4.668e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=8.709e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.181e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=6.168e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.92it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.92it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.95it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.91it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.93it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.92it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.08it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.02it/s]

Training epochs:   6%|â–‹         | 2/32 [00:51<12:25, 24.84s/it]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.07it/s][A
Epoch 3/32:   0%|          | 0/13 [00:00<?, ?it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.01it/s]
Epoch 2/32 - Train Loss: 35.974411 - Test Loss: 32.455970
Training epochs:   6%|â–‹         | 2/32 [00:51<12:25, 24.85s/it]
Epoch 3/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 3/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.44s/it][A
Epoch 3/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.42s/it][A

Epoch 3/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:15,  1.44s/it][AEpoch 3/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:15,  1.43s/it][A
Epoch 3/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.43s/it][A
Epoch 3/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.44s/it][A
Epoch 3/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:12,  1.44s/it][A
Epoch 3/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:12,  1.44s/it][A

Epoch 3/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.44s/it][AEpoch 3/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.44s/it][A
Epoch 3/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.44s/it][A
Epoch 3/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.44s/it][A
Epoch 3/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.45s/it][A
Epoch 3/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.44s/it][A
Epoch 3/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.44s/it][A
Epoch 3/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.44s/it][A
Epoch 3/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:12<00:05,  1.44s/it][A
Epoch 3/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:12<00:05,  1.44s/it][A
Epoch 3/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.44s/it][A
Epoch 3/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.44s/it][A
Epoch 3/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:15<00:02,  1.44s/it][A
Epoch 3/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:15<00:02,  1.44s/it][A
Epoch 3/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.44s/it][A
Epoch 3/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.44s/it][A

Epoch 3/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.33s/it][AEpoch 3/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.41s/it]
Epoch 3/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.33s/it][AEpoch 3/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.41s/it]

[Î²=2.5] Epoch 3 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=8.891e-01
  layer model_7__forward_module.module.conv2 act-std: mean=3.189e-01
  layer model_6__forward_module.module.conv1 act-std: mean=9.849e-01
  layer model_6__forward_module.module.conv2 act-std: mean=2.973e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.035e+00
  layer model_5__forward_module.module.conv2 act-std: mean=4.475e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.008e-01
  layer model_4__forward_module.module.conv2 act-std: mean=4.959e-01
  layer model_3__forward_module.module.conv1 act-std: mean=5.951e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.462e-01
  layer model_2__forward_module.module.conv1 act-std: mean=8.239e-01
  layer model_2__forward_module.module.conv2 act-std: mean=5.394e-01
  layer model_1__forward_module.module.conv1 act-std: mean=8.675e-01
  layer model_1__forward_module.module.conv2 act-std: mean=6.392e-01
  layer model_0__forward_module.module.conv1 act-std: mean=8.538e-01
  layer model_0__forward_module.module.conv2 act-std: mean=7.417e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=8.584e-02
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.645e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=9.886e-02
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.295e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.358e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.910e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.070e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.805e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=2.298e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=4.910e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.392e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=4.118e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.068e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=6.621e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.737e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.688e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=3.803e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=8.143e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.320e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=5.160e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.934e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=3.534e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=1.278e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=3.135e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=4.300e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=8.780e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.080e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=6.118e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=2.792e-01

  param model_7__forward_module.module.conv1.bias grad-norm: mean=3.803e-02
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.612e-01[A
  param model_7__forward_module.module.conv2.bias grad-norm: mean=3.400e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.91it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.89it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.91it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.90it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.91it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.91it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.06it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  2.00it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  2.05it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.99it/s]
Epoch 3/32 - Train Loss: 35.907924 - Test Loss: 32.416303
Training epochs:   9%|â–‰         | 3/32 [01:12<11:01, 22.82s/it]
Epoch 4/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:   9%|â–‰         | 3/32 [01:12<11:01, 22.82s/it]
Epoch 4/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 4/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.45s/it][A
Epoch 4/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.45s/it][A
Epoch 4/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:15,  1.45s/it][A
Epoch 4/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:15,  1.45s/it][A
Epoch 4/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.45s/it][A
Epoch 4/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.46s/it][A

Epoch 4/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:13,  1.45s/it][AEpoch 4/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:13,  1.45s/it][A

Epoch 4/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.45s/it][AEpoch 4/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.45s/it][A

Epoch 4/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.44s/it][AEpoch 4/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.44s/it][A
Epoch 4/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.44s/it][A
Epoch 4/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.44s/it][A

Epoch 4/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.44s/it][AEpoch 4/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.44s/it][A
Epoch 4/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:12<00:05,  1.44s/it][A
Epoch 4/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:12<00:05,  1.44s/it][A
Epoch 4/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.44s/it][A
Epoch 4/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.44s/it][A
Epoch 4/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:15<00:02,  1.44s/it][A
Epoch 4/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:15<00:02,  1.44s/it][A

Epoch 4/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.44s/it][AEpoch 4/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.44s/it][A

Epoch 4/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.33s/it][AEpoch 4/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.42s/it]

[Î²=2.5] Epoch 4 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=8.878e-01
  layer model_7__forward_module.module.conv2 act-std: mean=3.255e-01
Epoch 4/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.33s/it]  layer model_6__forward_module.module.conv1 act-std: mean=9.881e-01[A
  layer model_6__forward_module.module.conv2 act-std: mean=2.977e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.049e+00
  layer model_5__forward_module.module.conv2 act-std: mean=4.517e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.026e-01
Epoch 4/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.42s/it]  layer model_4__forward_module.module.conv2 act-std: mean=5.114e-01

  layer model_3__forward_module.module.conv1 act-std: mean=5.880e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.437e-01
  layer model_2__forward_module.module.conv1 act-std: mean=8.203e-01
  layer model_2__forward_module.module.conv2 act-std: mean=5.420e-01
  layer model_1__forward_module.module.conv1 act-std: mean=8.671e-01
  layer model_1__forward_module.module.conv2 act-std: mean=6.562e-01
  layer model_0__forward_module.module.conv1 act-std: mean=8.489e-01
  layer model_0__forward_module.module.conv2 act-std: mean=7.532e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=8.184e-02
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.675e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=8.440e-02
  param model_0__forward_module.module.conv2.bias grad-norm: mean=1.773e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.062e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.270e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=9.217e-02
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.266e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=1.290e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=2.176e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.019e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=2.441e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.704e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=3.102e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.306e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=2.545e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.230e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=4.331e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=1.657e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.277e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.350e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=2.053e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=1.168e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=2.330e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=2.921e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=5.752e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=2.841e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=4.064e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=2.480e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.901e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.501e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=2.940e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.92it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.89it/s][A

Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.93it/s][AEvaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.93it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.93it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.92it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.09it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.02it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.07it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.01it/s]
Epoch 4/32 - Train Loss: 35.857228 - Test Loss: 32.363714
Training epochs:  12%|â–ˆâ–Ž        | 4/32 [01:32<10:12, 21.86s/it]
Epoch 5/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  12%|â–ˆâ–Ž        | 4/32 [01:32<10:12, 21.87s/it]
Epoch 5/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 5/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.45s/it][AEpoch 5/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.46s/it][A
Epoch 5/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:15,  1.45s/it][A
Epoch 5/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:15,  1.44s/it][A
Epoch 5/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.44s/it][A
Epoch 5/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.44s/it][A

Epoch 5/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:12,  1.44s/it][AEpoch 5/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:12,  1.44s/it][A
Epoch 5/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.45s/it][A
Epoch 5/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.45s/it][A
Epoch 5/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.45s/it][A
Epoch 5/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.45s/it][A
Epoch 5/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.45s/it][A
Epoch 5/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.45s/it][A

Epoch 5/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.45s/it][AEpoch 5/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.45s/it][A
Epoch 5/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:05,  1.46s/it][A
Epoch 5/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:05,  1.46s/it][A
Epoch 5/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.45s/it][A
Epoch 5/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.45s/it][A

Epoch 5/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:15<00:02,  1.45s/it][AEpoch 5/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:15<00:02,  1.45s/it][A
Epoch 5/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.46s/it][A
Epoch 5/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.46s/it][A
Epoch 5/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.34s/it][AEpoch 5/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.42s/it]

[Î²=2.5] Epoch 5 summary:
  input  std: mean=1.813e+00
  layer model_7__forward_module.module.conv1 act-std: mean=8.898e-01
  layer model_7__forward_module.module.conv2 act-std: mean=3.316e-01
  layer model_6__forward_module.module.conv1 act-std: mean=9.911e-01
  layer model_6__forward_module.module.conv2 act-std: mean=2.996e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.066e+00
  layer model_5__forward_module.module.conv2 act-std: mean=4.597e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.070e-01
  layer model_4__forward_module.module.conv2 act-std: mean=5.291e-01
  layer model_3__forward_module.module.conv1 act-std: mean=5.802e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.414e-01
  layer model_2__forward_module.module.conv1 act-std: mean=8.152e-01
  layer model_2__forward_module.module.conv2 act-std: mean=5.438e-01
  layer model_1__forward_module.module.conv1 act-std: mean=8.664e-01
  layer model_1__forward_module.module.conv2 act-std: mean=6.676e-01
  layer model_0__forward_module.module.conv1 act-std: mean=8.492e-01
  layer model_0__forward_module.module.conv2 act-std: mean=7.728e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=8.226e-02
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.727e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=8.540e-02
  param model_0__forward_module.module.conv2.bias grad-norm: mean=1.788e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.039e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.201e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=9.254e-02
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.297e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=1.342e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=2.488e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.071e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=2.641e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=2.075e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=3.941e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.440e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=3.191e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.203e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=4.381e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=1.773e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.595e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.262e-01

  param model_5__forward_module.module.conv1.bias grad-norm: mean=4.195e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=1.449e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=3.590e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=2.454e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=4.340e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=2.839e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=3.996e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.150e-01Epoch 5/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.34s/it]
[A  param model_7__forward_module.module.conv1.bias grad-norm: mean=5.461e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.700e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=3.951e-02
Epoch 5/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.42s/it]

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.85it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.83it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.89it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.88it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.90it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.88it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  2.07it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  2.00it/s]

Training epochs:  16%|â–ˆâ–Œ        | 5/32 [01:52<09:37, 21.38s/it]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  2.06it/s][A
Epoch 6/32:   0%|          | 0/13 [00:00<?, ?it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.98it/s]
Epoch 5/32 - Train Loss: 35.794503 - Test Loss: 32.318336
Training epochs:  16%|â–ˆâ–Œ        | 5/32 [01:52<09:37, 21.38s/it]
Epoch 6/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 6/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.45s/it][A
Epoch 6/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.44s/it][A
Epoch 6/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:15,  1.44s/it][A
Epoch 6/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:15,  1.44s/it][A
Epoch 6/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.43s/it][A
Epoch 6/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.44s/it][A
Epoch 6/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:12,  1.43s/it][A
Epoch 6/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:12,  1.43s/it][A

Epoch 6/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.44s/it][AEpoch 6/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.44s/it][A

Epoch 6/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.44s/it][AEpoch 6/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.44s/it][A
Epoch 6/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.45s/it][A
Epoch 6/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.45s/it][A
Epoch 6/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.45s/it][A
Epoch 6/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.45s/it][A
Epoch 6/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:12<00:05,  1.45s/it][A
Epoch 6/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:05,  1.45s/it][A
Epoch 6/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.45s/it][A
Epoch 6/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.45s/it][A
Epoch 6/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:15<00:02,  1.44s/it][A
Epoch 6/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:15<00:02,  1.44s/it][A

Epoch 6/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.44s/it][AEpoch 6/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.44s/it][A
Epoch 6/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.33s/it][AEpoch 6/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.41s/it]

[Î²=2.5] Epoch 6 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=8.895e-01
  layer model_7__forward_module.module.conv2 act-std: mean=3.399e-01
  layer model_6__forward_module.module.conv1 act-std: mean=9.958e-01
  layer model_6__forward_module.module.conv2 act-std: mean=2.990e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.085e+00
  layer model_5__forward_module.module.conv2 act-std: mean=4.659e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.157e-01
  layer model_4__forward_module.module.conv2 act-std: mean=5.521e-01
  layer model_3__forward_module.module.conv1 act-std: mean=5.731e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.397e-01
  layer model_2__forward_module.module.conv1 act-std: mean=8.148e-01
  layer model_2__forward_module.module.conv2 act-std: mean=5.449e-01
  layer model_1__forward_module.module.conv1 act-std: mean=8.646e-01
  layer model_1__forward_module.module.conv2 act-std: mean=6.844e-01
  layer model_0__forward_module.module.conv1 act-std: mean=8.562e-01
  layer model_0__forward_module.module.conv2 act-std: mean=7.955e-01

  param model_0__forward_module.module.conv1.weight grad-norm: mean=6.310e-02
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.106e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=8.438e-02
  param model_0__forward_module.module.conv2.bias grad-norm: mean=1.748e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=7.121e-02
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.309e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=9.149e-02
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.180e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=1.381e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=2.723e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.072e-01
Epoch 6/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.33s/it]  param model_2__forward_module.module.conv2.bias grad-norm: mean=2.617e-02[A
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.794e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=3.310e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.409e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=3.107e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.289e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=4.654e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=1.749e-01Epoch 6/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.41s/it]

  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.259e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.782e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=3.090e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=1.326e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=2.970e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.077e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=6.203e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=3.062e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=4.349e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=2.880e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=4.636e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.502e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=3.319e-02


Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][AEvaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.97it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.95it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.96it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.96it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.95it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.94it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.11it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.05it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.09it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.03it/s]
Epoch 6/32 - Train Loss: 35.740765 - Test Loss: 32.267888
Training epochs:  19%|â–ˆâ–‰        | 6/32 [02:13<09:06, 21.03s/it]
Epoch 7/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  19%|â–ˆâ–‰        | 6/32 [02:13<09:06, 21.03s/it]
Epoch 7/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 7/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.45s/it][A
Epoch 7/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.46s/it][A
Epoch 7/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:15,  1.45s/it][A
Epoch 7/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:16,  1.46s/it][A

Epoch 7/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.45s/it][AEpoch 7/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.46s/it][A
Epoch 7/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:13,  1.45s/it][A
Epoch 7/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:13,  1.45s/it][A

Epoch 7/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.45s/it][AEpoch 7/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.45s/it][A
Epoch 7/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.45s/it][A
Epoch 7/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.45s/it][A

Epoch 7/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.45s/it][AEpoch 7/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.45s/it][A

Epoch 7/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.44s/it][AEpoch 7/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.44s/it][A

Epoch 7/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:05,  1.44s/it][AEpoch 7/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:05,  1.44s/it][A
Epoch 7/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.45s/it][A
Epoch 7/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.45s/it][A
Epoch 7/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:15<00:02,  1.45s/it][A
Epoch 7/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:15<00:02,  1.45s/it][A

Epoch 7/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.45s/it][AEpoch 7/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.45s/it][A
Epoch 7/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.33s/it][AEpoch 7/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.42s/it]

Epoch 7/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.33s/it][AEpoch 7/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.42s/it]

[Î²=2.5] Epoch 7 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=8.876e-01
  layer model_7__forward_module.module.conv2 act-std: mean=3.464e-01
  layer model_6__forward_module.module.conv1 act-std: mean=9.998e-01
  layer model_6__forward_module.module.conv2 act-std: mean=3.017e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.105e+00
  layer model_5__forward_module.module.conv2 act-std: mean=4.792e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.231e-01
  layer model_4__forward_module.module.conv2 act-std: mean=5.783e-01

  layer model_3__forward_module.module.conv1 act-std: mean=5.676e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.408e-01Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  layer model_2__forward_module.module.conv1 act-std: mean=8.221e-01
  layer model_2__forward_module.module.conv2 act-std: mean=5.459e-01
  layer model_1__forward_module.module.conv1 act-std: mean=8.618e-01
  layer model_1__forward_module.module.conv2 act-std: mean=6.996e-01
  layer model_0__forward_module.module.conv1 act-std: mean=8.677e-01
  layer model_0__forward_module.module.conv2 act-std: mean=8.125e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=5.659e-02
  param model_0__forward_module.module.conv1.bias grad-norm: mean=9.336e-03
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.049e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.292e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=7.195e-02
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.276e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.053e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.477e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=1.588e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=3.040e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.149e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=2.905e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.575e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.802e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.360e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=2.762e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.880e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=3.416e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=1.660e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=2.664e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.865e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=3.208e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=1.360e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=2.975e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.745e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=2.505e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=2.225e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=2.658e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=2.488e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=3.693e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.485e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=3.392e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.94it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.95it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.97it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.94it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.95it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.93it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.07it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.02it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.06it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.02it/s]
Epoch 7/32 - Train Loss: 35.683608 - Test Loss: 32.215190
Training epochs:  22%|â–ˆâ–ˆâ–       | 7/32 [02:33<08:41, 20.84s/it]
Epoch 8/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  22%|â–ˆâ–ˆâ–       | 7/32 [02:33<08:41, 20.84s/it]
Epoch 8/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 8/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.44s/it][A
Epoch 8/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.43s/it][A
Epoch 8/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:15,  1.44s/it][A
Epoch 8/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:15,  1.43s/it][A
Epoch 8/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.43s/it][A
Epoch 8/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.43s/it][A

Epoch 8/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:12,  1.44s/it][AEpoch 8/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:12,  1.44s/it][A
Epoch 8/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.46s/it][A
Epoch 8/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.46s/it][A

Epoch 8/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.46s/it][AEpoch 8/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.46s/it][A
Epoch 8/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.45s/it][A
Epoch 8/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.45s/it][A
Epoch 8/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.44s/it][A
Epoch 8/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.44s/it][A
Epoch 8/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:12<00:05,  1.44s/it][A
Epoch 8/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:12<00:05,  1.44s/it][A

Epoch 8/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.44s/it][AEpoch 8/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.44s/it][A

Epoch 8/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:15<00:02,  1.45s/it][AEpoch 8/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:15<00:02,  1.45s/it][A
Epoch 8/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.45s/it][A
Epoch 8/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.45s/it][A
Epoch 8/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.34s/it][AEpoch 8/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.42s/it]

[Î²=2.5] Epoch 8 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=8.880e-01
  layer model_7__forward_module.module.conv2 act-std: mean=3.556e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.004e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.024e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.125e+00
  layer model_5__forward_module.module.conv2 act-std: mean=4.942e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.336e-01
  layer model_4__forward_module.module.conv2 act-std: mean=6.132e-01
  layer model_3__forward_module.module.conv1 act-std: mean=5.632e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.356e-01
  layer model_2__forward_module.module.conv1 act-std: mean=8.298e-01
  layer model_2__forward_module.module.conv2 act-std: mean=5.488e-01
  layer model_1__forward_module.module.conv1 act-std: mean=8.585e-01
  layer model_1__forward_module.module.conv2 act-std: mean=7.163e-01
  layer model_0__forward_module.module.conv1 act-std: mean=8.846e-01
  layer model_0__forward_module.module.conv2 act-std: mean=8.314e-01

  param model_0__forward_module.module.conv1.weight grad-norm: mean=9.000e-02
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.833e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.182e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.716e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.057e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.175e-02
Epoch 8/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.34s/it]  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.151e-01[A
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.017e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=1.636e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=3.262e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.206e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.377e-02
Epoch 8/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.42s/it]  param model_3__forward_module.module.conv1.weight grad-norm: mean=2.535e-01

  param model_3__forward_module.module.conv1.bias grad-norm: mean=5.241e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.555e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.185e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.747e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=5.482e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=1.985e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.857e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.383e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=4.446e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=1.546e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=3.768e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.613e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=7.431e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=3.700e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.226e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=2.194e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.889e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.518e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=3.107e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.94it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.93it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.95it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.94it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.94it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.92it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.09it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.03it/s]

Training epochs:  25%|â–ˆâ–ˆâ–Œ       | 8/32 [02:54<08:17, 20.71s/it]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.08it/s]
[AEpoch 9/32:   0%|          | 0/13 [00:00<?, ?it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.02it/s]
Epoch 8/32 - Train Loss: 35.609272 - Test Loss: 32.165051
Training epochs:  25%|â–ˆâ–ˆâ–Œ       | 8/32 [02:54<08:17, 20.72s/it]
Epoch 9/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 9/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.44s/it]
[AEpoch 9/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.46s/it][A
Epoch 9/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:15,  1.45s/it][A
Epoch 9/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:15,  1.45s/it][A
Epoch 9/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.44s/it][A
Epoch 9/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.45s/it][A
Epoch 9/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:12,  1.44s/it]
[AEpoch 9/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:13,  1.45s/it][A
Epoch 9/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.45s/it][A
Epoch 9/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.45s/it][A
Epoch 9/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.46s/it][A
Epoch 9/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.46s/it][A
Epoch 9/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.46s/it][A
Epoch 9/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.46s/it][A

Epoch 9/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.45s/it][AEpoch 9/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.45s/it][A
Epoch 9/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:05,  1.45s/it][A
Epoch 9/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:05,  1.45s/it][A
Epoch 9/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.45s/it][A
Epoch 9/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.45s/it][A
Epoch 9/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:15<00:02,  1.45s/it][A
Epoch 9/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:15<00:02,  1.46s/it][A

Epoch 9/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.46s/it][AEpoch 9/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.46s/it][A
Epoch 9/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.35s/it][AEpoch 9/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.43s/it]


[Î²=2.5] Epoch 9 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=8.879e-01
  layer model_7__forward_module.module.conv2 act-std: mean=3.679e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.010e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.036e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.147e+00
  layer model_5__forward_module.module.conv2 act-std: mean=5.136e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.412e-01
  layer model_4__forward_module.module.conv2 act-std: mean=6.471e-01
  layer model_3__forward_module.module.conv1 act-std: mean=5.605e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.355e-01
  layer model_2__forward_module.module.conv1 act-std: mean=8.392e-01
  layer model_2__forward_module.module.conv2 act-std: mean=5.532e-01
Epoch 9/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.35s/it]  layer model_1__forward_module.module.conv1 act-std: mean=8.564e-01[A
  layer model_1__forward_module.module.conv2 act-std: mean=7.263e-01
  layer model_0__forward_module.module.conv1 act-std: mean=9.024e-01
  layer model_0__forward_module.module.conv2 act-std: mean=8.501e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.024e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=2.169e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.091e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.418e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=9.660e-02Epoch 9/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.43s/it]

  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.966e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.035e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.687e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=1.885e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=3.731e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.236e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.340e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=2.695e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=5.687e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.655e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.439e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.289e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=4.527e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=1.996e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.613e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.462e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=4.640e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=1.734e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=3.698e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.232e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=6.547e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=3.723e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.250e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=2.609e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=4.360e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.594e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=3.401e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.85it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.83it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.89it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.87it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.90it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.87it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  2.04it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.98it/s]
Training epochs:  28%|â–ˆâ–ˆâ–Š       | 9/32 [03:14<07:55, 20.67s/it]
Epoch 10/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  2.02it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.96it/s]
Epoch 9/32 - Train Loss: 35.543756 - Test Loss: 32.116597
Training epochs:  28%|â–ˆâ–ˆâ–Š       | 9/32 [03:14<07:55, 20.68s/it]
Epoch 10/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 10/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.49s/it][A
Epoch 10/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.47s/it][A

Epoch 10/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:16,  1.47s/it][AEpoch 10/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:16,  1.46s/it][A

Epoch 10/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.46s/it][AEpoch 10/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.46s/it][A
Epoch 10/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:13,  1.46s/it][A
Epoch 10/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:13,  1.46s/it][A

Epoch 10/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.47s/it][AEpoch 10/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.47s/it][A
Epoch 10/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.47s/it][A
Epoch 10/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.47s/it][A
Epoch 10/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.47s/it][A
Epoch 10/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.46s/it][A
Epoch 10/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.47s/it][A
Epoch 10/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.46s/it][A
Epoch 10/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:05,  1.47s/it][A
Epoch 10/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:05,  1.47s/it][A

Epoch 10/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.46s/it][AEpoch 10/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.47s/it][A

Epoch 10/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:02,  1.46s/it]Epoch 10/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:02,  1.46s/it][A[A

Epoch 10/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.46s/it][AEpoch 10/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.46s/it][A
Epoch 10/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.35s/it][AEpoch 10/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.44s/it]

Epoch 10/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.35s/it][AEpoch 10/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.44s/it]

[Î²=2.5] Epoch 10 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=8.899e-01
  layer model_7__forward_module.module.conv2 act-std: mean=3.802e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.015e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.053e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.166e+00
  layer model_5__forward_module.module.conv2 act-std: mean=5.358e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.505e-01
  layer model_4__forward_module.module.conv2 act-std: mean=6.866e-01
  layer model_3__forward_module.module.conv1 act-std: mean=5.599e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.335e-01
  layer model_2__forward_module.module.conv1 act-std: mean=8.462e-01
  layer model_2__forward_module.module.conv2 act-std: mean=5.524e-01
  layer model_1__forward_module.module.conv1 act-std: mean=8.503e-01
  layer model_1__forward_module.module.conv2 act-std: mean=7.443e-01

  layer model_0__forward_module.module.conv1 act-std: mean=9.214e-01
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  layer model_0__forward_module.module.conv2 act-std: mean=8.611e-01[A
  param model_0__forward_module.module.conv1.weight grad-norm: mean=9.955e-02
  param model_0__forward_module.module.conv1.bias grad-norm: mean=2.120e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.126e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.523e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=9.497e-02
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.928e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.064e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.706e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=1.664e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=3.226e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.122e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=2.805e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.833e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=3.623e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.475e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=3.255e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=3.056e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=6.406e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.242e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=4.013e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.864e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=3.102e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=1.510e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=3.032e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=2.993e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=5.868e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=3.426e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=4.652e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=2.469e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=3.983e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.499e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=3.256e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.93it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.94it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.92it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.90it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.89it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.89it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  2.03it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.98it/s]
Epoch 10/32 - Train Loss: 35.502016 - Test Loss: 32.065726

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  2.02it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.97it/s]
Training epochs:  31%|â–ˆâ–ˆâ–ˆâ–      | 10/32 [03:35<07:34, 20.68s/it]
Epoch 11/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  31%|â–ˆâ–ˆâ–ˆâ–      | 10/32 [03:35<07:35, 20.69s/it]
Epoch 11/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 11/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.45s/it][A
Epoch 11/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.45s/it][A
Epoch 11/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:15,  1.45s/it][A
Epoch 11/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:16,  1.45s/it][A

Epoch 11/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.46s/it][AEpoch 11/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.46s/it][A
Epoch 11/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:13,  1.46s/it][A
Epoch 11/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:13,  1.47s/it][A
Epoch 11/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.47s/it][A
Epoch 11/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.47s/it][A
Epoch 11/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.47s/it][A
Epoch 11/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.47s/it][A
Epoch 11/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.47s/it][A
Epoch 11/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.47s/it][A

Epoch 11/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.47s/it][AEpoch 11/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.47s/it][A

Epoch 11/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:05,  1.47s/it][AEpoch 11/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:05,  1.47s/it][A
Epoch 11/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.47s/it][A
Epoch 11/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.47s/it][A
Epoch 11/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:02,  1.47s/it][A
Epoch 11/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:02,  1.47s/it][A

Epoch 11/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.47s/it][AEpoch 11/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.47s/it][A
Epoch 11/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.36s/it][A
Epoch 11/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.44s/it]
Epoch 11/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.36s/it][AEpoch 11/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.44s/it]

[Î²=2.5] Epoch 11 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=8.917e-01
  layer model_7__forward_module.module.conv2 act-std: mean=3.953e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.020e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.074e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.187e+00
  layer model_5__forward_module.module.conv2 act-std: mean=5.644e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.581e-01
  layer model_4__forward_module.module.conv2 act-std: mean=7.291e-01
  layer model_3__forward_module.module.conv1 act-std: mean=5.597e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.320e-01
  layer model_2__forward_module.module.conv1 act-std: mean=8.552e-01
  layer model_2__forward_module.module.conv2 act-std: mean=5.527e-01
  layer model_1__forward_module.module.conv1 act-std: mean=8.480e-01
  layer model_1__forward_module.module.conv2 act-std: mean=7.557e-01
  layer model_0__forward_module.module.conv1 act-std: mean=9.462e-01
  layer model_0__forward_module.module.conv2 act-std: mean=8.809e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=8.003e-02
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.567e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.119e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.255e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=8.226e-02
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.628e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.013e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.284e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=1.808e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=3.572e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.197e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.023e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=2.039e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=4.002e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.585e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=3.436e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.307e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=4.436e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=1.962e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.400e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.967e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=3.287e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=1.640e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=3.215e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=2.318e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=4.142e-02

  param model_6__forward_module.module.conv2.weight grad-norm: mean=2.967e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=3.945e-02Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  param model_7__forward_module.module.conv1.weight grad-norm: mean=2.937e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=5.323e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.688e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=3.870e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.90it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.89it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.90it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.90it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.87it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.86it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  2.00it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.96it/s]
Training epochs:  34%|â–ˆâ–ˆâ–ˆâ–      | 11/32 [03:56<07:14, 20.71s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.99it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s]
Epoch 11/32 - Train Loss: 35.464585 - Test Loss: 32.014472

Epoch 12/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  34%|â–ˆâ–ˆâ–ˆâ–      | 11/32 [03:56<07:14, 20.71s/it]
Epoch 12/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 12/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.46s/it][A
Epoch 12/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.48s/it][A
Epoch 12/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:16,  1.47s/it][A
Epoch 12/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:16,  1.47s/it][A
Epoch 12/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.47s/it][A
Epoch 12/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.47s/it][A

Epoch 12/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:13,  1.47s/it][AEpoch 12/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:13,  1.47s/it][A

Epoch 12/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.47s/it][AEpoch 12/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.48s/it][A

Epoch 12/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.47s/it][AEpoch 12/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.47s/it][A

Epoch 12/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.47s/it][AEpoch 12/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.47s/it][A
Epoch 12/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.47s/it][A
Epoch 12/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.47s/it][A
Epoch 12/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:05,  1.47s/it][A
Epoch 12/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:05,  1.47s/it][A
Epoch 12/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.47s/it][A
Epoch 12/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.47s/it][A

Epoch 12/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:02,  1.47s/it][AEpoch 12/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:02,  1.47s/it][A
Epoch 12/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.48s/it]
[AEpoch 12/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.48s/it][A

Epoch 12/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.36s/it][AEpoch 12/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.36s/it][AEpoch 12/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.44s/it]
Epoch 12/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.44s/it]

[Î²=2.5] Epoch 12 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=8.919e-01
  layer model_7__forward_module.module.conv2 act-std: mean=4.113e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.026e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.096e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.207e+00
  layer model_5__forward_module.module.conv2 act-std: mean=5.918e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.642e-01
  layer model_4__forward_module.module.conv2 act-std: mean=7.719e-01
  layer model_3__forward_module.module.conv1 act-std: mean=5.622e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.303e-01
  layer model_2__forward_module.module.conv1 act-std: mean=8.637e-01
  layer model_2__forward_module.module.conv2 act-std: mean=5.564e-01
  layer model_1__forward_module.module.conv1 act-std: mean=8.484e-01
  layer model_1__forward_module.module.conv2 act-std: mean=7.701e-01
  layer model_0__forward_module.module.conv1 act-std: mean=9.657e-01
  layer model_0__forward_module.module.conv2 act-std: mean=8.928e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.068e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=2.183e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.214e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.415e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=8.393e-02
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.654e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.005e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.190e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=2.079e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=4.074e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.182e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.297e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=2.031e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=3.827e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.496e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=3.358e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.391e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=2.133e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=1.489e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.927e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.520e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=4.802e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=1.945e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=4.085e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.636e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=2.377e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=2.312e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=2.637e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=2.828e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=5.145e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.755e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.088e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.91it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.88it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.88it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.87it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.86it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.86it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  2.03it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.97it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  2.02it/s][ATraining epochs:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 12/32 [04:17<06:54, 20.74s/it]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.96it/s]
Epoch 12/32 - Train Loss: 35.401185 - Test Loss: 31.965319

Epoch 13/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 12/32 [04:17<06:54, 20.74s/it]
Epoch 13/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 13/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.47s/it][A
Epoch 13/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.49s/it][A
Epoch 13/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:16,  1.47s/it][A
Epoch 13/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:16,  1.48s/it][A
Epoch 13/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.47s/it][A
Epoch 13/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.48s/it][A

Epoch 13/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:13,  1.47s/it][AEpoch 13/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:13,  1.47s/it][A
Epoch 13/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.48s/it][A
Epoch 13/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.48s/it][A
Epoch 13/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.47s/it][A
Epoch 13/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.47s/it][A
Epoch 13/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.47s/it][A
Epoch 13/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.47s/it][A

Epoch 13/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.47s/it][AEpoch 13/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.47s/it][A
Epoch 13/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:05,  1.47s/it][A
Epoch 13/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:05,  1.47s/it][A
Epoch 13/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.46s/it][A
Epoch 13/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.46s/it][A
Epoch 13/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:02,  1.47s/it][A
Epoch 13/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:02,  1.47s/it][A

Epoch 13/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.47s/it][AEpoch 13/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.47s/it][A
Epoch 13/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.36s/it][AEpoch 13/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.44s/it]

Epoch 13/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.36s/it][AEpoch 13/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.44s/it]

[Î²=2.5] Epoch 13 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=8.965e-01
  layer model_7__forward_module.module.conv2 act-std: mean=4.298e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.032e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.113e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.224e+00
  layer model_5__forward_module.module.conv2 act-std: mean=6.229e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.691e-01
  layer model_4__forward_module.module.conv2 act-std: mean=8.142e-01
  layer model_3__forward_module.module.conv1 act-std: mean=5.644e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.278e-01
  layer model_2__forward_module.module.conv1 act-std: mean=8.708e-01
  layer model_2__forward_module.module.conv2 act-std: mean=5.539e-01
  layer model_1__forward_module.module.conv1 act-std: mean=8.532e-01
  layer model_1__forward_module.module.conv2 act-std: mean=7.897e-01
  layer model_0__forward_module.module.conv1 act-std: mean=9.883e-01
  layer model_0__forward_module.module.conv2 act-std: mean=9.008e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=7.371e-02
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.391e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.074e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=1.926e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=9.088e-02
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.903e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.060e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.520e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.321e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=7.286e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.590e-01

  param model_2__forward_module.module.conv2.bias grad-norm: mean=4.971e-02
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.978e-01[A
  param model_3__forward_module.module.conv1.bias grad-norm: mean=8.720e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.150e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=6.110e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.802e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=3.243e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.047e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.067e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.270e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=3.952e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=1.996e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=4.182e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=2.548e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=4.768e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=3.589e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=4.675e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=2.619e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=4.897e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.632e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.057e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.91it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.89it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.91it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.88it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.92it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.90it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.07it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.01it/s]
Training epochs:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 13/32 [04:37<06:34, 20.75s/it]
Epoch 14/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  2.05it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.99it/s]
Epoch 13/32 - Train Loss: 35.313332 - Test Loss: 31.919524
Training epochs:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 13/32 [04:37<06:34, 20.75s/it]
Epoch 14/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 14/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.47s/it][A
Epoch 14/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.49s/it][A

Epoch 14/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:16,  1.47s/it][AEpoch 14/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:16,  1.48s/it][A

Epoch 14/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.47s/it][AEpoch 14/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.47s/it][A
Epoch 14/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:13,  1.47s/it][A
Epoch 14/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:13,  1.47s/it][A

Epoch 14/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.47s/it][AEpoch 14/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.47s/it][A
Epoch 14/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.47s/it][A
Epoch 14/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.47s/it][A
Epoch 14/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.47s/it][A
Epoch 14/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.47s/it][A

Epoch 14/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.47s/it][AEpoch 14/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.47s/it][A

Epoch 14/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:05,  1.47s/it][AEpoch 14/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:05,  1.47s/it][A

Epoch 14/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.47s/it][AEpoch 14/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.47s/it][A
Epoch 14/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:02,  1.47s/it][A
Epoch 14/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:02,  1.47s/it][A
Epoch 14/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.47s/it][A
Epoch 14/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.47s/it][A
Epoch 14/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.35s/it][AEpoch 14/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.44s/it]

Epoch 14/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.35s/it][AEpoch 14/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.44s/it]

[Î²=2.5] Epoch 14 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=8.979e-01
  layer model_7__forward_module.module.conv2 act-std: mean=4.487e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.038e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.131e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.242e+00

  layer model_5__forward_module.module.conv2 act-std: mean=6.551e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.735e-01Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  layer model_4__forward_module.module.conv2 act-std: mean=8.654e-01
  layer model_3__forward_module.module.conv1 act-std: mean=5.670e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.251e-01
  layer model_2__forward_module.module.conv1 act-std: mean=8.734e-01
  layer model_2__forward_module.module.conv2 act-std: mean=5.500e-01
  layer model_1__forward_module.module.conv1 act-std: mean=8.575e-01
  layer model_1__forward_module.module.conv2 act-std: mean=8.038e-01
  layer model_0__forward_module.module.conv1 act-std: mean=1.008e+00
  layer model_0__forward_module.module.conv2 act-std: mean=9.063e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=9.581e-02
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.956e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.379e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.715e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=9.573e-02
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.012e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.230e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.052e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=2.377e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=5.091e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.409e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=4.075e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=2.701e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=5.713e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.834e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.688e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.331e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=4.561e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.317e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.694e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.165e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=4.142e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=1.916e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=3.601e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=2.184e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=4.188e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=2.934e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=3.545e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.155e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=5.898e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.835e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.361e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.89it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.88it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.89it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.88it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.89it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.89it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  2.05it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.99it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  2.06it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.99it/s]
Epoch 14/32 - Train Loss: 35.279056 - Test Loss: 31.878203
Training epochs:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 14/32 [04:58<06:13, 20.75s/it]Training epochs:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 14/32 [04:58<06:13, 20.75s/it]
Epoch 15/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 15/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 15/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.45s/it][A
Epoch 15/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.46s/it][A
Epoch 15/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:16,  1.46s/it][A
Epoch 15/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:16,  1.46s/it][A
Epoch 15/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.47s/it][A
Epoch 15/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.47s/it][A

Epoch 15/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:13,  1.47s/it][AEpoch 15/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:13,  1.47s/it][A

Epoch 15/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.48s/it][AEpoch 15/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.48s/it][A
Epoch 15/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.48s/it][A
Epoch 15/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.48s/it][A

Epoch 15/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.47s/it][AEpoch 15/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.47s/it][A

Epoch 15/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.47s/it][AEpoch 15/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.47s/it][A
Epoch 15/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:05,  1.47s/it][A
Epoch 15/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:05,  1.47s/it][A
Epoch 15/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.47s/it][A
Epoch 15/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.47s/it][A

Epoch 15/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:02,  1.47s/it][AEpoch 15/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:02,  1.47s/it][A
Epoch 15/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.47s/it][A
Epoch 15/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.47s/it][A
Epoch 15/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.36s/it][AEpoch 15/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.44s/it]

[Î²=2.5] Epoch 15 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.026e-01
  layer model_7__forward_module.module.conv2 act-std: mean=4.699e-01

  layer model_6__forward_module.module.conv1 act-std: mean=1.043e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.159e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.256e+00
  layer model_5__forward_module.module.conv2 act-std: mean=6.858e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.758e-01
  layer model_4__forward_module.module.conv2 act-std: mean=9.113e-01
  layer model_3__forward_module.module.conv1 act-std: mean=5.711e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.224e-01
  layer model_2__forward_module.module.conv1 act-std: mean=8.773e-01
  layer model_2__forward_module.module.conv2 act-std: mean=5.465e-01
Epoch 15/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.36s/it]  layer model_1__forward_module.module.conv1 act-std: mean=8.671e-01[A
  layer model_1__forward_module.module.conv2 act-std: mean=8.230e-01
  layer model_0__forward_module.module.conv1 act-std: mean=1.032e+00
  layer model_0__forward_module.module.conv2 act-std: mean=9.201e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=7.085e-02
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.257e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.302e-01Epoch 15/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.44s/it]

  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.360e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=8.293e-02
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.666e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.258e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.024e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=1.969e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=4.034e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.332e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.400e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.855e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=3.674e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.518e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=3.410e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.891e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=5.953e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.690e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=4.346e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.864e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=5.847e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.422e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=5.101e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.162e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=6.326e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.015e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.282e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=2.525e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=4.589e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.676e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.050e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.92it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.91it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.89it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.88it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.90it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.88it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  2.04it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.99it/s]
Training epochs:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 15/32 [05:19<05:52, 20.76s/it]
Epoch 16/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  2.02it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.97it/s]
Epoch 15/32 - Train Loss: 35.240219 - Test Loss: 31.830540
Training epochs:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 15/32 [05:19<05:52, 20.76s/it]
Epoch 16/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 16/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.48s/it][A
Epoch 16/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.47s/it][A
Epoch 16/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:16,  1.46s/it][A
Epoch 16/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:16,  1.47s/it][A
Epoch 16/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.47s/it][A
Epoch 16/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.47s/it][A
Epoch 16/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:13,  1.47s/it][A
Epoch 16/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:13,  1.47s/it][A
Epoch 16/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.47s/it][A
Epoch 16/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.47s/it][A
Epoch 16/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.47s/it][A
Epoch 16/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.47s/it][A
Epoch 16/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.47s/it][A
Epoch 16/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.47s/it][A

Epoch 16/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.47s/it][AEpoch 16/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.47s/it][A
Epoch 16/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:05,  1.47s/it][A
Epoch 16/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:05,  1.47s/it][A
Epoch 16/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.47s/it][A
Epoch 16/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.47s/it][A

Epoch 16/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:02,  1.47s/it][AEpoch 16/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:02,  1.47s/it][A
Epoch 16/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.47s/it][A
Epoch 16/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.47s/it][A
Epoch 16/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.35s/it][A
Epoch 16/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.44s/it]
Epoch 16/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.35s/it][AEpoch 16/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.44s/it]

[Î²=2.5] Epoch 16 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.070e-01
  layer model_7__forward_module.module.conv2 act-std: mean=4.920e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.050e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.179e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.269e+00
  layer model_5__forward_module.module.conv2 act-std: mean=7.188e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.765e-01
  layer model_4__forward_module.module.conv2 act-std: mean=9.571e-01
  layer model_3__forward_module.module.conv1 act-std: mean=5.747e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.194e-01
  layer model_2__forward_module.module.conv1 act-std: mean=8.828e-01
  layer model_2__forward_module.module.conv2 act-std: mean=5.412e-01
  layer model_1__forward_module.module.conv1 act-std: mean=8.795e-01
  layer model_1__forward_module.module.conv2 act-std: mean=8.539e-01
  layer model_0__forward_module.module.conv1 act-std: mean=1.043e+00
  layer model_0__forward_module.module.conv2 act-std: mean=9.094e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.006e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=2.019e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.327e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.470e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=7.335e-02
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.298e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.141e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.712e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=2.213e-01

  param model_2__forward_module.module.conv1.bias grad-norm: mean=4.684e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.350e-01Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.402e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=2.868e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=6.106e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.870e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.855e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=3.657e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=7.831e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.090e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=5.206e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.747e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=3.114e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.033e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=3.908e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.806e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=7.778e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.592e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.984e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=2.115e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=3.783e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.583e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=3.249e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.86it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.89it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.86it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.89it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.87it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  2.02it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.97it/s]
Training epochs:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 16/32 [05:40<05:32, 20.77s/it]
Epoch 17/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  2.01it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s]
Epoch 16/32 - Train Loss: 35.182782 - Test Loss: 31.789363
Training epochs:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 16/32 [05:40<05:32, 20.77s/it]
Epoch 17/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 17/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.49s/it][A
Epoch 17/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.47s/it][A
Epoch 17/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:16,  1.47s/it][A
Epoch 17/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:16,  1.46s/it][A
Epoch 17/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.47s/it][A
Epoch 17/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.48s/it][A
Epoch 17/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:13,  1.46s/it][A
Epoch 17/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:13,  1.47s/it][A
Epoch 17/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.47s/it]
[AEpoch 17/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.47s/it][A

Epoch 17/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.47s/it][AEpoch 17/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.47s/it][A
Epoch 17/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.47s/it][A
Epoch 17/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.47s/it][A
Epoch 17/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.47s/it][A
Epoch 17/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.47s/it][A
Epoch 17/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:05,  1.47s/it][A
Epoch 17/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:05,  1.47s/it][A
Epoch 17/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.47s/it][A
Epoch 17/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.47s/it][A
Epoch 17/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:02,  1.47s/it][A
Epoch 17/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:02,  1.47s/it][A

Epoch 17/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.47s/it][AEpoch 17/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.47s/it][A

Epoch 17/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.36s/it][AEpoch 17/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.36s/it][AEpoch 17/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.44s/it]

[Î²=2.5] Epoch 17 summary:
Epoch 17/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.44s/it]  input  std: mean=1.814e+00

  layer model_7__forward_module.module.conv1 act-std: mean=9.094e-01
  layer model_7__forward_module.module.conv2 act-std: mean=5.143e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.054e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.199e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.281e+00
  layer model_5__forward_module.module.conv2 act-std: mean=7.493e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.792e-01
  layer model_4__forward_module.module.conv2 act-std: mean=1.003e+00
  layer model_3__forward_module.module.conv1 act-std: mean=5.797e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.149e-01
  layer model_2__forward_module.module.conv1 act-std: mean=8.862e-01
  layer model_2__forward_module.module.conv2 act-std: mean=5.325e-01
  layer model_1__forward_module.module.conv1 act-std: mean=8.935e-01
  layer model_1__forward_module.module.conv2 act-std: mean=8.754e-01
  layer model_0__forward_module.module.conv1 act-std: mean=1.065e+00
  layer model_0__forward_module.module.conv2 act-std: mean=9.165e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.183e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=2.474e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.478e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.755e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=9.530e-02
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.964e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.403e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.244e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=2.433e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=5.062e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.314e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.486e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.966e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=3.997e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.588e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=3.410e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=3.402e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=7.329e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.125e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=5.004e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.737e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=3.154e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.097e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=3.420e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.820e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=7.768e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.540e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=6.000e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=2.604e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=4.918e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.804e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=3.771e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.91it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.90it/s][A

Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.91it/s][AEvaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.90it/s][A

Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.90it/s][AEvaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.90it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  2.05it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.99it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  2.03it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.98it/s]
Epoch 17/32 - Train Loss: 35.136774 - Test Loss: 31.746398
Training epochs:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 17/32 [06:00<05:11, 20.77s/it]
Epoch 18/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 17/32 [06:00<05:11, 20.77s/it]
Epoch 18/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 18/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.47s/it][A
Epoch 18/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.48s/it][A
Epoch 18/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:16,  1.47s/it][A
Epoch 18/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:16,  1.48s/it][A
Epoch 18/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.47s/it][A
Epoch 18/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.48s/it][A
Epoch 18/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:13,  1.48s/it][A
Epoch 18/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:13,  1.48s/it][A
Epoch 18/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.47s/it][A
Epoch 18/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.47s/it][A

Epoch 18/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.47s/it][AEpoch 18/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.47s/it][A
Epoch 18/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.47s/it][A
Epoch 18/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.47s/it][A

Epoch 18/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.47s/it][AEpoch 18/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.47s/it][A
Epoch 18/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:05,  1.47s/it][A
Epoch 18/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:05,  1.47s/it][A

Epoch 18/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.53s/it][AEpoch 18/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.53s/it][A
Epoch 18/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.51s/it][A
Epoch 18/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.51s/it][A

Epoch 18/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.50s/it][AEpoch 18/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.50s/it][A
Epoch 18/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.38s/it][AEpoch 18/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.46s/it]

[Î²=2.5] Epoch 18 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.151e-01
  layer model_7__forward_module.module.conv2 act-std: mean=5.394e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.061e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.213e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.295e+00
  layer model_5__forward_module.module.conv2 act-std: mean=7.798e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.775e-01
  layer model_4__forward_module.module.conv2 act-std: mean=1.052e+00
  layer model_3__forward_module.module.conv1 act-std: mean=5.846e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.133e-01
  layer model_2__forward_module.module.conv1 act-std: mean=8.871e-01
  layer model_2__forward_module.module.conv2 act-std: mean=5.262e-01
  layer model_1__forward_module.module.conv1 act-std: mean=9.062e-01
  layer model_1__forward_module.module.conv2 act-std: mean=9.045e-01
  layer model_0__forward_module.module.conv1 act-std: mean=1.078e+00
  layer model_0__forward_module.module.conv2 act-std: mean=9.088e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.839e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=4.137e-02

  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.031e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=4.212e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.006e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.086e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.517e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.853e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=2.419e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=5.182e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.450e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=4.003e-02
Epoch 18/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.38s/it]  param model_3__forward_module.module.conv1.weight grad-norm: mean=2.658e-01[A
  param model_3__forward_module.module.conv1.bias grad-norm: mean=5.679e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.924e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=5.016e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.964e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=3.892e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.192e-01
Epoch 18/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.46s/it]  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.253e-02

  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.971e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=6.037e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.744e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=5.314e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.305e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=6.762e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.038e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.550e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=4.332e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=8.938e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.465e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=6.471e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.85it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.84it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.87it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.85it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.87it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.86it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  2.03it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.96it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  2.01it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s]
Epoch 18/32 - Train Loss: 35.099482 - Test Loss: 31.708176
Training epochs:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 18/32 [06:21<04:51, 20.85s/it]
Epoch 19/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 18/32 [06:22<04:51, 20.85s/it]
Epoch 19/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 19/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.47s/it][A
Epoch 19/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.46s/it][A
Epoch 19/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:16,  1.47s/it][A
Epoch 19/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:16,  1.47s/it][A
Epoch 19/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.48s/it]
[AEpoch 19/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.48s/it][A

Epoch 19/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:13,  1.48s/it][AEpoch 19/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:13,  1.48s/it][A
Epoch 19/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.48s/it][A
Epoch 19/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.48s/it][A
Epoch 19/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.48s/it][A
Epoch 19/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.48s/it][A
Epoch 19/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.48s/it][A
Epoch 19/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.48s/it][A
Epoch 19/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.47s/it][A
Epoch 19/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.47s/it][A
Epoch 19/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:05,  1.47s/it][A
Epoch 19/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:05,  1.47s/it][A

Epoch 19/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.47s/it]Epoch 19/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.47s/it][A[A

Epoch 19/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:02,  1.47s/it][AEpoch 19/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:02,  1.47s/it][A
Epoch 19/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.47s/it][A
Epoch 19/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.47s/it][A
Epoch 19/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.36s/it][AEpoch 19/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.45s/it]

Epoch 19/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.36s/it][AEpoch 19/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.44s/it]

[Î²=2.5] Epoch 19 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.273e-01
  layer model_7__forward_module.module.conv2 act-std: mean=5.664e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.065e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.239e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.303e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.070e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.782e-01
  layer model_4__forward_module.module.conv2 act-std: mean=1.095e+00
  layer model_3__forward_module.module.conv1 act-std: mean=5.896e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.086e-01
  layer model_2__forward_module.module.conv1 act-std: mean=8.924e-01
  layer model_2__forward_module.module.conv2 act-std: mean=5.206e-01
  layer model_1__forward_module.module.conv1 act-std: mean=9.244e-01
  layer model_1__forward_module.module.conv2 act-std: mean=9.323e-01
  layer model_0__forward_module.module.conv1 act-std: mean=1.093e+00
  layer model_0__forward_module.module.conv2 act-std: mean=9.089e-01

  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.154e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=2.410e-02Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.527e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.828e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=7.582e-02
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.457e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.160e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.465e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.309e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=7.103e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.706e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=4.825e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.406e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=7.352e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.071e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=5.548e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.727e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=3.128e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=1.988e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=2.721e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.372e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=4.688e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.465e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=4.581e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=2.663e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=4.978e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=3.670e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=4.492e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=2.299e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=4.148e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.855e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=3.787e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.83it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.83it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.86it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.86it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.86it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.86it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  2.01it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.99it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s]
Epoch 19/32 - Train Loss: 35.045712 - Test Loss: 31.667531
Training epochs:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 19/32 [06:42<04:31, 20.85s/it]
Epoch 20/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 19/32 [06:42<04:31, 20.85s/it]
Epoch 20/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 20/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.48s/it][A
Epoch 20/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.49s/it][A

Epoch 20/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:16,  1.47s/it][AEpoch 20/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:16,  1.47s/it][A

Epoch 20/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.47s/it][AEpoch 20/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.47s/it][A
Epoch 20/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:13,  1.47s/it][A
Epoch 20/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:13,  1.47s/it][A
Epoch 20/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.47s/it][A
Epoch 20/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.47s/it][A

Epoch 20/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.48s/it][AEpoch 20/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.48s/it][A
Epoch 20/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.48s/it][A
Epoch 20/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.48s/it][A
Epoch 20/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.48s/it][A
Epoch 20/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.48s/it][A
Epoch 20/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:05,  1.48s/it][A
Epoch 20/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:05,  1.48s/it][A
Epoch 20/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.48s/it][A
Epoch 20/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.48s/it][A
Epoch 20/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:02,  1.48s/it][A
Epoch 20/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:02,  1.48s/it][A
Epoch 20/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.48s/it][A
Epoch 20/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.48s/it][A

Epoch 20/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.36s/it][AEpoch 20/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.36s/it]Epoch 20/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.45s/it][A
Epoch 20/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.45s/it]

[Î²=2.5] Epoch 20 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.318e-01
  layer model_7__forward_module.module.conv2 act-std: mean=5.905e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.071e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.250e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.316e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.304e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.751e-01
  layer model_4__forward_module.module.conv2 act-std: mean=1.137e+00
  layer model_3__forward_module.module.conv1 act-std: mean=5.944e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.064e-01
  layer model_2__forward_module.module.conv1 act-std: mean=8.974e-01
  layer model_2__forward_module.module.conv2 act-std: mean=5.133e-01
  layer model_1__forward_module.module.conv1 act-std: mean=9.416e-01
  layer model_1__forward_module.module.conv2 act-std: mean=9.693e-01
  layer model_0__forward_module.module.conv1 act-std: mean=1.105e+00
  layer model_0__forward_module.module.conv2 act-std: mean=9.026e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=8.196e-02
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.566e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.444e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.373e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=8.250e-02
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.588e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.351e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.887e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.967e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=8.676e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.872e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=5.720e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.626e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=7.769e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.273e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=6.155e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.776e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=3.348e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.443e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.461e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.618e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=5.469e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.843e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=5.310e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=2.693e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=4.975e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=3.998e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.083e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=2.724e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=5.454e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.057e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.442e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.89it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.88it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.88it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.87it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.90it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.89it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  2.05it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.99it/s]
Training epochs:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 20/32 [07:03<04:10, 20.85s/it]
Epoch 21/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  2.03it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.97it/s]
Epoch 20/32 - Train Loss: 35.016492 - Test Loss: 31.630173
Training epochs:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 20/32 [07:03<04:10, 20.85s/it]
Epoch 21/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 21/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.47s/it][A
Epoch 21/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.49s/it][A

Epoch 21/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:16,  1.49s/it][AEpoch 21/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:16,  1.48s/it][A

Epoch 21/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.48s/it][AEpoch 21/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.48s/it][A
Epoch 21/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:13,  1.48s/it][A
Epoch 21/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:13,  1.48s/it][A
Epoch 21/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 21/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 21/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.51s/it][A
Epoch 21/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.51s/it][A
Epoch 21/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.50s/it][A
Epoch 21/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.50s/it][A
Epoch 21/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.49s/it][A
Epoch 21/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.49s/it][A

Epoch 21/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:05,  1.49s/it][AEpoch 21/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:05,  1.49s/it][A

Epoch 21/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.49s/it][AEpoch 21/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.49s/it][A

Epoch 21/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:02,  1.48s/it][AEpoch 21/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:02,  1.48s/it][A

Epoch 21/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.48s/it][AEpoch 21/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.48s/it][A
Epoch 21/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.36s/it][AEpoch 21/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.46s/it]

[Î²=2.5] Epoch 21 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.430e-01

  layer model_7__forward_module.module.conv2 act-std: mean=6.144e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.076e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.274e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.323e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.600e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.766e-01
  layer model_4__forward_module.module.conv2 act-std: mean=1.184e+00
  layer model_3__forward_module.module.conv1 act-std: mean=5.987e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.072e-01
  layer model_2__forward_module.module.conv1 act-std: mean=9.031e-01
  layer model_2__forward_module.module.conv2 act-std: mean=5.084e-01
  layer model_1__forward_module.module.conv1 act-std: mean=9.595e-01
  layer model_1__forward_module.module.conv2 act-std: mean=1.010e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.120e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.990e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.762e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=3.934e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.969e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.744e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=8.690e-02
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.634e-02Epoch 21/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.36s/it]
[A  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.530e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.333e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.756e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=8.135e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.793e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=5.404e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.452e-01
Epoch 21/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.46s/it]  param model_3__forward_module.module.conv1.bias grad-norm: mean=7.441e-02

  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.138e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=5.618e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.612e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=2.705e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.112e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=2.711e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.495e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=5.133e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.617e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=4.768e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=2.552e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=5.104e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=3.408e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=4.147e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.239e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=6.409e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.355e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.947e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.87it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.84it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.89it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.87it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.88it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.85it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  2.01it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.96it/s]
Training epochs:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 21/32 [07:24<03:49, 20.91s/it]
Epoch 22/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.98it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s]
Epoch 21/32 - Train Loss: 34.955554 - Test Loss: 31.590119
Training epochs:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 21/32 [07:24<03:50, 20.91s/it]
Epoch 22/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 22/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.50s/it][A
Epoch 22/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.47s/it][A
Epoch 22/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:16,  1.47s/it][A
Epoch 22/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:16,  1.48s/it][A
Epoch 22/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.47s/it][A
Epoch 22/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.48s/it][A
Epoch 22/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:13,  1.47s/it][A
Epoch 22/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:13,  1.48s/it][A

Epoch 22/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.47s/it][AEpoch 22/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.47s/it][A
Epoch 22/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.47s/it][A
Epoch 22/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.47s/it][A
Epoch 22/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.47s/it][A
Epoch 22/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.47s/it][A
Epoch 22/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.47s/it][A
Epoch 22/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.47s/it][A
Epoch 22/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:05,  1.47s/it][A
Epoch 22/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:05,  1.47s/it][A
Epoch 22/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.47s/it][A
Epoch 22/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.47s/it][A
Epoch 22/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:02,  1.47s/it][A
Epoch 22/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:02,  1.47s/it][A
Epoch 22/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.47s/it][A
Epoch 22/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.47s/it][A
Epoch 22/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.36s/it][AEpoch 22/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.44s/it]

Epoch 22/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.36s/it][AEpoch 22/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.44s/it]

[Î²=2.5] Epoch 22 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.495e-01
  layer model_7__forward_module.module.conv2 act-std: mean=6.437e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.078e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.287e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.331e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.817e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.786e-01
  layer model_4__forward_module.module.conv2 act-std: mean=1.226e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.037e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.044e-01
  layer model_2__forward_module.module.conv1 act-std: mean=9.081e-01
  layer model_2__forward_module.module.conv2 act-std: mean=4.991e-01
  layer model_1__forward_module.module.conv1 act-std: mean=9.747e-01
  layer model_1__forward_module.module.conv2 act-std: mean=1.049e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.129e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.933e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.644e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=3.702e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.815e-01

  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.298e-02
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  param model_1__forward_module.module.conv1.weight grad-norm: mean=8.190e-02[A
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.435e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.449e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.041e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=4.418e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=9.825e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.867e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=6.052e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=4.160e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=9.219e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.370e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=6.535e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.758e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=6.007e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.857e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=4.052e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.841e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=3.471e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.146e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=3.791e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.945e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=8.165e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.921e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=6.291e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=2.810e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=5.441e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.193e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=3.979e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.92it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.89it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.89it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.87it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.87it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.86it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  2.02it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.97it/s]
Training epochs:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 22/32 [07:45<03:28, 20.88s/it]

Epoch 23/32:   0%|          | 0/13 [00:00<?, ?it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  2.01it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s]
Epoch 22/32 - Train Loss: 34.902324 - Test Loss: 31.554206
Training epochs:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 22/32 [07:45<03:28, 20.88s/it]
Epoch 23/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 23/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.47s/it][A
Epoch 23/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.49s/it][A

Epoch 23/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:16,  1.47s/it][AEpoch 23/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:16,  1.46s/it][A
Epoch 23/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.47s/it][A
Epoch 23/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.48s/it][A
Epoch 23/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:13,  1.48s/it][A
Epoch 23/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:13,  1.48s/it][A

Epoch 23/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.48s/it][AEpoch 23/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.48s/it][A

Epoch 23/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.48s/it]Epoch 23/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.48s/it][A[A
Epoch 23/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.48s/it][A
Epoch 23/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.48s/it][A

Epoch 23/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.48s/it][AEpoch 23/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.48s/it][A

Epoch 23/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:05,  1.47s/it][AEpoch 23/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:05,  1.48s/it][A

Epoch 23/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.47s/it][AEpoch 23/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.47s/it][A

Epoch 23/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:02,  1.48s/it][AEpoch 23/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:02,  1.48s/it][A

Epoch 23/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.48s/it][AEpoch 23/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.48s/it][A
Epoch 23/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.37s/it][AEpoch 23/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.45s/it]

[Î²=2.5] Epoch 23 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.594e-01
  layer model_7__forward_module.module.conv2 act-std: mean=6.660e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.085e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.295e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.339e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.024e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.773e-01
  layer model_4__forward_module.module.conv2 act-std: mean=1.268e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.084e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.047e-01
  layer model_2__forward_module.module.conv1 act-std: mean=9.189e-01
  layer model_2__forward_module.module.conv2 act-std: mean=4.977e-01
  layer model_1__forward_module.module.conv1 act-std: mean=9.877e-01
  layer model_1__forward_module.module.conv2 act-std: mean=1.095e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.139e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.872e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=8.983e-02
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.724e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.538e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.396e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=8.119e-02
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.488e-02

  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.293e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.384e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=1.532e-01
Epoch 23/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.37s/it]  param model_2__forward_module.module.conv1.bias grad-norm: mean=2.939e-02[A
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.166e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=2.469e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.732e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=3.293e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.518e-01Epoch 23/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.45s/it]

  param model_3__forward_module.module.conv2.bias grad-norm: mean=3.076e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.571e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=5.447e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.635e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.743e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.480e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=5.111e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.493e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=4.534e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.016e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=6.138e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=3.511e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=4.301e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=2.319e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=4.390e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.786e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=3.283e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.88it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.87it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.87it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.86it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.87it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.86it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  2.01it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s]
Training epochs:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 23/32 [08:06<03:08, 20.89s/it]
Epoch 24/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.97it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s]
Epoch 23/32 - Train Loss: 34.879562 - Test Loss: 31.520143
Training epochs:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 23/32 [08:06<03:08, 20.89s/it]
Epoch 24/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 24/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][A
Epoch 24/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.49s/it][A
Epoch 24/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:16,  1.49s/it][A
Epoch 24/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:16,  1.48s/it][A

Epoch 24/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.48s/it][AEpoch 24/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.48s/it][A
Epoch 24/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:13,  1.48s/it][A
Epoch 24/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:13,  1.48s/it][A
Epoch 24/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.48s/it][A
Epoch 24/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.48s/it][A

Epoch 24/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.48s/it][AEpoch 24/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.48s/it][A

Epoch 24/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.48s/it][AEpoch 24/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.48s/it][A

Epoch 24/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.48s/it][AEpoch 24/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.48s/it][A
Epoch 24/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:05,  1.48s/it][A
Epoch 24/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:05,  1.48s/it][A

Epoch 24/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.48s/it][AEpoch 24/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.48s/it][A
Epoch 24/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:02,  1.48s/it][A
Epoch 24/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:02,  1.48s/it][A
Epoch 24/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.49s/it][A
Epoch 24/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.49s/it][A
Epoch 24/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.37s/it][AEpoch 24/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.45s/it]

Epoch 24/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.37s/it][AEpoch 24/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.45s/it]

[Î²=2.5] Epoch 24 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.675e-01
  layer model_7__forward_module.module.conv2 act-std: mean=6.875e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.087e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.308e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.345e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.201e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.825e-01
  layer model_4__forward_module.module.conv2 act-std: mean=1.312e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.128e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.047e-01
  layer model_2__forward_module.module.conv1 act-std: mean=9.241e-01
  layer model_2__forward_module.module.conv2 act-std: mean=4.958e-01

  layer model_1__forward_module.module.conv1 act-std: mean=1.008e+00
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  layer model_1__forward_module.module.conv2 act-std: mean=1.136e+00[A
  layer model_0__forward_module.module.conv1 act-std: mean=1.143e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.815e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.654e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=3.608e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.835e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.310e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=8.958e-02
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.717e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.568e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.088e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=1.981e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=4.030e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.378e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.197e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.848e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=3.667e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.607e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=3.470e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.106e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=4.128e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.533e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.417e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.764e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=3.458e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.149e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=3.534e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=2.199e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=3.657e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=3.105e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=3.545e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=2.523e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=5.070e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.106e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=3.720e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.86it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.84it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.90it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.87it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.89it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.86it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  2.03it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.97it/s]
Training epochs:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 24/32 [08:27<02:47, 20.91s/it]
Epoch 25/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  2.01it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s]
Epoch 24/32 - Train Loss: 34.846110 - Test Loss: 31.486658
Training epochs:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 24/32 [08:27<02:47, 20.91s/it]
Epoch 25/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 25/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.48s/it][A
Epoch 25/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][A
Epoch 25/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:16,  1.49s/it][A
Epoch 25/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:16,  1.48s/it][A
Epoch 25/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.48s/it][A
Epoch 25/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.48s/it][A
Epoch 25/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:13,  1.47s/it][A
Epoch 25/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:13,  1.47s/it][A

Epoch 25/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.47s/it][AEpoch 25/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.47s/it][A
Epoch 25/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.47s/it][A
Epoch 25/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.47s/it][A
Epoch 25/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.47s/it][A
Epoch 25/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.47s/it][A
Epoch 25/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.47s/it][A
Epoch 25/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.47s/it][A

Epoch 25/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:05,  1.47s/it][AEpoch 25/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:05,  1.47s/it][A

Epoch 25/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.47s/it][AEpoch 25/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.47s/it][A

Epoch 25/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:02,  1.48s/it][AEpoch 25/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:02,  1.48s/it][A

Epoch 25/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.48s/it][AEpoch 25/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.48s/it][A

Epoch 25/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.36s/it]Epoch 25/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.36s/it][A[AEpoch 25/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.45s/it]
Epoch 25/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.44s/it]

[Î²=2.5] Epoch 25 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.708e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.104e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.092e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.322e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.356e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.360e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.852e-01
  layer model_4__forward_module.module.conv2 act-std: mean=1.354e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.164e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.055e-01
  layer model_2__forward_module.module.conv1 act-std: mean=9.337e-01
  layer model_2__forward_module.module.conv2 act-std: mean=4.949e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.025e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.188e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.158e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.921e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.259e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=2.606e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.382e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.158e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=8.396e-02
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.533e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.371e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.407e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=2.597e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=5.670e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.464e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.766e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.481e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=7.477e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.005e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=5.198e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.653e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=3.171e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.058e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=2.487e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.218e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=4.457e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.529e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=4.305e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.297e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=6.761e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.192e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.233e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=2.227e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=4.192e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.242e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=3.735e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.85it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.83it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.85it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.83it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.84it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.84it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.99it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.99it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s]
Epoch 25/32 - Train Loss: 34.799874 - Test Loss: 31.452053
Training epochs:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 25/32 [08:48<02:26, 20.91s/it]
Epoch 26/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 25/32 [08:48<02:26, 20.90s/it]
Epoch 26/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 26/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.47s/it][A
Epoch 26/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.47s/it][A
Epoch 26/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:16,  1.48s/it][A
Epoch 26/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:16,  1.48s/it][A

Epoch 26/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.48s/it][AEpoch 26/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.48s/it][A

Epoch 26/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:13,  1.48s/it][AEpoch 26/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:13,  1.48s/it][A
Epoch 26/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.48s/it][A
Epoch 26/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.48s/it][A

Epoch 26/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.48s/it][AEpoch 26/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.48s/it][A

Epoch 26/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.48s/it][AEpoch 26/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.48s/it][A
Epoch 26/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.48s/it][A
Epoch 26/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.48s/it][A

Epoch 26/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:05,  1.48s/it][AEpoch 26/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:05,  1.48s/it][A
Epoch 26/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.48s/it][A
Epoch 26/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.48s/it][A

Epoch 26/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:02,  1.48s/it][AEpoch 26/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:02,  1.48s/it][A
Epoch 26/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.48s/it][A
Epoch 26/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.48s/it][A
Epoch 26/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.37s/it][AEpoch 26/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.45s/it]

[Î²=2.5] Epoch 26 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.764e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.327e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.095e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.325e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.361e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.525e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.891e-01
  layer model_4__forward_module.module.conv2 act-std: mean=1.399e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.206e-01

  layer model_3__forward_module.module.conv2 act-std: mean=4.074e-01
  layer model_2__forward_module.module.conv1 act-std: mean=9.394e-01
  layer model_2__forward_module.module.conv2 act-std: mean=4.946e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.038e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.228e+00Epoch 26/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.37s/it]
[A  layer model_0__forward_module.module.conv1 act-std: mean=1.163e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.781e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.363e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=2.897e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.794e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.154e-02
Epoch 26/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.45s/it]  param model_1__forward_module.module.conv1.weight grad-norm: mean=8.669e-02

  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.572e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.661e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.130e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.051e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=6.589e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.635e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=4.389e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=2.958e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=6.409e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.007e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.818e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.247e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=4.650e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.511e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.471e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.019e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=4.106e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.234e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=3.778e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.301e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=6.927e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=3.748e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=4.682e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=2.576e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=4.999e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.241e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=3.611e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.91it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.90it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.89it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.86it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.87it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.85it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  2.01it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.96it/s]
Training epochs:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 26/32 [09:09<02:05, 20.91s/it]
Epoch 27/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.98it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s]
Epoch 26/32 - Train Loss: 34.784615 - Test Loss: 31.423636
Training epochs:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 26/32 [09:09<02:05, 20.91s/it]
Epoch 27/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 27/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.47s/it][A
Epoch 27/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.49s/it][A

Epoch 27/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:16,  1.48s/it][AEpoch 27/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:16,  1.49s/it][A
Epoch 27/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.49s/it][A
Epoch 27/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.49s/it][A
Epoch 27/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:13,  1.49s/it][A
Epoch 27/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:13,  1.49s/it][A

Epoch 27/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.49s/it][AEpoch 27/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.49s/it][A
Epoch 27/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.48s/it][A
Epoch 27/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.48s/it][A
Epoch 27/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.48s/it][A
Epoch 27/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.48s/it][A
Epoch 27/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.48s/it][A
Epoch 27/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.48s/it][A
Epoch 27/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:05,  1.48s/it][A
Epoch 27/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:05,  1.48s/it][A
Epoch 27/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.48s/it][A
Epoch 27/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.48s/it][A
Epoch 27/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:02,  1.48s/it][A
Epoch 27/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:02,  1.49s/it][A
Epoch 27/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.49s/it][A
Epoch 27/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.49s/it][A

Epoch 27/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.37s/it][AEpoch 27/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.45s/it]

[Î²=2.5] Epoch 27 summary:
  input  std: mean=1.814e+00Epoch 27/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.37s/it]
[A  layer model_7__forward_module.module.conv1 act-std: mean=9.766e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.446e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.097e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.334e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.368e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.674e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.930e-01
Epoch 27/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.46s/it]  layer model_4__forward_module.module.conv2 act-std: mean=1.440e+00

  layer model_3__forward_module.module.conv1 act-std: mean=6.243e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.084e-01
  layer model_2__forward_module.module.conv1 act-std: mean=9.497e-01
  layer model_2__forward_module.module.conv2 act-std: mean=4.928e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.052e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.272e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.177e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.809e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.939e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=4.371e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.039e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.567e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.121e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.376e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.715e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.174e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=4.056e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=9.125e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.854e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=5.453e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=4.214e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=9.406e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.304e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=6.338e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=3.166e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=6.653e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.218e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=4.568e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.117e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=4.360e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.562e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=4.161e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.937e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=8.119e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.804e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=6.215e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.584e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=7.440e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.724e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=5.025e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.89it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.87it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.87it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.85it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.88it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.87it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  2.03it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.97it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  2.03it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.96it/s]
Epoch 27/32 - Train Loss: 34.743994 - Test Loss: 31.393490
Training epochs:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 27/32 [09:30<01:44, 20.93s/it]
Epoch 28/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 27/32 [09:30<01:44, 20.93s/it]
Epoch 28/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 28/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.48s/it][A
Epoch 28/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.49s/it][A
Epoch 28/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:16,  1.48s/it][A
Epoch 28/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:16,  1.47s/it][A

Epoch 28/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.47s/it]Epoch 28/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.48s/it][A[A
Epoch 28/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:13,  1.48s/it][A
Epoch 28/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:13,  1.48s/it][A

Epoch 28/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.48s/it][AEpoch 28/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.48s/it][A

Epoch 28/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.48s/it][AEpoch 28/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.48s/it][A
Epoch 28/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.48s/it][A
Epoch 28/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.48s/it][A

Epoch 28/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.48s/it]Epoch 28/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.48s/it][A[A

Epoch 28/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:05,  1.48s/it][AEpoch 28/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:05,  1.48s/it][A

Epoch 28/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.48s/it][AEpoch 28/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.48s/it][A

Epoch 28/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:02,  1.48s/it][AEpoch 28/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:02,  1.49s/it][A
Epoch 28/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.48s/it][A
Epoch 28/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.49s/it][A
Epoch 28/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.37s/it][AEpoch 28/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.45s/it]

Epoch 28/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.37s/it][AEpoch 28/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.45s/it]

[Î²=2.5] Epoch 28 summary:
  input  std: mean=1.813e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.800e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.622e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.102e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.341e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.373e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.761e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.976e-01
  layer model_4__forward_module.module.conv2 act-std: mean=1.479e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.276e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.099e-01
  layer model_2__forward_module.module.conv1 act-std: mean=9.552e-01

  layer model_2__forward_module.module.conv2 act-std: mean=4.927e-01
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  layer model_1__forward_module.module.conv1 act-std: mean=1.066e+00[A
  layer model_1__forward_module.module.conv2 act-std: mean=1.308e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.179e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.860e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.534e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=3.372e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.694e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.739e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=9.063e-02
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.699e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.523e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.624e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.565e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=7.780e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.726e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=4.787e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.631e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=7.779e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.092e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=5.399e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=4.297e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=9.415e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=4.244e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=6.022e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.043e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=4.048e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.389e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=4.048e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=5.287e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.115e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=6.359e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=8.418e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.151e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=6.276e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.525e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.438e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.85it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.84it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.83it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.85it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.84it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  2.03it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.96it/s]
Training epochs:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 28/32 [09:51<01:23, 20.94s/it]
Epoch 29/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  2.02it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s]
Epoch 28/32 - Train Loss: 34.736004 - Test Loss: 31.372321
Training epochs:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 28/32 [09:51<01:23, 20.94s/it]
Epoch 29/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 29/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.50s/it][A
Epoch 29/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.48s/it][A

Epoch 29/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:16,  1.49s/it][AEpoch 29/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:16,  1.48s/it][A

Epoch 29/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.48s/it][AEpoch 29/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.48s/it][A
Epoch 29/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:13,  1.48s/it][A
Epoch 29/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:13,  1.48s/it][A
Epoch 29/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.48s/it][A
Epoch 29/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.48s/it][A
Epoch 29/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.48s/it][A
Epoch 29/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.48s/it][A
Epoch 29/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.48s/it][A
Epoch 29/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.48s/it][A

Epoch 29/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.48s/it][AEpoch 29/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.48s/it][A

Epoch 29/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:05,  1.48s/it][AEpoch 29/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:05,  1.48s/it][A

Epoch 29/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.48s/it][AEpoch 29/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.48s/it][A

Epoch 29/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:02,  1.48s/it][AEpoch 29/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:02,  1.48s/it][A

Epoch 29/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.48s/it][AEpoch 29/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.48s/it][A
Epoch 29/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.36s/it][AEpoch 29/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.45s/it]

[Î²=2.5] Epoch 29 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.815e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.741e-01

  layer model_6__forward_module.module.conv1 act-std: mean=1.104e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.343e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.381e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.879e-01
  layer model_4__forward_module.module.conv1 act-std: mean=1.003e+00
  layer model_4__forward_module.module.conv2 act-std: mean=1.519e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.317e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.127e-01
  layer model_2__forward_module.module.conv1 act-std: mean=9.606e-01
  layer model_2__forward_module.module.conv2 act-std: mean=4.966e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.079e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.356e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.194e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.886e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.938e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=6.765e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.159e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.853e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.363e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.951e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.707e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.955e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=2.448e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=5.110e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.494e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.436e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=2.722e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=5.770e-02Epoch 29/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.36s/it]
[A  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.862e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.179e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=6.672e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.499e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=6.711e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=9.695e-02Epoch 29/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.45s/it]

  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.043e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=4.001e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.509e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=4.342e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=6.306e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.364e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=8.522e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.122e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=2.816e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=5.597e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.746e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.373e-02


Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][AEvaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.85it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.83it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.85it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.84it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.84it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.82it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.97it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.96it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s]
Epoch 29/32 - Train Loss: 34.689403 - Test Loss: 31.347947
Training epochs:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 29/32 [10:12<01:02, 20.95s/it]
Epoch 30/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 29/32 [10:12<01:02, 20.95s/it]
Epoch 30/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 30/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.49s/it][AEpoch 30/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.48s/it][A
Epoch 30/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:16,  1.48s/it][A
Epoch 30/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:16,  1.48s/it][A
Epoch 30/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.48s/it][A
Epoch 30/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.48s/it][A

Epoch 30/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:13,  1.49s/it][AEpoch 30/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:13,  1.49s/it][A
Epoch 30/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.49s/it][A
Epoch 30/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.49s/it][A

Epoch 30/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.49s/it][AEpoch 30/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.49s/it][A
Epoch 30/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.48s/it][A
Epoch 30/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.48s/it][A
Epoch 30/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.48s/it][A
Epoch 30/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.48s/it][A

Epoch 30/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:05,  1.48s/it][AEpoch 30/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:05,  1.48s/it][A
Epoch 30/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.48s/it][A
Epoch 30/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.48s/it][A
Epoch 30/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:02,  1.48s/it][A
Epoch 30/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:02,  1.48s/it][A

Epoch 30/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.49s/it]Epoch 30/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.49s/it][A[A

Epoch 30/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.37s/it][AEpoch 30/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.46s/it]
Epoch 30/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.37s/it][AEpoch 30/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.45s/it]

[Î²=2.5] Epoch 30 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.836e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.858e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.106e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.354e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.385e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.981e-01
  layer model_4__forward_module.module.conv1 act-std: mean=1.006e+00
  layer model_4__forward_module.module.conv2 act-std: mean=1.559e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.357e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.144e-01
  layer model_2__forward_module.module.conv1 act-std: mean=9.668e-01
  layer model_2__forward_module.module.conv2 act-std: mean=4.941e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.088e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.380e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.197e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.896e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.543e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=5.816e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.243e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.993e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.055e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.002e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.936e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.527e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.635e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=7.932e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.798e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=5.089e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.370e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=7.244e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.137e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=5.277e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=3.413e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=7.288e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.757e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=5.248e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.853e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=3.426e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.888e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=4.866e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=4.720e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=9.949e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=6.238e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=8.037e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.843e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=8.059e-02

  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.915e-01
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  param model_7__forward_module.module.conv2.bias grad-norm: mean=5.187e-02[A

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.84it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.82it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.85it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.83it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.84it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.83it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  2.01it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s]
Training epochs:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 30/32 [10:33<00:41, 20.96s/it]
Epoch 31/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.98it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s]
Epoch 30/32 - Train Loss: 34.643629 - Test Loss: 31.318773
Training epochs:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 30/32 [10:33<00:41, 20.97s/it]
Epoch 31/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 31/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.47s/it][A
Epoch 31/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.50s/it][A
Epoch 31/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:16,  1.49s/it][A
Epoch 31/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:16,  1.48s/it][A

Epoch 31/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.49s/it][AEpoch 31/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.49s/it][A

Epoch 31/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:13,  1.49s/it][AEpoch 31/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:13,  1.49s/it][A
Epoch 31/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.49s/it][A
Epoch 31/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.49s/it][A

Epoch 31/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.49s/it][AEpoch 31/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.49s/it][A

Epoch 31/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.49s/it][AEpoch 31/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.49s/it][A

Epoch 31/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.49s/it][AEpoch 31/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.49s/it][A
Epoch 31/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:05,  1.49s/it][A
Epoch 31/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:05,  1.49s/it][A
Epoch 31/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.50s/it][A
Epoch 31/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.50s/it][A
Epoch 31/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:02,  1.50s/it][A
Epoch 31/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:02,  1.50s/it][A
Epoch 31/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.49s/it][A
Epoch 31/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.49s/it][A
Epoch 31/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.37s/it][AEpoch 31/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.46s/it]

[Î²=2.5] Epoch 31 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.801e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.967e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.110e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.348e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.392e+00
  layer model_5__forward_module.module.conv2 act-std: mean=1.003e+00
  layer model_4__forward_module.module.conv1 act-std: mean=1.010e+00
  layer model_4__forward_module.module.conv2 act-std: mean=1.598e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.389e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.159e-01
  layer model_2__forward_module.module.conv1 act-std: mean=9.721e-01
  layer model_2__forward_module.module.conv2 act-std: mean=4.959e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.102e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.411e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.210e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.899e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.756e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=3.886e-02

  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.807e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.021e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=9.755e-02
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.842e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.756e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.915e-02Epoch 31/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.37s/it]
[A  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.556e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=7.737e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.735e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=4.924e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.243e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=6.887e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.104e-01Epoch 31/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.46s/it]

  param model_3__forward_module.module.conv2.bias grad-norm: mean=5.179e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=4.059e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=9.032e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=4.232e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=5.936e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.776e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=5.890e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=3.272e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=5.525e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=4.725e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.010e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=5.650e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=7.281e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=2.561e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=4.659e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.544e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=3.849e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.86it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.85it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.87it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.85it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.86it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.84it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  2.02it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.96it/s]
Training epochs:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 31/32 [10:54<00:20, 20.99s/it]
Epoch 32/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  2.00it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s]
Epoch 31/32 - Train Loss: 34.626838 - Test Loss: 31.293490
Training epochs:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 31/32 [10:54<00:20, 21.00s/it]
Epoch 32/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 32/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.47s/it][A
Epoch 32/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.49s/it][A
Epoch 32/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:16,  1.49s/it][A
Epoch 32/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:16,  1.48s/it][A
Epoch 32/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.48s/it][A
Epoch 32/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  1.48s/it][A

Epoch 32/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:13,  1.48s/it][AEpoch 32/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:13,  1.48s/it][A
Epoch 32/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.48s/it][A
Epoch 32/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  1.49s/it][A

Epoch 32/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.49s/it][AEpoch 32/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  1.49s/it][A
Epoch 32/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.48s/it][A
Epoch 32/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  1.48s/it][A

Epoch 32/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.49s/it][AEpoch 32/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  1.49s/it][A
Epoch 32/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:05,  1.49s/it][A
Epoch 32/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:05,  1.49s/it][A

Epoch 32/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.49s/it][AEpoch 32/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  1.49s/it][A

Epoch 32/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:02,  1.49s/it][AEpoch 32/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:02,  1.49s/it][A

Epoch 32/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.49s/it][AEpoch 32/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  1.49s/it][A
Epoch 32/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.37s/it][AEpoch 32/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.46s/it]

[Î²=2.5] Epoch 32 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.851e-01
  layer model_7__forward_module.module.conv2 act-std: mean=8.041e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.112e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.363e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.398e+00
  layer model_5__forward_module.module.conv2 act-std: mean=1.010e+00
  layer model_4__forward_module.module.conv1 act-std: mean=1.014e+00
  layer model_4__forward_module.module.conv2 act-std: mean=1.634e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.422e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.200e-01
  layer model_2__forward_module.module.conv1 act-std: mean=9.760e-01
  layer model_2__forward_module.module.conv2 act-std: mean=4.995e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.115e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.442e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.215e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.919e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.492e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=3.218e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.563e-01

  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.519e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=9.715e-02
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.897e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.538e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.386e-02Epoch 32/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.37s/it]
[A  param model_2__forward_module.module.conv1.weight grad-norm: mean=2.580e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=5.321e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.583e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.880e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=2.664e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=5.505e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.924e-01
Epoch 32/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:18<00:00,  1.46s/it]  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.263e-02

  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.278e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=4.463e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.713e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.347e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.296e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=4.598e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.718e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=4.673e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.581e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=7.293e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=3.863e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=4.741e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.294e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=6.759e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.714e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.727e-02


Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][AEvaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.84it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.83it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.85it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.84it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.84it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.84it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.99it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s]
Epoch 32/32 - Train Loss: 34.629493 - Test Loss: 31.273519

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.99it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s]
Training epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [11:15<00:00, 21.00s/it]Training epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [11:15<00:00, 21.10s/it]
Training epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [11:15<00:00, 21.01s/it]Training epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [11:15<00:00, 21.10s/it]
Loaded best models from epoch 32 with loss 31.256616

>>> Completed beta = 2.5
>>> Time for this beta: 0:11:15
>>> Total elapsed time: 0:11:17
==================================================
Loaded data shape: torch.Size([4096, 2, 64, 64])
Training data shape: torch.Size([3276, 2, 64, 64])
Testing data shape: torch.Size([820, 2, 64, 64])

>>> Training the model at beta =  3.0

>>> Training the model at beta = 3.0

Training epochs:   0%|          | 0/32 [00:00<?, ?it/s]Training epochs:   0%|          | 0/32 [00:00<?, ?it/s]

Epoch 1/32:   0%|          | 0/13 [00:00<?, ?it/s][AEpoch 1/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 1/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.48s/it][AEpoch 1/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.48s/it][A
Epoch 1/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:16,  1.50s/it][A
Epoch 1/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:16,  1.50s/it][A
Epoch 1/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 1/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 1/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 1/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A

Epoch 1/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.51s/it][AEpoch 1/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.51s/it][A

Epoch 1/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.51s/it][AEpoch 1/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.51s/it][A
Epoch 1/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.50s/it][A
Epoch 1/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.50s/it][A

Epoch 1/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.50s/it][AEpoch 1/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.50s/it][A

Epoch 1/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.51s/it][AEpoch 1/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.51s/it][A
Epoch 1/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.51s/it][A
Epoch 1/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 1/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.56s/it][A
Epoch 1/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.56s/it][A
Epoch 1/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 1/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 1/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 1/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

[Î²=3.0] Epoch 1 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.703e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.632e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.117e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.089e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.417e+00

  layer model_5__forward_module.module.conv2 act-std: mean=9.764e-01
  layer model_4__forward_module.module.conv1 act-std: mean=1.010e+00
  layer model_4__forward_module.module.conv2 act-std: mean=1.647e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.393e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.963e-01Epoch 1/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it]
[A  layer model_2__forward_module.module.conv1 act-std: mean=1.004e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.709e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.137e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.464e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.247e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.821e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=5.339e-01
Epoch 1/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.219e-01

  param model_0__forward_module.module.conv2.weight grad-norm: mean=4.172e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=8.245e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=2.247e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=4.632e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=3.857e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=7.099e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=1.139e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=2.509e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=3.939e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.374e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.092e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.395e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=4.604e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.484e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=7.576e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.610e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=7.582e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.102e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=7.889e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.704e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=8.335e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.561e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=9.903e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=2.120e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.153e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.488e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.152e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.408e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=7.733e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.627e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.82it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.83it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.82it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.82it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.81it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.96it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]
Epoch 1/32 - Train Loss: 38.592768 - Test Loss: 34.856760
Training epochs:   3%|â–Ž         | 1/32 [00:21<11:06, 21.51s/it]
Epoch 2/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:   3%|â–Ž         | 1/32 [00:21<11:07, 21.52s/it]
Epoch 2/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 2/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.49s/it][AEpoch 2/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.50s/it][A
Epoch 2/32:  15%|â–ˆâ–Œ        | 2/13 [00:02<00:16,  1.50s/it][A
Epoch 2/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.50s/it][A
Epoch 2/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.51s/it][A
Epoch 2/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.51s/it][A
Epoch 2/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.51s/it][A
Epoch 2/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.51s/it][A
Epoch 2/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.51s/it][A
Epoch 2/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.51s/it][A

Epoch 2/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][AEpoch 2/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A

Epoch 2/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.51s/it][AEpoch 2/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.51s/it][A

Epoch 2/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.51s/it][AEpoch 2/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.51s/it][A
Epoch 2/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.51s/it][A
Epoch 2/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.51s/it][A
Epoch 2/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 2/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 2/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 2/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A

Epoch 2/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][AEpoch 2/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 2/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 2/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.48s/it]

Epoch 2/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 2/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.48s/it]

[Î²=3.0] Epoch 2 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.738e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.659e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.122e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.114e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.417e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.752e-01
  layer model_4__forward_module.module.conv1 act-std: mean=1.009e+00
  layer model_4__forward_module.module.conv2 act-std: mean=1.691e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.390e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.039e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.009e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.720e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.157e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.508e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.249e+00

  layer model_0__forward_module.module.conv2 act-std: mean=8.865e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.476e-01Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  param model_0__forward_module.module.conv1.bias grad-norm: mean=5.321e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.435e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=4.068e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.595e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=3.126e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.609e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=4.220e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=6.194e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.352e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.667e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=8.181e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=5.960e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.276e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=3.220e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=8.824e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=3.081e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=6.358e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.967e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=4.907e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=6.655e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.434e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=7.225e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.312e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=5.207e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.063e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=6.883e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=8.711e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=7.578e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.593e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=5.249e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=9.907e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.82it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.82it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.82it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.81it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.96it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]
Training epochs:   6%|â–‹         | 2/32 [00:42<10:43, 21.45s/it]

Epoch 3/32:   0%|          | 0/13 [00:00<?, ?it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]
Epoch 2/32 - Train Loss: 38.552488 - Test Loss: 34.821912
Training epochs:   6%|â–‹         | 2/32 [00:42<10:43, 21.46s/it]
Epoch 3/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 3/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][A
Epoch 3/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A

Epoch 3/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.51s/it][AEpoch 3/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A

Epoch 3/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.51s/it][AEpoch 3/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.51s/it][A

Epoch 3/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.51s/it][AEpoch 3/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 3/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.51s/it][A
Epoch 3/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A

Epoch 3/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.51s/it][AEpoch 3/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.51s/it][A
Epoch 3/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.51s/it][A
Epoch 3/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.51s/it][A

Epoch 3/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.51s/it][AEpoch 3/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.51s/it][A
Epoch 3/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.50s/it][A
Epoch 3/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.50s/it][A

Epoch 3/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.51s/it][AEpoch 3/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.51s/it][A
Epoch 3/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.51s/it][A
Epoch 3/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.51s/it][A

Epoch 3/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.51s/it]Epoch 3/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.51s/it][A[A
Epoch 3/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 3/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.48s/it]

Epoch 3/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 3/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.48s/it]

[Î²=3.0] Epoch 3 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.696e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.717e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.125e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.112e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.423e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.819e-01
  layer model_4__forward_module.module.conv1 act-std: mean=1.009e+00
  layer model_4__forward_module.module.conv2 act-std: mean=1.735e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.390e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.050e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.012e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.729e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.170e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.543e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.263e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.996e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=3.638e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=8.178e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.982e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=5.503e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.609e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=3.132e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=3.026e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=5.152e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.560e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=7.323e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.067e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=5.110e-02

  param model_3__forward_module.module.conv1.weight grad-norm: mean=4.554e-01
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  param model_3__forward_module.module.conv1.bias grad-norm: mean=9.546e-02[A
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.693e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=6.873e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.482e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=4.836e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.398e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=4.110e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=4.268e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=8.968e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=4.671e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=8.450e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.787e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=7.127e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=5.284e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=6.122e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=5.363e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.123e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=4.166e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=7.144e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.83it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.85it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.83it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.84it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.82it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]
Training epochs:   9%|â–‰         | 3/32 [01:04<10:21, 21.43s/it]
Epoch 4/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]
Epoch 3/32 - Train Loss: 38.473660 - Test Loss: 34.804753
Training epochs:   9%|â–‰         | 3/32 [01:04<10:21, 21.44s/it]
Epoch 4/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 4/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 4/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.50s/it][A
Epoch 4/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.50s/it][A
Epoch 4/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.51s/it][A

Epoch 4/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.50s/it][AEpoch 4/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.51s/it][A

Epoch 4/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.50s/it][AEpoch 4/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.51s/it][A

Epoch 4/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.51s/it][AEpoch 4/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.51s/it][A
Epoch 4/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.51s/it][A
Epoch 4/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.51s/it][A
Epoch 4/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.51s/it][A
Epoch 4/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 4/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 4/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A

Epoch 4/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][AEpoch 4/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 4/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 4/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A

Epoch 4/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.51s/it][AEpoch 4/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.51s/it][A
Epoch 4/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.51s/it][A
Epoch 4/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.51s/it][A
Epoch 4/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][A
Epoch 4/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.48s/it]

[Î²=3.0] Epoch 4 summary:
  input  std: mean=1.814e+00
Epoch 4/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it]  layer model_7__forward_module.module.conv1 act-std: mean=9.702e-01[A
  layer model_7__forward_module.module.conv2 act-std: mean=7.771e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.128e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.130e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.431e+00
Epoch 4/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.48s/it]  layer model_5__forward_module.module.conv2 act-std: mean=9.977e-01

  layer model_4__forward_module.module.conv1 act-std: mean=1.004e+00
  layer model_4__forward_module.module.conv2 act-std: mean=1.778e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.426e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.069e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.010e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.747e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.170e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.563e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.264e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.958e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.180e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=4.776e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.490e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=4.085e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.531e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=3.062e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.536e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=4.056e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=7.086e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.555e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.700e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=8.834e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=8.581e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.858e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=3.687e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.139e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.528e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=4.627e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.439e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=4.208e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=3.608e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=7.567e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=4.079e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=7.245e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=5.606e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.164e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=6.768e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=8.449e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=4.410e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=9.025e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.656e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=6.399e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.84it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.84it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.83it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.96it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s]
Training epochs:  12%|â–ˆâ–Ž        | 4/32 [01:25<09:59, 21.42s/it]
Epoch 5/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Epoch 4/32 - Train Loss: 38.473379 - Test Loss: 34.781771
Training epochs:  12%|â–ˆâ–Ž        | 4/32 [01:25<10:00, 21.43s/it]
Epoch 5/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 5/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.50s/it][A
Epoch 5/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 5/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.51s/it][A
Epoch 5/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A

Epoch 5/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][AEpoch 5/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.51s/it][A

Epoch 5/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][AEpoch 5/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 5/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 5/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A

Epoch 5/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][AEpoch 5/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A

Epoch 5/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][AEpoch 5/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 5/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 5/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 5/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 5/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A

Epoch 5/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][AEpoch 5/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A

Epoch 5/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][AEpoch 5/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 5/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 5/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 5/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 5/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

[Î²=3.0] Epoch 5 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.648e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.805e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.128e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.123e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.434e+00
  layer model_5__forward_module.module.conv2 act-std: mean=1.004e+00
  layer model_4__forward_module.module.conv1 act-std: mean=1.004e+00
  layer model_4__forward_module.module.conv2 act-std: mean=1.826e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.471e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.088e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.014e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.778e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.176e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.574e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.268e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.990e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.643e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=5.928e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.573e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=4.346e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.109e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.945e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.065e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.003e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=4.256e-01

  param model_2__forward_module.module.conv1.bias grad-norm: mean=8.999e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.298e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=6.028e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=4.721e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=9.931e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.624e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=6.531e-02Epoch 5/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it]
[A  param model_4__forward_module.module.conv1.weight grad-norm: mean=5.291e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.139e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=5.128e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=7.096e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.112e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=3.855e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.656e-01Epoch 5/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

  param model_5__forward_module.module.conv2.bias grad-norm: mean=4.016e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=5.961e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.207e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=7.342e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=9.053e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.384e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=6.435e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.169e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.392e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.82it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.83it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.81it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Epoch 5/32 - Train Loss: 38.445325 - Test Loss: 34.765889
Training epochs:  16%|â–ˆâ–Œ        | 5/32 [01:47<09:39, 21.48s/it]
Epoch 6/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  16%|â–ˆâ–Œ        | 5/32 [01:47<09:39, 21.48s/it]
Epoch 6/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 6/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it]Epoch 6/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A[A
Epoch 6/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 6/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 6/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it]
[AEpoch 6/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 6/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 6/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A

Epoch 6/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][AEpoch 6/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A

Epoch 6/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][AEpoch 6/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A

Epoch 6/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][AEpoch 6/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A

Epoch 6/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][AEpoch 6/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 6/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 6/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A

Epoch 6/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][AEpoch 6/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A

Epoch 6/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][AEpoch 6/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A

Epoch 6/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][AEpoch 6/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 6/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 6/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

Epoch 6/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 6/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=3.0] Epoch 6 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.641e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.876e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.130e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.146e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.434e+00
  layer model_5__forward_module.module.conv2 act-std: mean=1.013e+00
  layer model_4__forward_module.module.conv1 act-std: mean=9.998e-01
  layer model_4__forward_module.module.conv2 act-std: mean=1.861e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.502e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.120e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.020e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.792e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.186e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.600e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.281e+00
  layer model_0__forward_module.module.conv2 act-std: mean=9.016e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.209e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=4.743e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.248e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.550e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.737e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=3.539e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.717e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=4.268e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.329e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=6.630e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.009e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=5.118e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=5.746e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.221e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.959e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=8.077e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=6.415e-01

  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.386e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=6.448e-01Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  param model_4__forward_module.module.conv2.bias grad-norm: mean=8.932e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=3.075e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=6.214e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=3.321e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=5.535e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=7.572e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.592e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=9.693e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.212e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=4.619e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=9.327e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.760e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=6.530e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.82it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Training epochs:  19%|â–ˆâ–‰        | 6/32 [02:08<09:19, 21.53s/it]
Epoch 7/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Epoch 6/32 - Train Loss: 38.377544 - Test Loss: 34.748960
Training epochs:  19%|â–ˆâ–‰        | 6/32 [02:08<09:19, 21.53s/it]
Epoch 7/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 7/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][A
Epoch 7/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 7/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.51s/it][A
Epoch 7/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 7/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.51s/it][A
Epoch 7/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 7/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 7/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 7/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 7/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A

Epoch 7/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it]Epoch 7/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A[A

Epoch 7/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][AEpoch 7/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 7/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 7/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A

Epoch 7/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][AEpoch 7/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A

Epoch 7/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][AEpoch 7/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 7/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 7/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A

Epoch 7/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][AEpoch 7/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 7/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 7/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

Epoch 7/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 7/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=3.0] Epoch 7 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.652e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.895e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.132e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.163e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.440e+00
  layer model_5__forward_module.module.conv2 act-std: mean=1.018e+00
  layer model_4__forward_module.module.conv1 act-std: mean=1.000e+00
  layer model_4__forward_module.module.conv2 act-std: mean=1.893e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.532e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.140e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.017e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.803e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.190e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.610e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.280e+00
  layer model_0__forward_module.module.conv2 act-std: mean=9.031e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.624e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=3.274e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.911e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.916e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.459e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=3.147e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.210e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.304e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.644e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=7.826e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.984e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=5.195e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.755e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=7.812e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.342e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=5.480e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.165e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=3.916e-02

  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.072e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.537e-02Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  param model_5__forward_module.module.conv1.weight grad-norm: mean=3.020e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=6.077e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=3.417e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=5.843e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.912e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=7.587e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.984e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.611e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=4.742e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=9.762e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.520e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=5.718e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A

Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][AEvaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Epoch 7/32 - Train Loss: 38.374210 - Test Loss: 34.745128
Training epochs:  22%|â–ˆâ–ˆâ–       | 7/32 [02:30<08:59, 21.57s/it]
Epoch 8/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  22%|â–ˆâ–ˆâ–       | 7/32 [02:30<08:59, 21.57s/it]
Epoch 8/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 8/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][AEpoch 8/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 8/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 8/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A

Epoch 8/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][AEpoch 8/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 8/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 8/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 8/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 8/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 8/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 8/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 8/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 8/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A

Epoch 8/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][AEpoch 8/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A

Epoch 8/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][AEpoch 8/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A

Epoch 8/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][AEpoch 8/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 8/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 8/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A

Epoch 8/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][AEpoch 8/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 8/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 8/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=3.0] Epoch 8 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.643e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.924e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.134e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.158e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.440e+00
  layer model_5__forward_module.module.conv2 act-std: mean=1.020e+00
  layer model_4__forward_module.module.conv1 act-std: mean=9.991e-01
  layer model_4__forward_module.module.conv2 act-std: mean=1.907e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.550e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.165e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.021e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.806e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.198e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.617e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.288e+00
  layer model_0__forward_module.module.conv2 act-std: mean=9.037e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.496e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=2.960e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.916e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.856e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.203e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.260e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.821e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.475e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.820e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=8.016e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.940e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=5.152e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=2.969e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=6.025e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.244e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.488e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=3.277e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=6.527e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=4.011e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=4.928e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.507e-01

  param model_5__forward_module.module.conv1.bias grad-norm: mean=4.906e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.797e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=4.751e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.154e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=5.661e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.805e-01
Epoch 8/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it]  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.688e-02[A
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.729e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=7.573e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.100e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=5.034e-02
Epoch 8/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.83it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.75it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.75it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Training epochs:  25%|â–ˆâ–ˆâ–Œ       | 8/32 [02:52<08:38, 21.61s/it]
Epoch 9/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.85it/s]
Epoch 8/32 - Train Loss: 38.392051 - Test Loss: 34.732259
Training epochs:  25%|â–ˆâ–ˆâ–Œ       | 8/32 [02:52<08:38, 21.62s/it]
Epoch 9/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 9/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 9/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.56s/it][A
Epoch 9/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 9/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A

Epoch 9/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][AEpoch 9/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 9/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 9/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 9/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 9/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 9/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 9/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 9/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 9/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 9/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 9/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A

Epoch 9/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][AEpoch 9/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 9/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 9/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 9/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 9/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A

Epoch 9/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][AEpoch 9/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 9/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][A
Epoch 9/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it]Epoch 9/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it][A
Epoch 9/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=3.0] Epoch 9 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.659e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.962e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.135e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.161e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.443e+00
  layer model_5__forward_module.module.conv2 act-std: mean=1.018e+00
  layer model_4__forward_module.module.conv1 act-std: mean=9.992e-01
  layer model_4__forward_module.module.conv2 act-std: mean=1.933e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.577e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.180e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.021e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.830e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.200e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.631e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.287e+00
  layer model_0__forward_module.module.conv2 act-std: mean=9.097e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.633e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=3.357e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.068e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.142e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.131e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.066e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.068e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.944e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.383e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=7.066e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.053e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=4.614e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.810e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=8.044e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.394e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=5.184e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.128e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=3.904e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.857e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.060e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.303e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=4.107e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.626e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=3.842e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.475e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=6.431e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.869e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.731e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=4.329e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=8.548e-02

  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.373e-01
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  param model_7__forward_module.module.conv2.bias grad-norm: mean=5.239e-02[A

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.81it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.81it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.96it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]
Training epochs:  28%|â–ˆâ–ˆâ–Š       | 9/32 [03:13<08:17, 21.63s/it]
Epoch 10/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Epoch 9/32 - Train Loss: 38.350214 - Test Loss: 34.727726
Training epochs:  28%|â–ˆâ–ˆâ–Š       | 9/32 [03:14<08:17, 21.63s/it]
Epoch 10/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 10/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 10/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.57s/it][A
Epoch 10/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 10/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:17,  1.55s/it][A
Epoch 10/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 10/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 10/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 10/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A

Epoch 10/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][AEpoch 10/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A

Epoch 10/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][AEpoch 10/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 10/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 10/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 10/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 10/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A

Epoch 10/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][AEpoch 10/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A

Epoch 10/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it]Epoch 10/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A[A

Epoch 10/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][AEpoch 10/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 10/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 10/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 10/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 10/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=3.0] Epoch 10 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.673e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.959e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.136e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.168e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.443e+00
  layer model_5__forward_module.module.conv2 act-std: mean=1.017e+00
  layer model_4__forward_module.module.conv1 act-std: mean=9.984e-01
  layer model_4__forward_module.module.conv2 act-std: mean=1.949e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.594e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.183e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.022e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.827e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.200e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.628e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.290e+00
  layer model_0__forward_module.module.conv2 act-std: mean=9.049e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.394e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=2.640e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.897e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.622e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.083e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.956e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.943e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.561e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=4.894e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.043e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.104e-01

  param model_2__forward_module.module.conv2.bias grad-norm: mean=6.060e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=5.361e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.157e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.740e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=6.838e-02
Epoch 10/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it]  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.697e-01[A
  param model_4__forward_module.module.conv1.bias grad-norm: mean=5.355e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.412e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.790e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.715e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=5.181e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.947e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=4.810e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.819e-01Epoch 10/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

  param model_6__forward_module.module.conv1.bias grad-norm: mean=7.368e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=5.031e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.818e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=4.049e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=8.052e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.238e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=5.025e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.82it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.83it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.81it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.81it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]
Epoch 10/32 - Train Loss: 38.365285 - Test Loss: 34.724113
Training epochs:  31%|â–ˆâ–ˆâ–ˆâ–      | 10/32 [03:35<07:55, 21.63s/it]
Epoch 11/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  31%|â–ˆâ–ˆâ–ˆâ–      | 10/32 [03:35<07:55, 21.63s/it]
Epoch 11/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 11/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 11/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 11/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 11/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 11/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 11/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 11/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 11/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 11/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 11/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A

Epoch 11/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][AEpoch 11/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 11/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 11/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A

Epoch 11/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][AEpoch 11/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 11/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 11/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A

Epoch 11/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][AEpoch 11/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 11/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 11/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A

Epoch 11/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][AEpoch 11/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A

Epoch 11/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 11/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 11/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]
Epoch 11/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=3.0] Epoch 11 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.659e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.993e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.139e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.180e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.446e+00
  layer model_5__forward_module.module.conv2 act-std: mean=1.015e+00
  layer model_4__forward_module.module.conv1 act-std: mean=9.994e-01
  layer model_4__forward_module.module.conv2 act-std: mean=1.971e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.620e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.197e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.027e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.845e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.208e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.647e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.294e+00
  layer model_0__forward_module.module.conv2 act-std: mean=9.094e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.448e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=2.697e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.704e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.249e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.041e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.771e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.799e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.286e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.804e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=7.989e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.953e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=4.857e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.356e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=6.752e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.256e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.646e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.485e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=4.979e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.214e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.690e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.410e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=4.591e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.807e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=4.653e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.575e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=6.727e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=5.071e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.756e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.767e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=7.384e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.127e-01

  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.462e-02
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.82it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.81it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.53it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.64it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]
Epoch 11/32 - Train Loss: 38.354742 - Test Loss: 34.712214
Training epochs:  34%|â–ˆâ–ˆâ–ˆâ–      | 11/32 [03:57<07:34, 21.64s/it]
Epoch 12/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.83it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.75it/s]
Training epochs:  34%|â–ˆâ–ˆâ–ˆâ–      | 11/32 [03:57<07:35, 21.69s/it]
Epoch 12/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 12/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.50s/it][A
Epoch 12/32:   8%|â–Š         | 1/13 [00:01<00:20,  1.67s/it][A
Epoch 12/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 12/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:17,  1.59s/it][A
Epoch 12/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.56s/it][A
Epoch 12/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 12/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 12/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:14,  1.56s/it][A
Epoch 12/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 12/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.55s/it][A
Epoch 12/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 12/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A

Epoch 12/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][AEpoch 12/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 12/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 12/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 12/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 12/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 12/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 12/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 12/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 12/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:17<00:03,  1.53s/it][A
Epoch 12/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 12/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 12/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][A
Epoch 12/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.52s/it]
Epoch 12/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][A
[Î²=3.0] Epoch 12 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.650e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.980e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.140e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.173e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.449e+00
Epoch 12/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]  layer model_5__forward_module.module.conv2 act-std: mean=1.022e+00

  layer model_4__forward_module.module.conv1 act-std: mean=9.981e-01
  layer model_4__forward_module.module.conv2 act-std: mean=1.988e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.643e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.211e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.026e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.868e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.211e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.659e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.298e+00
  layer model_0__forward_module.module.conv2 act-std: mean=9.114e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.878e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=3.980e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.913e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.863e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.132e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.059e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.879e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.324e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=2.692e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=5.041e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.824e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=4.068e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=2.785e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=5.396e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.182e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.116e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.672e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=5.158e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.099e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.513e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=3.375e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=7.048e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=3.516e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=5.958e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.679e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=6.777e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.568e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.027e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.959e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=7.945e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.340e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=5.501e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A

Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][AEvaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Epoch 12/32 - Train Loss: 38.345416 - Test Loss: 34.704258
Training epochs:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 12/32 [04:19<07:14, 21.70s/it]Training epochs:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 12/32 [04:19<07:13, 21.69s/it]
Epoch 13/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 13/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 13/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][AEpoch 13/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 13/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 13/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A

Epoch 13/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][AEpoch 13/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A

Epoch 13/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][AEpoch 13/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 13/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 13/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 13/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 13/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 13/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 13/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A

Epoch 13/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][AEpoch 13/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 13/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 13/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A

Epoch 13/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][AEpoch 13/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 13/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 13/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 13/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 13/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 13/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 13/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

Epoch 13/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 13/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=3.0] Epoch 13 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.679e-01
  layer model_7__forward_module.module.conv2 act-std: mean=8.062e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.142e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.196e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.452e+00
  layer model_5__forward_module.module.conv2 act-std: mean=1.020e+00
  layer model_4__forward_module.module.conv1 act-std: mean=9.973e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.005e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.658e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.222e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.027e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.860e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.213e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.660e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.300e+00
  layer model_0__forward_module.module.conv2 act-std: mean=9.145e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.098e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=4.534e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.055e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.084e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.177e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.122e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.094e-01

  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.086e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=1.829e-01Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  param model_2__forward_module.module.conv1.bias grad-norm: mean=3.257e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.649e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=2.534e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=2.006e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=3.575e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.968e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=2.935e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.946e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=3.304e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.914e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.014e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.348e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=4.452e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.741e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=4.481e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.142e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=5.487e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.452e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=4.655e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.247e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=6.042e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.833e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=3.722e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.82it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.82it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.82it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.97it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s]
Training epochs:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 13/32 [04:40<06:51, 21.68s/it]
Epoch 14/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Epoch 13/32 - Train Loss: 38.328643 - Test Loss: 34.699463
Training epochs:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 13/32 [04:40<06:52, 21.71s/it]
Epoch 14/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 14/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][AEpoch 14/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.58s/it][A
Epoch 14/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:17,  1.56s/it][A
Epoch 14/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 14/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.55s/it][A
Epoch 14/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A

Epoch 14/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][AEpoch 14/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A

Epoch 14/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][AEpoch 14/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 14/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 14/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A

Epoch 14/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][AEpoch 14/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 14/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 14/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 14/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 14/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A

Epoch 14/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][AEpoch 14/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 14/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 14/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 14/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 14/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 14/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 14/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=3.0] Epoch 14 summary:
  input  std: mean=1.814e+00

  layer model_7__forward_module.module.conv1 act-std: mean=9.664e-01
  layer model_7__forward_module.module.conv2 act-std: mean=8.010e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.144e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.186e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.452e+00
  layer model_5__forward_module.module.conv2 act-std: mean=1.019e+00
  layer model_4__forward_module.module.conv1 act-std: mean=9.987e-01
Epoch 14/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it]  layer model_4__forward_module.module.conv2 act-std: mean=2.015e+00[A
  layer model_3__forward_module.module.conv1 act-std: mean=6.668e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.224e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.030e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.898e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.214e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.669e+00
Epoch 14/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]  layer model_0__forward_module.module.conv1 act-std: mean=1.299e+00

  layer model_0__forward_module.module.conv2 act-std: mean=9.128e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.748e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=3.616e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.773e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.510e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.111e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.046e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.734e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.218e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=2.421e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=4.853e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.776e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.616e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=2.749e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=5.396e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.202e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.496e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=3.133e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=6.354e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.745e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=4.448e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=3.368e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=6.716e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=3.426e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=5.954e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.936e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=7.511e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.961e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.461e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=4.283e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=8.362e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.326e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=5.451e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.83it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.82it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][ATraining epochs:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 14/32 [05:02<06:30, 21.72s/it]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Epoch 14/32 - Train Loss: 38.323564 - Test Loss: 34.695900

Epoch 15/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 14/32 [05:02<06:30, 21.72s/it]
Epoch 15/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 15/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 15/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.56s/it][A

Epoch 15/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:17,  1.55s/it][AEpoch 15/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:17,  1.55s/it][A
Epoch 15/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 15/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 15/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 15/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 15/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 15/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 15/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 15/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 15/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 15/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A

Epoch 15/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][AEpoch 15/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 15/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 15/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A

Epoch 15/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][AEpoch 15/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 15/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 15/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 15/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 15/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A

Epoch 15/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 15/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]
Epoch 15/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 15/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=3.0] Epoch 15 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.677e-01
  layer model_7__forward_module.module.conv2 act-std: mean=8.045e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.143e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.196e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.454e+00
  layer model_5__forward_module.module.conv2 act-std: mean=1.015e+00
  layer model_4__forward_module.module.conv1 act-std: mean=9.977e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.022e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.682e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.233e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.030e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.887e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.216e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.666e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.300e+00
  layer model_0__forward_module.module.conv2 act-std: mean=9.141e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.342e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=2.550e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.682e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.189e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.116e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.035e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.697e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.200e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.284e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=7.040e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.864e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=4.160e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.801e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=7.907e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.358e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=5.389e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.503e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=4.885e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.288e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.734e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.457e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=4.794e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=3.160e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=5.090e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=4.128e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=7.720e-02

  param model_6__forward_module.module.conv2.weight grad-norm: mean=5.445e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=6.171e-02Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  param model_7__forward_module.module.conv1.weight grad-norm: mean=2.747e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=5.064e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.708e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=3.731e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.77it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.76it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.76it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.76it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Training epochs:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 15/32 [05:24<06:09, 21.71s/it]
Epoch 16/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.85it/s]
Epoch 15/32 - Train Loss: 38.303576 - Test Loss: 34.695393
Training epochs:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 15/32 [05:24<06:09, 21.72s/it]
Epoch 16/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 16/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it]Epoch 16/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.58s/it][A[A
Epoch 16/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:17,  1.56s/it][A
Epoch 16/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A

Epoch 16/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.56s/it][AEpoch 16/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.55s/it][A
Epoch 16/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 16/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.55s/it][A
Epoch 16/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 16/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 16/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 16/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 16/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 16/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 16/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 16/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 16/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 16/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 16/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 16/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 16/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 16/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 16/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 16/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A

Epoch 16/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 16/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 16/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]
Epoch 16/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=3.0] Epoch 16 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.677e-01
  layer model_7__forward_module.module.conv2 act-std: mean=8.035e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.145e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.190e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.456e+00
  layer model_5__forward_module.module.conv2 act-std: mean=1.015e+00
  layer model_4__forward_module.module.conv1 act-std: mean=9.992e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.033e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.688e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.253e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.031e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.883e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.219e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.678e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.301e+00
  layer model_0__forward_module.module.conv2 act-std: mean=9.127e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.556e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=3.208e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.807e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.439e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=9.721e-02
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.610e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.837e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.372e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=2.581e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=5.240e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.763e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.551e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.064e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=5.987e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.098e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=3.999e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.229e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=4.205e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.797e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=2.938e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.585e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=5.006e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.705e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=4.379e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.855e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=7.565e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.776e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.434e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.519e-01

  param model_7__forward_module.module.conv1.bias grad-norm: mean=6.935e-02
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.978e-01[A
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.229e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.75it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.74it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.76it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.75it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.76it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Training epochs:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 16/32 [05:46<05:47, 21.74s/it]
Epoch 17/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.84it/s]
Epoch 16/32 - Train Loss: 38.316997 - Test Loss: 34.691528
Training epochs:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 16/32 [05:46<05:47, 21.75s/it]
Epoch 17/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 17/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 17/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.55s/it][A

Epoch 17/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:17,  1.55s/it]Epoch 17/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A[A

Epoch 17/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.55s/it][AEpoch 17/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.55s/it][A
Epoch 17/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.55s/it][A
Epoch 17/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.55s/it][A
Epoch 17/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.55s/it][A
Epoch 17/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.55s/it][A

Epoch 17/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][AEpoch 17/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 17/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 17/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 17/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 17/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 17/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 17/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 17/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 17/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A

Epoch 17/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][AEpoch 17/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 17/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 17/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A

Epoch 17/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 17/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 17/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=3.0] Epoch 17 summary:Epoch 17/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.683e-01
  layer model_7__forward_module.module.conv2 act-std: mean=8.057e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.147e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.193e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.455e+00
  layer model_5__forward_module.module.conv2 act-std: mean=1.015e+00
  layer model_4__forward_module.module.conv1 act-std: mean=9.986e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.042e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.700e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.248e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.033e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.891e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.220e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.677e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.302e+00
  layer model_0__forward_module.module.conv2 act-std: mean=9.160e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.402e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=2.583e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.690e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.055e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.086e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.854e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.929e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.743e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=2.207e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=4.072e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.769e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.687e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.328e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=6.733e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.294e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.916e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.128e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=3.776e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.649e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=2.703e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=3.138e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=6.318e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=3.436e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=5.644e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.735e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=7.385e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.377e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=4.655e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=4.261e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=8.330e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.258e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=5.124e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.77it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.76it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.74it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Training epochs:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 17/32 [06:07<05:26, 21.75s/it]
Epoch 18/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Epoch 17/32 - Train Loss: 38.288564 - Test Loss: 34.687043
Training epochs:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 17/32 [06:07<05:26, 21.75s/it]
Epoch 18/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 18/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][AEpoch 18/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 18/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 18/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 18/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 18/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A

Epoch 18/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][AEpoch 18/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 18/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 18/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 18/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 18/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 18/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 18/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 18/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 18/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 18/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 18/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 18/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 18/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 18/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 18/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 18/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 18/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 18/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 18/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=3.0] Epoch 18 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.683e-01
  layer model_7__forward_module.module.conv2 act-std: mean=8.074e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.147e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.200e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.457e+00
  layer model_5__forward_module.module.conv2 act-std: mean=1.016e+00
  layer model_4__forward_module.module.conv1 act-std: mean=9.974e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.052e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.713e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.253e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.034e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.908e-01

  layer model_1__forward_module.module.conv1 act-std: mean=1.221e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.683e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.304e+00
  layer model_0__forward_module.module.conv2 act-std: mean=9.179e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.599e-01
Epoch 18/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it]  param model_0__forward_module.module.conv1.bias grad-norm: mean=3.165e-02[A
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.927e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.877e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.112e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.035e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.076e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.973e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=2.231e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=4.087e-02
Epoch 18/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.820e-01

  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.245e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=2.173e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=4.098e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.060e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=3.481e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=3.197e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=6.658e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.610e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=4.568e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.465e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=4.486e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.918e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=4.767e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=4.223e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=8.268e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=5.449e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=6.093e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.214e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=5.750e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.871e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=3.899e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.75it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.75it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Epoch 18/32 - Train Loss: 38.318762 - Test Loss: 34.684828
Training epochs:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 18/32 [06:29<05:04, 21.76s/it]Training epochs:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 18/32 [06:29<05:04, 21.75s/it]
Epoch 19/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 19/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 19/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 19/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A

Epoch 19/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][AEpoch 19/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 19/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 19/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 19/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 19/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A

Epoch 19/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][AEpoch 19/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 19/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 19/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 19/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 19/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 19/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 19/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 19/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 19/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 19/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 19/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 19/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 19/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A

Epoch 19/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][AEpoch 19/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 19/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 19/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

Epoch 19/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 19/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=3.0] Epoch 19 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.693e-01
  layer model_7__forward_module.module.conv2 act-std: mean=8.082e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.149e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.200e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.458e+00
  layer model_5__forward_module.module.conv2 act-std: mean=1.016e+00
  layer model_4__forward_module.module.conv1 act-std: mean=9.990e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.061e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.723e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.274e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.035e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.904e-01

  layer model_1__forward_module.module.conv1 act-std: mean=1.223e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.685e+00Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  layer model_0__forward_module.module.conv1 act-std: mean=1.306e+00
  layer model_0__forward_module.module.conv2 act-std: mean=9.177e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.652e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=3.571e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.788e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.687e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.133e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.088e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.873e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.597e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=1.941e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=3.628e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.736e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.041e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=2.199e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=3.877e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.053e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=3.183e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.234e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=4.256e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.739e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=2.639e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.185e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=4.120e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.722e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=3.899e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.221e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=6.025e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.614e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.072e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=2.840e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=5.285e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.672e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=3.528e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]
Training epochs:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 19/32 [06:51<04:42, 21.74s/it]
Epoch 20/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Epoch 19/32 - Train Loss: 38.339324 - Test Loss: 34.684236
Training epochs:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 19/32 [06:51<04:42, 21.74s/it]
Epoch 20/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 20/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 20/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.56s/it][A
Epoch 20/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:17,  1.55s/it][A
Epoch 20/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A

Epoch 20/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][AEpoch 20/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 20/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 20/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 20/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 20/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 20/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 20/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 20/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 20/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 20/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 20/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 20/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 20/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 20/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 20/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 20/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 20/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 20/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 20/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A

Epoch 20/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 20/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 20/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=3.0] Epoch 20 summary:
  input  std: mean=1.814e+00
Epoch 20/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]  layer model_7__forward_module.module.conv1 act-std: mean=9.696e-01

  layer model_7__forward_module.module.conv2 act-std: mean=8.069e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.149e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.205e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.459e+00
  layer model_5__forward_module.module.conv2 act-std: mean=1.014e+00
  layer model_4__forward_module.module.conv1 act-std: mean=9.989e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.065e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.727e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.263e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.035e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.917e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.224e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.685e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.307e+00
  layer model_0__forward_module.module.conv2 act-std: mean=9.181e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.621e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=3.296e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.703e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.189e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=9.759e-02
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.678e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.718e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.064e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=2.774e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=5.704e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.814e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.641e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=2.511e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=4.879e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.141e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=3.756e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.466e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=4.713e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.976e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.158e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.126e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=3.910e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.383e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=3.400e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.175e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=5.818e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.664e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.093e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.081e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=5.911e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.874e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.027e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.77it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.76it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.75it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.76it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.74it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Training epochs:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 20/32 [07:13<04:20, 21.75s/it]
Epoch 21/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.84it/s]
Epoch 20/32 - Train Loss: 38.315270 - Test Loss: 34.682192
Training epochs:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 20/32 [07:13<04:20, 21.75s/it]
Epoch 21/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 21/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 21/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 21/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 21/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 21/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 21/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 21/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 21/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 21/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 21/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 21/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 21/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 21/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 21/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 21/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 21/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 21/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 21/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 21/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.58s/it][A
Epoch 21/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.58s/it][A

Epoch 21/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:17<00:03,  1.57s/it][AEpoch 21/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:17<00:03,  1.57s/it][A

Epoch 21/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.56s/it][AEpoch 21/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.56s/it][A
Epoch 21/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.44s/it][AEpoch 21/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.52s/it]

Epoch 21/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.44s/it][AEpoch 21/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.52s/it]

[Î²=3.0] Epoch 21 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.693e-01
  layer model_7__forward_module.module.conv2 act-std: mean=8.080e-01

  layer model_6__forward_module.module.conv1 act-std: mean=1.149e+00
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  layer model_6__forward_module.module.conv2 act-std: mean=3.207e-01[A
  layer model_5__forward_module.module.conv1 act-std: mean=1.459e+00
  layer model_5__forward_module.module.conv2 act-std: mean=1.013e+00
  layer model_4__forward_module.module.conv1 act-std: mean=9.991e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.072e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.733e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.259e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.035e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.920e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.224e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.688e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.307e+00
  layer model_0__forward_module.module.conv2 act-std: mean=9.185e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.963e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=4.084e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.915e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.817e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.185e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.224e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.962e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.736e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=2.061e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=3.780e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.629e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.047e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.167e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=6.578e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.209e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.459e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.229e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=4.189e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.884e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.182e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.758e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=3.053e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.247e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=3.249e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.333e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=6.034e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.450e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=4.827e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=2.588e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=4.764e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.850e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=3.643e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]
Epoch 21/32 - Train Loss: 38.333888 - Test Loss: 34.682022

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Training epochs:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 21/32 [07:35<03:59, 21.79s/it]
Epoch 22/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 21/32 [07:35<03:59, 21.80s/it]
Epoch 22/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 22/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.56s/it][A
Epoch 22/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.55s/it][A
Epoch 22/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:17,  1.55s/it][A
Epoch 22/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 22/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 22/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A

Epoch 22/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][AEpoch 22/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 22/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 22/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A

Epoch 22/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][AEpoch 22/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 22/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 22/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 22/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 22/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 22/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 22/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A

Epoch 22/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][AEpoch 22/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 22/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 22/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A

Epoch 22/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][AEpoch 22/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 22/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 22/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

Epoch 22/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 22/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=3.0] Epoch 22 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.693e-01
  layer model_7__forward_module.module.conv2 act-std: mean=8.086e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.150e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.208e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.459e+00
  layer model_5__forward_module.module.conv2 act-std: mean=1.014e+00
  layer model_4__forward_module.module.conv1 act-std: mean=9.990e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.075e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.741e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.276e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.035e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.924e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.225e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.685e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.307e+00
  layer model_0__forward_module.module.conv2 act-std: mean=9.181e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.516e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=3.004e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.695e-01

  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.196e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.033e-01Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.792e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.818e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.408e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=2.291e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=4.301e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.675e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.149e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.166e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=6.514e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.158e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.299e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.093e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=3.903e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.997e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.252e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.680e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=5.156e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.920e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=4.843e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=2.878e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=5.130e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.092e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=4.395e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.493e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=6.461e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.997e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.660e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.76it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.76it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.76it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.76it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.85it/s]
Epoch 22/32 - Train Loss: 38.298160 - Test Loss: 34.678318
Training epochs:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 22/32 [07:56<03:37, 21.79s/it]
Epoch 23/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 22/32 [07:56<03:37, 21.79s/it]
Epoch 23/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 23/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][AEpoch 23/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A

Epoch 23/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][AEpoch 23/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 23/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 23/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 23/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 23/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A

Epoch 23/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][AEpoch 23/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A

Epoch 23/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][AEpoch 23/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A

Epoch 23/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][AEpoch 23/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 23/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 23/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 23/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 23/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 23/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 23/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 23/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 23/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A

Epoch 23/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][AEpoch 23/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 23/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 23/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=3.0] Epoch 23 summary:
  input  std: mean=1.814e+00

  layer model_7__forward_module.module.conv1 act-std: mean=9.691e-01
  layer model_7__forward_module.module.conv2 act-std: mean=8.078e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.150e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.208e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.461e+00
  layer model_5__forward_module.module.conv2 act-std: mean=1.010e+00
  layer model_4__forward_module.module.conv1 act-std: mean=9.992e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.080e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.748e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.275e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.036e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.919e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.226e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.694e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.307e+00Epoch 23/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it]
[A  layer model_0__forward_module.module.conv2 act-std: mean=9.179e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.225e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=2.208e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.710e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.181e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.047e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.842e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.829e-01
Epoch 23/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.426e-02

  param model_2__forward_module.module.conv1.weight grad-norm: mean=2.394e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=4.567e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.704e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.226e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.026e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=6.015e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.066e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=3.957e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.867e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=3.260e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.771e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=2.826e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.204e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=3.950e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.641e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=4.166e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.260e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=6.012e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.670e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.125e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.285e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=6.084e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.890e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=3.782e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.75it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.76it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.75it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.76it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.75it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Training epochs:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 23/32 [08:18<03:16, 21.78s/it]
Epoch 24/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.84it/s]
Epoch 23/32 - Train Loss: 38.313176 - Test Loss: 34.675912
Training epochs:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 23/32 [08:18<03:16, 21.79s/it]
Epoch 24/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 24/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.55s/it][A
Epoch 24/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A

Epoch 24/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][AEpoch 24/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 24/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 24/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A

Epoch 24/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][AEpoch 24/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A

Epoch 24/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][AEpoch 24/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 24/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 24/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 24/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 24/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A

Epoch 24/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it]Epoch 24/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A[A

Epoch 24/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it]Epoch 24/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A[A

Epoch 24/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it]Epoch 24/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A[A
Epoch 24/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 24/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 24/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 24/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 24/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 24/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

Epoch 24/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 24/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=3.0] Epoch 24 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.698e-01
  layer model_7__forward_module.module.conv2 act-std: mean=8.101e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.151e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.213e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.461e+00
  layer model_5__forward_module.module.conv2 act-std: mean=1.010e+00
  layer model_4__forward_module.module.conv1 act-std: mean=9.992e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.087e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.749e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.270e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.036e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.924e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.227e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.694e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.309e+00
  layer model_0__forward_module.module.conv2 act-std: mean=9.209e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.951e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=4.013e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.896e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.988e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.150e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.268e-02

  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.816e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.410e-02Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.318e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=6.833e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.822e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=4.333e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.900e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=8.007e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.305e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.878e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.831e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=3.176e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.427e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=2.207e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.001e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=3.634e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.630e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=3.804e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.477e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=6.556e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.774e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.177e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=2.646e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=4.762e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.715e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=3.642e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A

Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][AEvaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s][ATraining epochs:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 24/32 [08:40<02:54, 21.78s/it]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Epoch 24/32 - Train Loss: 38.302699 - Test Loss: 34.676666
Training epochs:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 24/32 [08:40<02:54, 21.78s/it]
Epoch 25/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 25/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 25/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 25/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 25/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 25/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 25/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 25/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 25/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 25/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 25/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 25/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A

Epoch 25/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][AEpoch 25/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 25/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 25/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 25/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 25/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A

Epoch 25/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][AEpoch 25/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A

Epoch 25/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][AEpoch 25/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A

Epoch 25/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][AEpoch 25/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 25/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.59s/it][A
Epoch 25/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.59s/it][A
Epoch 25/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.46s/it][A
Epoch 25/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.52s/it]

[Î²=3.0] Epoch 25 summary:
  input  std: mean=1.814e+00
Epoch 25/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.46s/it]  layer model_7__forward_module.module.conv1 act-std: mean=9.696e-01[A
  layer model_7__forward_module.module.conv2 act-std: mean=8.086e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.152e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.207e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.462e+00
  layer model_5__forward_module.module.conv2 act-std: mean=1.011e+00
  layer model_4__forward_module.module.conv1 act-std: mean=9.991e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.089e+00
Epoch 25/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.52s/it]  layer model_3__forward_module.module.conv1 act-std: mean=6.754e-01

  layer model_3__forward_module.module.conv2 act-std: mean=4.281e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.037e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.938e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.227e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.695e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.309e+00
  layer model_0__forward_module.module.conv2 act-std: mean=9.183e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.593e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=3.220e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.762e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.294e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.117e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.030e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.642e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=1.909e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=2.070e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=4.054e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.648e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.018e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=2.575e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=4.896e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.955e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=3.279e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.207e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=4.179e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.918e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.164e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.648e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=2.539e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.159e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=2.897e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.179e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=5.915e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.213e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=4.708e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=2.879e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=5.187e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.663e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=3.315e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Training epochs:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 25/32 [09:02<02:32, 21.83s/it]
Epoch 26/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.84it/s]
Epoch 25/32 - Train Loss: 38.310513 - Test Loss: 34.674795
Training epochs:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 25/32 [09:02<02:32, 21.84s/it]
Epoch 26/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 26/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][AEpoch 26/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.56s/it][A
Epoch 26/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:17,  1.55s/it][A
Epoch 26/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A

Epoch 26/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it]Epoch 26/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A[A
Epoch 26/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 26/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 26/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 26/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A

Epoch 26/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][AEpoch 26/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A

Epoch 26/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][AEpoch 26/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 26/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 26/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 26/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it]
[AEpoch 26/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 26/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 26/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 26/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 26/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 26/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 26/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A

Epoch 26/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 26/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 26/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]
Epoch 26/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=3.0] Epoch 26 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.697e-01
  layer model_7__forward_module.module.conv2 act-std: mean=8.095e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.152e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.210e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.461e+00
  layer model_5__forward_module.module.conv2 act-std: mean=1.011e+00
  layer model_4__forward_module.module.conv1 act-std: mean=9.994e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.092e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.758e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.277e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.037e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.922e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.228e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.698e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.309e+00
  layer model_0__forward_module.module.conv2 act-std: mean=9.218e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.004e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=4.347e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.908e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.712e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.044e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.840e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.763e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.278e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=1.886e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=3.569e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.618e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=2.420e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=2.446e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=4.752e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.958e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=3.293e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.083e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=3.698e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.742e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=2.784e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.953e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=3.432e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.350e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=3.623e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.076e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=5.434e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.084e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=4.121e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=2.594e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=4.575e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.739e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=3.184e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.75it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Epoch 26/32 - Train Loss: 38.311582 - Test Loss: 34.674133
Training epochs:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 26/32 [09:24<02:10, 21.82s/it]
Epoch 27/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 26/32 [09:24<02:10, 21.82s/it]
Epoch 27/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 27/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.55s/it][A
Epoch 27/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 27/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 27/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 27/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 27/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 27/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 27/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 27/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 27/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 27/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 27/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 27/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 27/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 27/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 27/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A

Epoch 27/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][AEpoch 27/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A

Epoch 27/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][AEpoch 27/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 27/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 27/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A

Epoch 27/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][AEpoch 27/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 27/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 27/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=3.0] Epoch 27 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.699e-01
  layer model_7__forward_module.module.conv2 act-std: mean=8.097e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.152e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.211e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.462e+00
  layer model_5__forward_module.module.conv2 act-std: mean=1.010e+00
  layer model_4__forward_module.module.conv1 act-std: mean=9.995e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.094e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.760e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.280e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.038e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.932e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.228e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.695e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.309e+00
  layer model_0__forward_module.module.conv2 act-std: mean=9.189e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.488e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=2.957e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.719e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.341e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=9.239e-02
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.570e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.711e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=1.965e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=2.344e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=4.434e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.715e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.383e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.040e-01

  param model_3__forward_module.module.conv1.bias grad-norm: mean=6.189e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.216e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.439e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.046e-01
Epoch 27/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it]  param model_4__forward_module.module.conv1.bias grad-norm: mean=3.712e-02[A
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.708e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=2.765e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.722e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=2.915e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.234e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=3.289e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.260e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=5.807e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.293e-01Epoch 27/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

  param model_6__forward_module.module.conv2.bias grad-norm: mean=4.611e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=2.943e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=5.683e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.755e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=3.285e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.76it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]
Training epochs:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 27/32 [09:45<01:48, 21.79s/it]
Epoch 28/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Epoch 27/32 - Train Loss: 38.298391 - Test Loss: 34.674013
Training epochs:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 27/32 [09:45<01:48, 21.80s/it]
Epoch 28/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 28/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.56s/it][A
Epoch 28/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A

Epoch 28/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:17,  1.55s/it][AEpoch 28/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 28/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 28/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.55s/it][A
Epoch 28/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 28/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.55s/it][A
Epoch 28/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 28/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A

Epoch 28/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][AEpoch 28/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 28/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 28/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 28/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 28/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 28/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 28/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A

Epoch 28/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][AEpoch 28/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 28/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 28/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 28/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 28/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 28/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 28/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=3.0] Epoch 28 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.704e-01
  layer model_7__forward_module.module.conv2 act-std: mean=8.109e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.152e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.212e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.462e+00

  layer model_5__forward_module.module.conv2 act-std: mean=1.009e+00
  layer model_4__forward_module.module.conv1 act-std: mean=9.995e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.097e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.764e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.289e-01Epoch 28/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it]
[A  layer model_2__forward_module.module.conv1 act-std: mean=1.038e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.943e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.228e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.698e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.309e+00
  layer model_0__forward_module.module.conv2 act-std: mean=9.208e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.362e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=2.658e-02Epoch 28/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.726e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.397e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.048e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.808e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.819e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.328e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=2.454e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=4.651e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.750e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.563e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=2.601e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=4.998e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.064e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=3.676e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.025e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=3.607e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.857e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=2.903e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.756e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=3.061e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.150e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=2.963e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.261e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=5.782e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.501e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=4.944e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=2.295e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=3.817e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.700e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=3.312e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.83it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]
Training epochs:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 28/32 [10:07<01:27, 21.78s/it]
Epoch 29/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Epoch 28/32 - Train Loss: 38.294725 - Test Loss: 34.671572
Training epochs:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 28/32 [10:07<01:27, 21.78s/it]
Epoch 29/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 29/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 29/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.55s/it][A

Epoch 29/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][AEpoch 29/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 29/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 29/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 29/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 29/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 29/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 29/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A

Epoch 29/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][AEpoch 29/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 29/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 29/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A

Epoch 29/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][AEpoch 29/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 29/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 29/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A

Epoch 29/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][AEpoch 29/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A

Epoch 29/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][AEpoch 29/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 29/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 29/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 29/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 29/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

Epoch 29/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 29/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=3.0] Epoch 29 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.706e-01
  layer model_7__forward_module.module.conv2 act-std: mean=8.099e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.153e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.213e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.463e+00
  layer model_5__forward_module.module.conv2 act-std: mean=1.009e+00
  layer model_4__forward_module.module.conv1 act-std: mean=9.995e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.101e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.766e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.279e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.038e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.933e-01

  layer model_1__forward_module.module.conv1 act-std: mean=1.229e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.700e+00Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  layer model_0__forward_module.module.conv1 act-std: mean=1.310e+00
  layer model_0__forward_module.module.conv2 act-std: mean=9.204e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.502e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=3.054e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.716e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.349e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.107e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.101e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.763e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.364e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=2.148e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=4.164e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.674e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=2.845e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=2.544e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=4.810e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.067e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=3.498e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.271e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=4.366e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.014e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.337e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.839e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=2.945e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.274e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=2.993e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.459e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=6.489e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.337e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=4.711e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=2.761e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=5.003e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.651e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=3.508e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]
Training epochs:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 29/32 [10:29<01:05, 21.75s/it]
Epoch 30/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Epoch 29/32 - Train Loss: 38.274629 - Test Loss: 34.672151
Training epochs:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 29/32 [10:29<01:05, 21.75s/it]
Epoch 30/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 30/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 30/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.55s/it][A
Epoch 30/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 30/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 30/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 30/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 30/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 30/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A

Epoch 30/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][AEpoch 30/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 30/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 30/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A

Epoch 30/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][AEpoch 30/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 30/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 30/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 30/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 30/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 30/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 30/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 30/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 30/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 30/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 30/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A

Epoch 30/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 30/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 30/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]
Epoch 30/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=3.0] Epoch 30 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.704e-01
  layer model_7__forward_module.module.conv2 act-std: mean=8.107e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.153e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.211e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.463e+00
  layer model_5__forward_module.module.conv2 act-std: mean=1.009e+00
  layer model_4__forward_module.module.conv1 act-std: mean=9.996e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.101e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.769e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.280e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.038e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.936e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.229e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.700e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.310e+00
  layer model_0__forward_module.module.conv2 act-std: mean=9.207e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.384e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=2.654e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.646e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.003e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.066e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.966e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.827e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.406e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=2.617e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=5.071e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.799e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.337e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=2.320e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=4.317e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.034e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=3.585e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.734e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=3.000e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.565e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=2.594e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.799e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=2.753e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.287e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=2.932e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=2.867e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=4.827e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.149e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=4.332e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.151e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=5.799e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.938e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=3.958e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.81it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.96it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.96it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]
Epoch 30/32 - Train Loss: 38.288631 - Test Loss: 34.670904
Training epochs:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 30/32 [10:50<00:43, 21.73s/it]
Epoch 31/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 30/32 [10:50<00:43, 21.72s/it]
Epoch 31/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 31/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 31/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 31/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:17,  1.63s/it][A
Epoch 31/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:17,  1.63s/it][A

Epoch 31/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.59s/it][AEpoch 31/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.59s/it][A
Epoch 31/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:14,  1.57s/it][A
Epoch 31/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:14,  1.57s/it][A
Epoch 31/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.56s/it][A
Epoch 31/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.56s/it][A

Epoch 31/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.55s/it][AEpoch 31/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.55s/it][A

Epoch 31/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.55s/it][AEpoch 31/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.55s/it][A
Epoch 31/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 31/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 31/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:14<00:06,  1.54s/it][A
Epoch 31/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:14<00:06,  1.54s/it][A

Epoch 31/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][AEpoch 31/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A

Epoch 31/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:17<00:03,  1.54s/it][AEpoch 31/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:17<00:03,  1.54s/it][A
Epoch 31/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 31/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A

Epoch 31/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 31/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 31/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.52s/it]
Epoch 31/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.52s/it]

[Î²=3.0] Epoch 31 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.704e-01
  layer model_7__forward_module.module.conv2 act-std: mean=8.106e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.153e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.214e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.463e+00
  layer model_5__forward_module.module.conv2 act-std: mean=1.008e+00
  layer model_4__forward_module.module.conv1 act-std: mean=9.995e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.104e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.771e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.287e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.039e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.937e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.229e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.699e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.310e+00
  layer model_0__forward_module.module.conv2 act-std: mean=9.207e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.549e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=3.170e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.716e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.402e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.074e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.875e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.812e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.176e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=1.964e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=3.537e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.642e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=2.562e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=2.097e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=3.765e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.064e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=3.099e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.025e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=3.758e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.868e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=2.777e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.926e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=3.203e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.260e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=3.224e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.185e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=5.808e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.214e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=4.539e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.056e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=5.682e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.851e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=3.961e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.76it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Training epochs:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 31/32 [11:12<00:21, 21.79s/it]
Epoch 32/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Epoch 31/32 - Train Loss: 38.281393 - Test Loss: 34.670355
Training epochs:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 31/32 [11:12<00:21, 21.79s/it]
Epoch 32/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 32/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.56s/it][AEpoch 32/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 32/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:17,  1.56s/it][A
Epoch 32/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:17,  1.55s/it][A
Epoch 32/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.55s/it][A
Epoch 32/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.56s/it][A
Epoch 32/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.55s/it][A
Epoch 32/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.55s/it][A

Epoch 32/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.55s/it][AEpoch 32/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.55s/it][A

Epoch 32/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.55s/it][AEpoch 32/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.55s/it][A
Epoch 32/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.55s/it][A
Epoch 32/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.55s/it][A
Epoch 32/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 32/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.55s/it][A

Epoch 32/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][AEpoch 32/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 32/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 32/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A

Epoch 32/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:17<00:03,  1.54s/it][AEpoch 32/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 32/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 32/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A

Epoch 32/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 32/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 32/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]
Epoch 32/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=3.0] Epoch 32 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.704e-01
  layer model_7__forward_module.module.conv2 act-std: mean=8.111e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.153e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.219e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.463e+00
  layer model_5__forward_module.module.conv2 act-std: mean=1.009e+00
  layer model_4__forward_module.module.conv1 act-std: mean=9.999e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.107e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.775e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.292e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.038e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.938e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.230e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.701e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.310e+00
  layer model_0__forward_module.module.conv2 act-std: mean=9.216e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.287e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=2.395e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.589e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=1.918e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=9.539e-02
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.576e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.556e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=1.610e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=2.369e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=4.603e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.748e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.343e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=2.407e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=4.615e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.089e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=3.548e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.946e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=3.440e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.890e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.057e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.820e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=3.160e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.341e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=3.360e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.313e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=6.116e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.216e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=4.431e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=2.847e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=5.325e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.817e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=3.560e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Epoch 32/32 - Train Loss: 38.338037 - Test Loss: 34.670168
Training epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [11:34<00:00, 21.80s/it]Training epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [11:34<00:00, 21.71s/it]
Training epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [11:34<00:00, 21.80s/it]Training epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [11:34<00:00, 21.71s/it]
Loaded best models from epoch 32 with loss 34.670168

>>> Completed beta = 3.0
>>> Time for this beta: 0:11:34
>>> Total elapsed time: 0:22:52
==================================================
Loaded data shape: torch.Size([4096, 2, 64, 64])
Training data shape: torch.Size([3276, 2, 64, 64])
Testing data shape: torch.Size([820, 2, 64, 64])

>>> Training the model at beta =  3.5
Training epochs:   0%|          | 0/32 [00:00<?, ?it/s]
>>> Training the model at beta = 3.5

Training epochs:   0%|          | 0/32 [00:00<?, ?it/s]
Epoch 1/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 1/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 1/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][AEpoch 1/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 1/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 1/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 1/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 1/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 1/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 1/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 1/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 1/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 1/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 1/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 1/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 1/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 1/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 1/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A

Epoch 1/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][AEpoch 1/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 1/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 1/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A

Epoch 1/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][AEpoch 1/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A

Epoch 1/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][AEpoch 1/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A

Epoch 1/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.43s/it][AEpoch 1/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]
Epoch 1/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.43s/it][A
[Î²=3.5] Epoch 1 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.543e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.673e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.154e+00
Epoch 1/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]  layer model_6__forward_module.module.conv2 act-std: mean=2.977e-01

  layer model_5__forward_module.module.conv1 act-std: mean=1.480e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.642e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.915e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.068e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.691e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.033e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.047e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.681e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.233e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.650e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.328e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.993e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=5.305e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.238e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=3.857e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=7.121e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=2.694e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=5.896e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=3.441e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=5.711e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=9.923e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=2.180e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=3.662e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.105e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.181e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.566e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=4.726e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.345e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=9.581e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=2.062e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=9.665e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.339e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=9.435e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=2.102e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=9.180e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.750e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.287e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=2.709e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.500e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.848e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.444e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=3.098e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=8.273e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.731e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.76it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.75it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.72it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.75it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.73it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.85it/s]
Training epochs:   3%|â–Ž         | 1/32 [00:21<11:14, 21.76s/it]
Epoch 2/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.83it/s]
Epoch 1/32 - Train Loss: 41.479071 - Test Loss: 37.363209
Training epochs:   3%|â–Ž         | 1/32 [00:21<11:15, 21.79s/it]
Epoch 2/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 2/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.56s/it]
[AEpoch 2/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A

Epoch 2/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][AEpoch 2/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 2/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 2/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.55s/it][A
Epoch 2/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 2/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.55s/it][A
Epoch 2/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 2/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 2/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 2/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 2/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 2/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 2/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 2/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A

Epoch 2/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][AEpoch 2/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 2/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 2/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 2/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 2/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 2/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 2/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 2/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 2/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=3.5] Epoch 2 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.554e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.827e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.153e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.027e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.474e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.871e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.940e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.098e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.737e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.152e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.049e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.805e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.235e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.693e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.326e+00
  layer model_0__forward_module.module.conv2 act-std: mean=9.143e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=3.623e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=7.358e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.959e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=4.468e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.607e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.902e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.590e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.416e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=6.256e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.221e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.887e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=7.295e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=6.939e-01

  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.358e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=3.417e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=7.823e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=4.868e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=9.460e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=5.696e-01
Epoch 2/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it]  param model_4__forward_module.module.conv2.bias grad-norm: mean=6.845e-02[A
  param model_5__forward_module.module.conv1.weight grad-norm: mean=4.995e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=9.085e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=5.515e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=8.925e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=7.662e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.471e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=9.425e-01Epoch 2/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.069e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=6.596e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.279e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=5.252e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=7.948e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A

Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][AEvaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A

Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][AEvaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Epoch 2/32 - Train Loss: 41.473269 - Test Loss: 37.357268
Training epochs:   6%|â–‹         | 2/32 [00:43<10:53, 21.77s/it]
Epoch 3/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:   6%|â–‹         | 2/32 [00:43<10:52, 21.77s/it]
Epoch 3/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 3/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 3/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 3/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 3/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 3/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 3/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A

Epoch 3/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][AEpoch 3/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 3/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 3/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A

Epoch 3/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][AEpoch 3/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A

Epoch 3/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][AEpoch 3/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A

Epoch 3/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][AEpoch 3/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 3/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 3/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 3/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 3/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A

Epoch 3/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][AEpoch 3/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 3/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 3/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 3/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.43s/it][AEpoch 3/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=3.5] Epoch 3 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.548e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.799e-01

  layer model_6__forward_module.module.conv1 act-std: mean=1.153e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.005e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.474e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.811e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.931e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.095e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.717e-01Epoch 3/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.43s/it]
[A  layer model_3__forward_module.module.conv2 act-std: mean=4.083e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.050e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.726e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.236e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.691e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.328e+00
  layer model_0__forward_module.module.conv2 act-std: mean=9.015e-01Epoch 3/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.413e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=5.053e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.864e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=4.338e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.475e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.587e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.527e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.143e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=4.118e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=8.731e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.681e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=6.064e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=4.284e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=9.217e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=3.218e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=6.417e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.777e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=5.004e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.698e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.742e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=3.726e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=6.942e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=4.264e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=6.558e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=4.759e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=9.463e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=5.999e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=6.513e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=5.131e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=9.801e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=4.249e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=6.344e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A

Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][AEvaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.77it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Epoch 3/32 - Train Loss: 41.461771 - Test Loss: 37.348127
Training epochs:   9%|â–‰         | 3/32 [01:05<10:31, 21.79s/it]
Epoch 4/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:   9%|â–‰         | 3/32 [01:05<10:31, 21.78s/it]
Epoch 4/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 4/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 4/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.55s/it][A

Epoch 4/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][AEpoch 4/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 4/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 4/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 4/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 4/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 4/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 4/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 4/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 4/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A

Epoch 4/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][AEpoch 4/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A

Epoch 4/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][AEpoch 4/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A

Epoch 4/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][AEpoch 4/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 4/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 4/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A

Epoch 4/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][AEpoch 4/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 4/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 4/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 4/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 4/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=3.5] Epoch 4 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.547e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.789e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.153e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.006e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.473e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.792e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.930e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.098e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.719e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.098e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.052e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.739e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.236e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.693e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.329e+00
  layer model_0__forward_module.module.conv2 act-std: mean=9.002e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.473e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=4.943e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.604e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.561e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.495e-01

  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.760e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.271e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.596e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.474e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=6.966e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.329e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=4.160e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.988e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=7.730e-02Epoch 4/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it]
[A  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.730e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=5.141e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=3.185e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=5.828e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.975e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=4.524e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.855e-01Epoch 4/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

  param model_5__forward_module.module.conv1.bias grad-norm: mean=5.436e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=3.300e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=4.679e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=5.491e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.059e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=6.775e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=7.481e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=4.470e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=8.605e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=4.003e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=5.682e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.77it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Epoch 4/32 - Train Loss: 41.439340 - Test Loss: 37.348048
Training epochs:  12%|â–ˆâ–Ž        | 4/32 [01:27<10:09, 21.76s/it]
Epoch 5/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  12%|â–ˆâ–Ž        | 4/32 [01:27<10:09, 21.76s/it]
Epoch 5/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 5/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 5/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 5/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 5/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 5/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 5/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A

Epoch 5/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][AEpoch 5/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 5/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 5/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 5/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 5/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 5/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 5/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 5/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 5/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 5/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 5/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 5/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 5/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 5/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 5/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A

Epoch 5/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][AEpoch 5/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 5/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 5/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=3.5] Epoch 5 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.546e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.794e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.153e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.010e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.472e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.812e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.934e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.103e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.723e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.105e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.052e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.734e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.236e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.697e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.329e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.991e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.615e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=5.144e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.521e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.202e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.412e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.451e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.380e-01

  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.733e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.328e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=6.256e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.335e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=4.127e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.547e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=6.754e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.817e-01Epoch 5/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it]
[A  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.861e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.575e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=4.142e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.525e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.408e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.536e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=4.272e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=3.341e-01
Epoch 5/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]  param model_5__forward_module.module.conv2.bias grad-norm: mean=4.311e-02

  param model_6__forward_module.module.conv1.weight grad-norm: mean=4.405e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=7.572e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=5.748e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.764e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.497e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=6.068e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.571e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.351e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.56it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Training epochs:  16%|â–ˆâ–Œ        | 5/32 [01:48<09:47, 21.75s/it]
Epoch 6/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.76it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.73it/s]
Epoch 5/32 - Train Loss: 41.431327 - Test Loss: 37.346342
Training epochs:  16%|â–ˆâ–Œ        | 5/32 [01:48<09:48, 21.81s/it]
Epoch 6/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 6/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][AEpoch 6/32:   8%|â–Š         | 1/13 [00:01<00:20,  1.70s/it][A
Epoch 6/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:17,  1.60s/it][A
Epoch 6/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A

Epoch 6/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.57s/it][AEpoch 6/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A

Epoch 6/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:14,  1.56s/it][AEpoch 6/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A

Epoch 6/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][AEpoch 6/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.55s/it][A
Epoch 6/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 6/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 6/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 6/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 6/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 6/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A

Epoch 6/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][AEpoch 6/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 6/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 6/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 6/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 6/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:17<00:03,  1.54s/it][A
Epoch 6/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 6/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 6/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 6/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=3.5] Epoch 6 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.548e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.804e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.154e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.008e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.472e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.831e-01

  layer model_4__forward_module.module.conv1 act-std: mean=9.937e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.105e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.722e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.102e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.053e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.721e-01Epoch 6/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it]
[A  layer model_1__forward_module.module.conv1 act-std: mean=1.236e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.699e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.329e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.971e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.125e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=4.117e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.447e-01Epoch 6/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.52s/it]

  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.224e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.392e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.380e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.380e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.807e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=2.630e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=4.896e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.223e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.694e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.439e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=6.457e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.946e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.986e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.814e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=4.937e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.616e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.711e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.704e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=4.387e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=3.341e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=4.616e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.889e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=6.417e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=5.759e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.727e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=4.381e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=8.095e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.885e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=5.758e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.76it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.74it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Epoch 6/32 - Train Loss: 41.432199 - Test Loss: 37.345871
Training epochs:  19%|â–ˆâ–‰        | 6/32 [02:10<09:26, 21.79s/it]
Epoch 7/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  19%|â–ˆâ–‰        | 6/32 [02:10<09:26, 21.77s/it]
Epoch 7/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 7/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 7/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A

Epoch 7/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][AEpoch 7/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 7/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 7/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 7/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.55s/it][A
Epoch 7/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.55s/it][A
Epoch 7/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 7/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A

Epoch 7/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][AEpoch 7/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 7/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 7/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 7/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 7/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A

Epoch 7/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][AEpoch 7/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 7/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 7/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 7/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 7/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 7/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 7/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 7/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 7/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]


[Î²=3.5] Epoch 7 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.548e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.805e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.154e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.010e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.471e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.829e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.939e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.108e+00Epoch 7/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it]
[A  layer model_3__forward_module.module.conv1 act-std: mean=6.723e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.104e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.053e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.724e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.236e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.700e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.330e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.966e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.137e-01Epoch 7/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

  param model_0__forward_module.module.conv1.bias grad-norm: mean=4.147e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.364e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.113e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.349e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.328e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.244e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.520e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.014e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=5.513e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.373e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.802e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.628e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=6.963e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.899e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.603e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.742e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=4.715e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=4.020e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=4.337e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.709e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=4.007e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=3.245e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=4.524e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=4.498e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=7.920e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=6.548e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=6.947e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.965e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=6.832e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.816e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=5.126e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.84it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.82it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.81it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.81it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Epoch 7/32 - Train Loss: 41.410336 - Test Loss: 37.345245
Training epochs:  22%|â–ˆâ–ˆâ–       | 7/32 [02:32<09:04, 21.78s/it]
Epoch 8/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  22%|â–ˆâ–ˆâ–       | 7/32 [02:32<09:04, 21.77s/it]
Epoch 8/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 8/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][AEpoch 8/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.55s/it][A
Epoch 8/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 8/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 8/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 8/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 8/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 8/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 8/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 8/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 8/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 8/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 8/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 8/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 8/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 8/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 8/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 8/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 8/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 8/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A

Epoch 8/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][AEpoch 8/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A

Epoch 8/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][AEpoch 8/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 8/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 8/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

Epoch 8/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][A
Epoch 8/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
[Î²=3.5] Epoch 8 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.551e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.810e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.154e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.013e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.471e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.832e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.941e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.109e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.722e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.104e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.053e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.721e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.236e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.701e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.330e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.960e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.202e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=4.240e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.416e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.157e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.330e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.212e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.380e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.883e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=2.022e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=3.309e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.127e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=2.807e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.035e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=5.751e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.794e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.408e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.564e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=4.234e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.755e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.848e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.670e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=4.377e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=3.268e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=4.878e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=4.214e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=6.832e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=5.924e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=6.267e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=4.022e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=6.940e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.823e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=5.374e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.76it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.74it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.76it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.75it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.76it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.75it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.84it/s]
Training epochs:  25%|â–ˆâ–ˆâ–Œ       | 8/32 [02:54<08:42, 21.79s/it]
Epoch 9/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.82it/s]
Epoch 8/32 - Train Loss: 41.417524 - Test Loss: 37.344347
Training epochs:  25%|â–ˆâ–ˆâ–Œ       | 8/32 [02:54<08:42, 21.78s/it]
Epoch 9/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 9/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 9/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.55s/it][A

Epoch 9/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][AEpoch 9/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 9/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 9/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 9/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 9/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 9/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 9/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 9/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 9/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 9/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 9/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A

Epoch 9/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][AEpoch 9/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 9/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 9/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A

Epoch 9/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][AEpoch 9/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A

Epoch 9/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][AEpoch 9/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 9/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 9/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 9/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 9/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

Epoch 9/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 9/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
[Î²=3.5] Epoch 9 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.552e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.810e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.154e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.012e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.470e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.830e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.943e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.111e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.722e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.103e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.053e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.720e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.237e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.703e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.330e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.957e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.814e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=3.300e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.368e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.573e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.470e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.678e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.338e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.783e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.437e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=6.564e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.317e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=4.071e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.007e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=5.700e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.754e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.225e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.388e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=3.832e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.435e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.161e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=3.160e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=5.537e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=3.384e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=5.211e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=4.716e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=8.760e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=6.020e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=6.485e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=4.202e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=7.612e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.701e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=5.010e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Epoch 9/32 - Train Loss: 41.398211 - Test Loss: 37.344292
Training epochs:  28%|â–ˆâ–ˆâ–Š       | 9/32 [03:15<08:20, 21.77s/it]
Epoch 10/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  28%|â–ˆâ–ˆâ–Š       | 9/32 [03:15<08:20, 21.77s/it]
Epoch 10/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 10/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][AEpoch 10/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A

Epoch 10/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][AEpoch 10/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 10/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 10/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.55s/it][A
Epoch 10/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.55s/it][A
Epoch 10/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.55s/it][A
Epoch 10/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 10/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A

Epoch 10/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][AEpoch 10/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A

Epoch 10/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][AEpoch 10/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 10/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 10/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 10/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 10/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A

Epoch 10/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it]Epoch 10/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A[A

Epoch 10/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][AEpoch 10/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A

Epoch 10/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][AEpoch 10/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 10/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 10/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]


[Î²=3.5] Epoch 10 summary:
  input  std: mean=1.814e+00
Epoch 10/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it]  layer model_7__forward_module.module.conv1 act-std: mean=9.552e-01[A
  layer model_7__forward_module.module.conv2 act-std: mean=7.815e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.154e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.014e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.470e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.831e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.946e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.113e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.722e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.106e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.053e+00Epoch 10/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

  layer model_2__forward_module.module.conv2 act-std: mean=4.720e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.237e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.704e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.330e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.949e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.944e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=3.711e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.362e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.788e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.425e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.590e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.295e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.733e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.041e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=5.470e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.394e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=4.279e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.914e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=7.777e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=3.106e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=5.375e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.695e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=4.618e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.477e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.437e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.853e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=4.864e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=3.065e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=4.156e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=4.195e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=7.223e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=5.681e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.925e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=4.123e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=7.171e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.908e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=5.104e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]
Training epochs:  31%|â–ˆâ–ˆâ–ˆâ–      | 10/32 [03:37<07:59, 21.77s/it]
Epoch 11/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Epoch 10/32 - Train Loss: 41.438571 - Test Loss: 37.343863
Training epochs:  31%|â–ˆâ–ˆâ–ˆâ–      | 10/32 [03:37<07:59, 21.78s/it]
Epoch 11/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 11/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.55s/it][A
Epoch 11/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 11/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 11/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A

Epoch 11/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][AEpoch 11/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A

Epoch 11/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][AEpoch 11/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 11/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 11/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 11/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:11,  1.59s/it][A
Epoch 11/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:11,  1.59s/it][A
Epoch 11/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.57s/it][A
Epoch 11/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.57s/it][A
Epoch 11/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.55s/it][A
Epoch 11/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.56s/it][A

Epoch 11/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.55s/it][AEpoch 11/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.55s/it][A

Epoch 11/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.55s/it][AEpoch 11/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.55s/it][A
Epoch 11/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:17<00:03,  1.54s/it][A
Epoch 11/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:17<00:03,  1.54s/it][A
Epoch 11/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 11/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 11/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 11/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.52s/it]

Epoch 11/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 11/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=3.5] Epoch 11 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.554e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.813e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.154e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.015e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.470e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.829e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.947e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.114e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.723e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.108e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.053e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.718e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.237e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.704e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.330e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.944e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.171e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=4.182e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.399e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.116e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.504e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.665e-02

  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.431e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.026e-02Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.031e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=5.709e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.326e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.938e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.679e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=7.265e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.810e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.696e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=3.277e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=6.053e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.833e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=4.112e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.113e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=3.254e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.923e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=3.949e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.642e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=5.908e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=5.346e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.256e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.612e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=6.333e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.648e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.966e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.81it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Epoch 11/32 - Train Loss: 41.396504 - Test Loss: 37.343346
Training epochs:  34%|â–ˆâ–ˆâ–ˆâ–      | 11/32 [03:59<07:37, 21.80s/it]
Epoch 12/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  34%|â–ˆâ–ˆâ–ˆâ–      | 11/32 [03:59<07:37, 21.79s/it]
Epoch 12/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 12/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 12/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.55s/it][A
Epoch 12/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 12/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 12/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 12/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 12/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 12/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 12/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 12/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 12/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 12/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A

Epoch 12/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][AEpoch 12/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A

Epoch 12/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][AEpoch 12/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 12/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 12/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A

Epoch 12/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][AEpoch 12/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A

Epoch 12/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it]Epoch 12/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A[A

Epoch 12/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][AEpoch 12/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 12/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 12/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

Epoch 12/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 12/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=3.5] Epoch 12 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.555e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.816e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.154e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.018e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.470e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.833e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.949e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.115e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.723e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.107e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.053e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.717e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.237e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.704e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.331e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.943e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.369e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=4.687e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.519e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.305e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.375e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.282e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.483e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.027e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=2.932e-01

  param model_2__forward_module.module.conv1.bias grad-norm: mean=5.579e-02
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.217e-01[A
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.841e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.236e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=5.893e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.831e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.189e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.590e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=4.308e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.909e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=4.095e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.852e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=4.894e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=3.575e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=5.568e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=4.148e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=6.889e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=5.784e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=6.055e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.998e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=7.257e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.844e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=5.342e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.82it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Epoch 12/32 - Train Loss: 41.463809 - Test Loss: 37.343028
Training epochs:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 12/32 [04:21<07:15, 21.78s/it]
Epoch 13/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 12/32 [04:21<07:15, 21.78s/it]
Epoch 13/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 13/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 13/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 13/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 13/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 13/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 13/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A

Epoch 13/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][AEpoch 13/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 13/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 13/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 13/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 13/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 13/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 13/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 13/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 13/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 13/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.59s/it][A
Epoch 13/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.59s/it][A
Epoch 13/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.57s/it][A
Epoch 13/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.57s/it][A
Epoch 13/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:17<00:03,  1.56s/it][A
Epoch 13/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:17<00:03,  1.56s/it][A
Epoch 13/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.55s/it][A
Epoch 13/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.55s/it][A
Epoch 13/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.43s/it][A
Epoch 13/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.52s/it]

[Î²=3.5] Epoch 13 summary:
  input  std: mean=1.814e+00Epoch 13/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.43s/it]
[A  layer model_7__forward_module.module.conv1 act-std: mean=9.555e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.817e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.154e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.018e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.469e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.832e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.951e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.116e+00
Epoch 13/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.52s/it]  layer model_3__forward_module.module.conv1 act-std: mean=6.721e-01

  layer model_3__forward_module.module.conv2 act-std: mean=4.106e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.053e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.715e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.237e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.705e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.331e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.943e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.113e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=4.258e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.530e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.508e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.379e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.450e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.375e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.766e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=2.984e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=5.594e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.409e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=4.182e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=4.439e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=8.885e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=3.078e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=5.591e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.675e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=4.622e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.519e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.261e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=3.170e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=5.901e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=3.429e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=4.894e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=4.426e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=7.745e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=5.893e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=6.067e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=4.378e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=7.902e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.774e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.969e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.77it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.71it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.74it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.75it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Training epochs:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 13/32 [04:43<06:54, 21.82s/it]
Epoch 14/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.83it/s]
Epoch 13/32 - Train Loss: 41.444703 - Test Loss: 37.342885
Training epochs:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 13/32 [04:43<06:54, 21.83s/it]
Epoch 14/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 14/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 14/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.57s/it][A
Epoch 14/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 14/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:17,  1.55s/it][A
Epoch 14/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.55s/it][A
Epoch 14/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 14/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 14/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.55s/it][A
Epoch 14/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 14/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 14/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 14/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 14/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 14/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 14/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 14/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A

Epoch 14/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][AEpoch 14/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A

Epoch 14/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][AEpoch 14/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 14/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 14/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 14/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 14/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 14/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 14/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=3.5] Epoch 14 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.558e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.821e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.154e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.018e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.469e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.835e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.951e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.117e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.721e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.107e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.053e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.714e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.237e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.706e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.331e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.940e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.074e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=3.811e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.288e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.768e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.257e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.970e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.051e-01

  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.198e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=2.593e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=4.726e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.199e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.539e-02
Epoch 14/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it]  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.753e-01[A
  param model_3__forward_module.module.conv1.bias grad-norm: mean=7.470e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.927e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.736e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.981e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=5.407e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.957e-01
Epoch 14/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]  param model_4__forward_module.module.conv2.bias grad-norm: mean=4.239e-02

  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.800e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=5.215e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=3.512e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=4.947e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=4.913e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=9.086e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=6.264e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=6.653e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.616e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=6.211e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.721e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.838e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.76it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Training epochs:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 14/32 [05:05<06:32, 21.82s/it]
Epoch 15/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Epoch 14/32 - Train Loss: 41.413486 - Test Loss: 37.342529
Training epochs:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 14/32 [05:05<06:32, 21.82s/it]
Epoch 15/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 15/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 15/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.56s/it][A
Epoch 15/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:17,  1.55s/it][A
Epoch 15/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A

Epoch 15/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][AEpoch 15/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 15/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 15/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 15/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 15/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 15/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 15/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 15/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 15/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A

Epoch 15/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][AEpoch 15/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 15/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 15/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 15/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 15/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A

Epoch 15/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it]Epoch 15/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A[A

Epoch 15/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][AEpoch 15/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 15/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 15/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

Epoch 15/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 15/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=3.5] Epoch 15 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.557e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.820e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.154e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.018e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.469e+00

  layer model_5__forward_module.module.conv2 act-std: mean=9.837e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.952e-01Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  layer model_4__forward_module.module.conv2 act-std: mean=2.117e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.722e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.105e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.053e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.711e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.237e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.706e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.331e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.941e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.128e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=4.152e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.485e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.247e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.356e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.399e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.228e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.535e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=2.856e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=5.241e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.305e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.592e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.204e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=6.014e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.794e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.369e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.771e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=4.980e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=4.360e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=4.715e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.288e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=3.289e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.968e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=3.978e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.961e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=6.533e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=6.009e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=6.032e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.773e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=7.035e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.635e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.411e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Epoch 15/32 - Train Loss: 41.440192 - Test Loss: 37.342445
Training epochs:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 15/32 [05:26<06:10, 21.81s/it]Training epochs:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 15/32 [05:26<06:10, 21.80s/it]
Epoch 16/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 16/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 16/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 16/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 16/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 16/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 16/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 16/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 16/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 16/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 16/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 16/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 16/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 16/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 16/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 16/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A

Epoch 16/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][AEpoch 16/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 16/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 16/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 16/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 16/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 16/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 16/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 16/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 16/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 16/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][A
Epoch 16/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=3.5] Epoch 16 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.557e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.818e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.154e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.016e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.469e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.836e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.952e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.118e+00
Epoch 16/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it]  layer model_3__forward_module.module.conv1 act-std: mean=6.721e-01[A
  layer model_3__forward_module.module.conv2 act-std: mean=4.107e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.053e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.712e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.237e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.707e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.331e+00
Epoch 16/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]  layer model_0__forward_module.module.conv2 act-std: mean=8.936e-01

  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.161e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=4.122e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.499e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.178e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.448e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.489e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.390e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.721e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.698e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=7.510e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.375e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=4.447e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.681e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=7.247e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.885e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.679e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.616e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=4.615e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.762e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.721e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.841e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=5.025e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=3.184e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=4.867e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=4.377e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=7.685e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=6.310e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=6.730e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.866e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=6.513e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.898e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=5.248e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.76it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.74it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.76it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Training epochs:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 16/32 [05:48<05:48, 21.77s/it]
Epoch 17/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Epoch 16/32 - Train Loss: 41.387188 - Test Loss: 37.341865
Training epochs:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 16/32 [05:48<05:48, 21.78s/it]
Epoch 17/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 17/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.56s/it][A
Epoch 17/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 17/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 17/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:17,  1.55s/it][A
Epoch 17/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 17/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.55s/it][A

Epoch 17/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][AEpoch 17/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 17/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 17/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A

Epoch 17/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][AEpoch 17/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 17/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it]
[AEpoch 17/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 17/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 17/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 17/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 17/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 17/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 17/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 17/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 17/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 17/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 17/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 17/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 17/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

Epoch 17/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 17/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=3.5] Epoch 17 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.557e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.822e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.154e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.018e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.469e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.836e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.954e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.119e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.722e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.111e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.053e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.714e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.237e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.707e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.331e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.936e-01

  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.889e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=3.540e-02Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.387e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.979e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.519e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.796e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.499e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.971e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=2.915e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=5.336e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.336e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=4.156e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.932e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=7.496e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.852e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.864e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.669e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=4.757e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.833e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=4.083e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.784e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=5.012e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.979e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=4.298e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=4.827e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=8.546e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=6.375e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=6.660e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=5.445e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.055e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=4.307e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=6.500e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A

Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][AEvaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][A

Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.76it/s][AEvaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.75it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.74it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.74it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.83it/s]
Epoch 17/32 - Train Loss: 41.428082 - Test Loss: 37.341860

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.83it/s]
Training epochs:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 17/32 [06:10<05:26, 21.78s/it]
Epoch 18/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 17/32 [06:10<05:26, 21.78s/it]
Epoch 18/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 18/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][AEpoch 18/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 18/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 18/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 18/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 18/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 18/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 18/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 18/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 18/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 18/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 18/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 18/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 18/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 18/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 18/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A

Epoch 18/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][AEpoch 18/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 18/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 18/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 18/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 18/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A

Epoch 18/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][AEpoch 18/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 18/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 18/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=3.5] Epoch 18 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.558e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.823e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.154e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.019e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.469e+00

  layer model_5__forward_module.module.conv2 act-std: mean=9.839e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.954e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.120e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.722e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.109e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.053e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.712e-01Epoch 18/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it]
[A  layer model_1__forward_module.module.conv1 act-std: mean=1.237e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.708e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.331e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.935e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.594e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=2.682e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.252e-01
Epoch 18/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.533e-02

  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.378e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.412e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.469e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.010e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.608e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=7.003e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.287e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=4.294e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.897e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=7.370e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.864e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=5.227e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.454e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=4.052e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.587e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.563e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.562e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=4.597e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=3.032e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=4.182e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=4.092e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=6.710e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=5.452e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.375e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=4.448e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=8.200e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.853e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=5.365e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.77it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.76it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.85it/s]
Epoch 18/32 - Train Loss: 41.413876 - Test Loss: 37.341693
Training epochs:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 18/32 [06:32<05:04, 21.77s/it]
Epoch 19/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 18/32 [06:32<05:04, 21.77s/it]
Epoch 19/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 19/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.55s/it][A
Epoch 19/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.56s/it][A
Epoch 19/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 19/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.55s/it][A
Epoch 19/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 19/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A

Epoch 19/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][AEpoch 19/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A

Epoch 19/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][AEpoch 19/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.55s/it][A
Epoch 19/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 19/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 19/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 19/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A

Epoch 19/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][AEpoch 19/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 19/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 19/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A

Epoch 19/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][AEpoch 19/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A

Epoch 19/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:17<00:03,  1.65s/it][AEpoch 19/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:17<00:03,  1.65s/it][A
Epoch 19/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.63s/it][A
Epoch 19/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.63s/it][A
Epoch 19/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:20<00:00,  1.48s/it][A
Epoch 19/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:20<00:00,  1.54s/it]
Epoch 19/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:20<00:00,  1.48s/it][AEpoch 19/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:20<00:00,  1.54s/it]

[Î²=3.5] Epoch 19 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.560e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.825e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.154e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.022e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.469e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.843e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.955e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.121e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.723e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.112e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.053e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.714e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.237e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.709e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.331e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.936e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.466e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=5.101e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.592e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.704e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.353e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.402e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.302e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.069e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=2.837e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=5.364e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.252e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=4.162e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.496e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=7.203e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.833e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.756e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.786e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=4.897e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.934e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.986e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.927e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=5.424e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=3.319e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=4.828e-02

  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.998e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=6.803e-02Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  param model_6__forward_module.module.conv2.weight grad-norm: mean=5.645e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.666e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=4.099e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=7.545e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.817e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=5.036e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.77it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.76it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Epoch 19/32 - Train Loss: 41.467432 - Test Loss: 37.341633
Training epochs:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 19/32 [06:54<04:44, 21.91s/it]Training epochs:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 19/32 [06:54<04:44, 21.91s/it]

Epoch 20/32:   0%|          | 0/13 [00:00<?, ?it/s][AEpoch 20/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 20/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it]
[AEpoch 20/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 20/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 20/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 20/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 20/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 20/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.55s/it][A
Epoch 20/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.55s/it][A
Epoch 20/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 20/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 20/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 20/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A

Epoch 20/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][AEpoch 20/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A

Epoch 20/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][AEpoch 20/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A

Epoch 20/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][AEpoch 20/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A

Epoch 20/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][AEpoch 20/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 20/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 20/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 20/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 20/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 20/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it]
[AEpoch 20/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 20/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]
Epoch 20/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=3.5] Epoch 20 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.558e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.818e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.154e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.019e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.469e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.836e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.955e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.120e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.721e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.107e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.053e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.709e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.237e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.709e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.331e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.932e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.732e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=3.132e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.388e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.889e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.623e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=3.092e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.651e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.526e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.109e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=5.785e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.258e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=4.284e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.488e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=6.477e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.906e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.965e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.807e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=4.889e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.925e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=4.070e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.652e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=4.629e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=3.094e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=4.116e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=4.300e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=7.392e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=6.074e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.970e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=4.259e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=7.741e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.883e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=5.344e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Epoch 20/32 - Train Loss: 41.411963 - Test Loss: 37.341384
Training epochs:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 20/32 [07:16<04:22, 21.86s/it]
Epoch 21/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 20/32 [07:16<04:22, 21.86s/it]
Epoch 21/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 21/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 21/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 21/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 21/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 21/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 21/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 21/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 21/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 21/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 21/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 21/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 21/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 21/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 21/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 21/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.59s/it][A
Epoch 21/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.59s/it][A
Epoch 21/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:14<00:06,  1.57s/it][A
Epoch 21/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:14<00:06,  1.57s/it][A
Epoch 21/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.56s/it][A
Epoch 21/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.57s/it][A

Epoch 21/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:17<00:03,  1.56s/it][AEpoch 21/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:17<00:03,  1.56s/it][A

Epoch 21/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.55s/it][AEpoch 21/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.55s/it][A

Epoch 21/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.43s/it][AEpoch 21/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.43s/it][AEpoch 21/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.52s/it]

[Î²=3.5] Epoch 21 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.559e-01
Epoch 21/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.52s/it]  layer model_7__forward_module.module.conv2 act-std: mean=7.826e-01

  layer model_6__forward_module.module.conv1 act-std: mean=1.154e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.022e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.469e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.843e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.955e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.121e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.722e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.111e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.053e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.712e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.237e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.709e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.331e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.936e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.203e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=4.239e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.421e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.111e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.302e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.150e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.278e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.401e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=2.722e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=5.033e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.180e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.874e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=4.226e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=8.518e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.998e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=5.159e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.974e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=5.405e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=4.131e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=4.478e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=3.036e-01

  param model_5__forward_module.module.conv1.bias grad-norm: mean=5.382e-02
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  param model_5__forward_module.module.conv2.weight grad-norm: mean=3.236e-01[A
  param model_5__forward_module.module.conv2.bias grad-norm: mean=4.326e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=5.112e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=9.882e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=6.311e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=6.967e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.805e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=6.997e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.480e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.333e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.74it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.74it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Epoch 21/32 - Train Loss: 41.457663 - Test Loss: 37.341249
Training epochs:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 21/32 [07:38<04:00, 21.88s/it]
Epoch 22/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 21/32 [07:38<04:00, 21.88s/it]
Epoch 22/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 22/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 22/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 22/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 22/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 22/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 22/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 22/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 22/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A

Epoch 22/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][AEpoch 22/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 22/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 22/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 22/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 22/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 22/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 22/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 22/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 22/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 22/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 22/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A

Epoch 22/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][AEpoch 22/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 22/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 22/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 22/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 22/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

Epoch 22/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 22/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=3.5] Epoch 22 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.559e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.820e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.154e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.020e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.469e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.841e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.957e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.121e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.722e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.110e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.053e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.711e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.237e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.709e+00

  layer model_0__forward_module.module.conv1 act-std: mean=1.331e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.932e-01Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.033e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=3.816e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.365e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.993e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.502e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.764e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.367e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.887e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=2.857e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=5.285e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.217e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.751e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=2.714e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=4.846e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.759e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.104e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=3.431e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=6.542e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.884e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=4.224e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.419e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=3.859e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.988e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=3.894e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=4.112e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=7.384e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=5.765e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.992e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.714e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=6.619e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.703e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=5.022e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.69it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.75it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Training epochs:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 22/32 [07:59<03:38, 21.84s/it]
Epoch 23/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Epoch 22/32 - Train Loss: 41.399779 - Test Loss: 37.341125
Training epochs:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 22/32 [07:59<03:38, 21.84s/it]
Epoch 23/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 23/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.55s/it][A
Epoch 23/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A

Epoch 23/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:17,  1.55s/it][AEpoch 23/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 23/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 23/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 23/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 23/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A

Epoch 23/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][AEpoch 23/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A

Epoch 23/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][AEpoch 23/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 23/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 23/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 23/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 23/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 23/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 23/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A

Epoch 23/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][AEpoch 23/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A

Epoch 23/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][AEpoch 23/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A

Epoch 23/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][AEpoch 23/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 23/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.43s/it][AEpoch 23/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=3.5] Epoch 23 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.558e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.821e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.155e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.021e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.469e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.838e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.957e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.121e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.721e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.111e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.053e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.710e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.238e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.709e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.331e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.931e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.688e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=2.894e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.228e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.595e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.495e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.628e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.659e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.499e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=2.899e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=5.476e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.253e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=4.064e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=4.686e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=9.445e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.946e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=5.922e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.873e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=5.229e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.887e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=4.304e-02

  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.659e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=4.123e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=3.139e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=4.461e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=4.416e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=7.507e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=5.961e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.980e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=4.752e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=9.236e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.897e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=5.340e-02
Epoch 23/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.43s/it][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][AEpoch 23/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.77it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.76it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.85it/s]
Epoch 23/32 - Train Loss: 41.392796 - Test Loss: 37.341051
Training epochs:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 23/32 [08:21<03:16, 21.83s/it]
Epoch 24/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 23/32 [08:21<03:16, 21.83s/it]
Epoch 24/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 24/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.55s/it][A
Epoch 24/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.55s/it][A

Epoch 24/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:17,  1.55s/it][AEpoch 24/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 24/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 24/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 24/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 24/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 24/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 24/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A

Epoch 24/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it]Epoch 24/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A[A
Epoch 24/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 24/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 24/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 24/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A

Epoch 24/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][AEpoch 24/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 24/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 24/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A

Epoch 24/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][AEpoch 24/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 24/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 24/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 24/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 24/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

Epoch 24/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 24/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=3.5] Epoch 24 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.559e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.822e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.155e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.020e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.469e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.840e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.957e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.122e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.721e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.110e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.053e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.710e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.237e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.709e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.331e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.932e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.310e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=4.524e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.547e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.543e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.312e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.220e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.114e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.370e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.133e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=5.784e-02

  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.203e-01
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.980e-02[A
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.558e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=6.978e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.838e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.790e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.881e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=5.181e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=4.027e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=4.074e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.705e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=4.382e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=3.396e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=4.753e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=4.244e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=7.631e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=5.536e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.617e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=4.322e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=8.000e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=4.052e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=5.294e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.75it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.73it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.76it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.74it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.75it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.85it/s]
Training epochs:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 24/32 [08:43<02:54, 21.82s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s][A
Epoch 25/32:   0%|          | 0/13 [00:00<?, ?it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.84it/s]
Epoch 24/32 - Train Loss: 41.417589 - Test Loss: 37.341085
Training epochs:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 24/32 [08:43<02:54, 21.82s/it]
Epoch 25/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 25/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][AEpoch 25/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 25/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:17,  1.63s/it][A
Epoch 25/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:17,  1.63s/it][A
Epoch 25/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.60s/it][A
Epoch 25/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.60s/it][A

Epoch 25/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:14,  1.57s/it][AEpoch 25/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:14,  1.57s/it][A
Epoch 25/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.56s/it][A
Epoch 25/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.56s/it][A

Epoch 25/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.56s/it][AEpoch 25/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.56s/it][A
Epoch 25/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.56s/it][A
Epoch 25/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.56s/it][A

Epoch 25/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.55s/it][AEpoch 25/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.55s/it][A
Epoch 25/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:14<00:06,  1.55s/it][A
Epoch 25/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:14<00:06,  1.55s/it][A

Epoch 25/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it]Epoch 25/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A[A

Epoch 25/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:17<00:03,  1.54s/it][AEpoch 25/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:17<00:03,  1.54s/it][A
Epoch 25/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.55s/it][A
Epoch 25/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.55s/it][A

Epoch 25/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.43s/it][AEpoch 25/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.43s/it][AEpoch 25/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.52s/it]
Epoch 25/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.52s/it]

[Î²=3.5] Epoch 25 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.561e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.829e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.154e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.021e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.469e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.849e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.958e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.123e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.723e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.112e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.053e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.711e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.238e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.711e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.331e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.936e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.302e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=4.593e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.527e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.493e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.331e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.113e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.442e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.955e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=2.966e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=5.792e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.281e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=4.155e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=4.176e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=8.290e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.910e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=5.370e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.875e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=5.073e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.734e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.664e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.641e-01

  param model_5__forward_module.module.conv1.bias grad-norm: mean=4.185e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=3.267e-01Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  param model_5__forward_module.module.conv2.bias grad-norm: mean=4.571e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.463e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=5.631e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=5.333e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.460e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=4.598e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=8.600e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.882e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=5.349e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.77it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Training epochs:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 25/32 [09:05<02:33, 21.86s/it]
Epoch 26/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Epoch 25/32 - Train Loss: 41.419628 - Test Loss: 37.341072
Training epochs:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 25/32 [09:05<02:33, 21.87s/it]
Epoch 26/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 26/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][AEpoch 26/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.55s/it][A
Epoch 26/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 26/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A

Epoch 26/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][AEpoch 26/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 26/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 26/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 26/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 26/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 26/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 26/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 26/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 26/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 26/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 26/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 26/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 26/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 26/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 26/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 26/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 26/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A

Epoch 26/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][AEpoch 26/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 26/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][A
Epoch 26/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]
Epoch 26/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 26/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=3.5] Epoch 26 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.558e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.822e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.155e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.021e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.469e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.841e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.958e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.122e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.721e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.111e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.053e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.709e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.238e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.710e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.331e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.933e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.812e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=3.293e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.371e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.028e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.409e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.421e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.418e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.883e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.348e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=6.461e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.215e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=4.290e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.941e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=7.915e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.947e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=5.163e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.588e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=4.646e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.385e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.157e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.663e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=4.533e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=3.343e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=4.839e-02

  param model_6__forward_module.module.conv1.weight grad-norm: mean=4.329e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=7.752e-02Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  param model_6__forward_module.module.conv2.weight grad-norm: mean=5.723e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=6.047e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=4.062e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=7.357e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.721e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.747e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.77it/s][A

Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][AEvaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A

Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][AEvaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Epoch 26/32 - Train Loss: 41.403579 - Test Loss: 37.340890
Training epochs:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 26/32 [09:27<02:10, 21.83s/it]
Epoch 27/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 26/32 [09:27<02:10, 21.83s/it]
Epoch 27/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 27/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 27/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 27/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 27/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 27/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 27/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 27/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 27/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A

Epoch 27/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][AEpoch 27/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 27/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 27/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 27/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 27/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 27/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 27/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A

Epoch 27/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][AEpoch 27/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 27/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 27/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A

Epoch 27/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][AEpoch 27/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 27/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 27/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A

Epoch 27/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 27/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=3.5] Epoch 27 summary:Epoch 27/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it]
[A  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.560e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.824e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.155e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.021e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.469e+00
Epoch 27/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]  layer model_5__forward_module.module.conv2 act-std: mean=9.844e-01

  layer model_4__forward_module.module.conv1 act-std: mean=9.957e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.122e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.722e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.112e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.053e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.710e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.238e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.710e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.331e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.932e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.918e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=3.623e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.373e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.959e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.455e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.666e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.379e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.739e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=2.928e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=5.504e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.293e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=4.141e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=2.629e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=4.566e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.830e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.339e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=3.635e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=6.878e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=4.609e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=5.155e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.745e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=4.577e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=3.070e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=4.322e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=4.401e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=7.658e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=6.148e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=6.569e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=4.259e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=7.905e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.914e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=5.177e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.83it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.82it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.82it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.81it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Epoch 27/32 - Train Loss: 41.419456 - Test Loss: 37.340885
Training epochs:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 27/32 [09:48<01:48, 21.79s/it]
Epoch 28/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 27/32 [09:48<01:48, 21.79s/it]
Epoch 28/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 28/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.55s/it][A
Epoch 28/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A

Epoch 28/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][AEpoch 28/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 28/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 28/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A

Epoch 28/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][AEpoch 28/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 28/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 28/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 28/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 28/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A

Epoch 28/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][AEpoch 28/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A

Epoch 28/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][AEpoch 28/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A

Epoch 28/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][AEpoch 28/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A

Epoch 28/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][AEpoch 28/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A

Epoch 28/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][AEpoch 28/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 28/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 28/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 28/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 28/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=3.5] Epoch 28 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.559e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.825e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.155e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.022e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.468e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.841e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.959e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.123e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.722e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.111e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.053e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.709e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.238e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.711e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.331e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.934e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.123e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=4.138e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.339e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.887e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.409e-01

  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.518e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.286e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.792e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.740e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=7.373e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.278e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=4.493e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=4.289e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=8.702e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=3.050e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=5.449e-02Epoch 28/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it]
[A  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.283e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=3.753e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.423e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.177e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.507e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=4.024e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=3.079e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=4.113e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=4.114e-01
Epoch 28/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]  param model_6__forward_module.module.conv1.bias grad-norm: mean=6.928e-02

  param model_6__forward_module.module.conv2.weight grad-norm: mean=5.949e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=6.064e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.996e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=7.114e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.871e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=5.130e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A

Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][AEvaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.76it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Training epochs:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 28/32 [10:10<01:27, 21.78s/it]

Epoch 29/32:   0%|          | 0/13 [00:00<?, ?it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.85it/s]
Epoch 28/32 - Train Loss: 41.439179 - Test Loss: 37.340844
Training epochs:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 28/32 [10:10<01:27, 21.78s/it]
Epoch 29/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 29/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 29/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.55s/it][A

Epoch 29/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][AEpoch 29/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 29/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 29/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 29/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 29/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 29/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 29/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A

Epoch 29/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][AEpoch 29/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 29/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.59s/it][A
Epoch 29/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.59s/it][A
Epoch 29/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.57s/it][A
Epoch 29/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.57s/it][A
Epoch 29/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.56s/it][A
Epoch 29/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.56s/it][A
Epoch 29/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.55s/it][A
Epoch 29/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.55s/it][A
Epoch 29/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:17<00:03,  1.55s/it][A
Epoch 29/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:17<00:03,  1.55s/it][A

Epoch 29/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.55s/it][AEpoch 29/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.55s/it][A
Epoch 29/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.43s/it][AEpoch 29/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.52s/it]

[Î²=3.5] Epoch 29 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.559e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.824e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.155e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.020e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.469e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.842e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.959e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.122e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.721e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.110e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.053e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.709e-01

  layer model_1__forward_module.module.conv1 act-std: mean=1.237e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.710e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.331e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.933e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.130e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=4.038e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.347e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.956e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.447e-01Epoch 29/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.43s/it]
[A  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.645e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.351e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.930e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.077e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=5.804e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.239e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.795e-02
Epoch 29/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.52s/it]  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.799e-01

  param model_3__forward_module.module.conv1.bias grad-norm: mean=7.622e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.789e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.933e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.896e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=5.170e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.981e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=4.461e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.954e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=5.317e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=3.407e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=5.085e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=4.181e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=7.118e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=5.943e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=6.239e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=5.118e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.038e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.881e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=5.724e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.76it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.75it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Epoch 29/32 - Train Loss: 41.416673 - Test Loss: 37.340816
Training epochs:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 29/32 [10:32<01:05, 21.82s/it]
Epoch 30/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 29/32 [10:32<01:05, 21.82s/it]
Epoch 30/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 30/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][AEpoch 30/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 30/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 30/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 30/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 30/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 30/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 30/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 30/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 30/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 30/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 30/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A

Epoch 30/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][AEpoch 30/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 30/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 30/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A

Epoch 30/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][AEpoch 30/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A

Epoch 30/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][AEpoch 30/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 30/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 30/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 30/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 30/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 30/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 30/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=3.5] Epoch 30 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.559e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.823e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.155e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.021e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.469e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.844e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.958e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.123e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.721e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.111e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.053e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.710e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.237e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.711e+00

  layer model_0__forward_module.module.conv1 act-std: mean=1.331e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.933e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.932e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=3.601e-02
Epoch 30/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it]  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.388e-01[A
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.799e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.508e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.787e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.250e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.640e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=2.977e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=5.404e-02
Epoch 30/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.232e-01

  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.630e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=4.183e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=8.424e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.856e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=5.332e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.331e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=3.859e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.399e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.308e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.426e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=3.985e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.757e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=3.867e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=4.832e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=9.057e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=6.078e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=6.709e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=4.224e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=8.140e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.800e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=5.309e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A

Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][AEvaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.75it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.74it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.85it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.84it/s]
Epoch 30/32 - Train Loss: 41.373831 - Test Loss: 37.340715
Training epochs:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 30/32 [10:54<00:43, 21.80s/it]
Epoch 31/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 30/32 [10:54<00:43, 21.80s/it]
Epoch 31/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 31/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.55s/it][A
Epoch 31/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A

Epoch 31/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:17,  1.55s/it][AEpoch 31/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 31/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 31/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A

Epoch 31/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][AEpoch 31/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A

Epoch 31/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][AEpoch 31/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A

Epoch 31/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][AEpoch 31/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 31/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 31/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 31/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 31/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 31/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 31/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 31/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 31/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 31/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 31/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 31/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 31/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 31/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 31/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=3.5] Epoch 31 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.559e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.823e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.155e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.022e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.468e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.842e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.959e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.123e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.722e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.111e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.053e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.709e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.238e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.710e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.331e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.932e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.981e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=3.811e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.452e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.844e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.481e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.674e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.377e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.981e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.063e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=5.901e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.310e-01

  param model_2__forward_module.module.conv2.bias grad-norm: mean=4.159e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.190e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=5.910e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.785e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=3.871e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.640e-01Epoch 31/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it]
[A  param model_4__forward_module.module.conv1.bias grad-norm: mean=4.624e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.539e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.416e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.739e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=4.787e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=3.083e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=4.414e-02
Epoch 31/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]  param model_6__forward_module.module.conv1.weight grad-norm: mean=4.259e-01

  param model_6__forward_module.module.conv1.bias grad-norm: mean=7.566e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=5.835e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=6.029e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.927e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=7.363e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.662e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.650e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.77it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.76it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Epoch 31/32 - Train Loss: 41.381945 - Test Loss: 37.340654

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Training epochs:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 31/32 [11:15<00:21, 21.78s/it]
Epoch 32/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 31/32 [11:15<00:21, 21.79s/it]
Epoch 32/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 32/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 32/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.55s/it][A
Epoch 32/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 32/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 32/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 32/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 32/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 32/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A

Epoch 32/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][AEpoch 32/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A

Epoch 32/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][AEpoch 32/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A

Epoch 32/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][AEpoch 32/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 32/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 32/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 32/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 32/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A

Epoch 32/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][AEpoch 32/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 32/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 32/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 32/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 32/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 32/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 32/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

Epoch 32/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 32/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[Î²=3.5] Epoch 32 summary:[A
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.560e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.828e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.155e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.023e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.468e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.847e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.959e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.123e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.722e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.114e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.053e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.712e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.238e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.711e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.331e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.932e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.811e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=3.347e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.297e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.631e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.554e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.905e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.140e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.506e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.297e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=6.449e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.269e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=4.263e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.607e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=6.999e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.870e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.985e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.511e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=4.065e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.766e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.716e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.496e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=4.167e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.801e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=3.685e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=4.078e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=7.127e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=5.260e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.420e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.482e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=5.921e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.479e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.537e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.77it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.73it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.74it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.75it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Training epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [11:37<00:00, 21.78s/it]Training epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [11:37<00:00, 21.80s/it]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.84it/s]
Epoch 32/32 - Train Loss: 41.438127 - Test Loss: 37.340622
Training epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [11:37<00:00, 21.79s/it]Training epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [11:37<00:00, 21.80s/it]
Loaded best models from epoch 32 with loss 37.340622

>>> Completed beta = 3.5
>>> Time for this beta: 0:11:38
>>> Total elapsed time: 0:34:30
==================================================
Loaded data shape: torch.Size([4096, 2, 64, 64])
Training data shape: torch.Size([3276, 2, 64, 64])
Testing data shape: torch.Size([820, 2, 64, 64])

>>> Training the model at beta =  4.0

>>> Training the model at beta = 4.0

Training epochs:   0%|          | 0/32 [00:00<?, ?it/s]Training epochs:   0%|          | 0/32 [00:00<?, ?it/s]
Epoch 1/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 1/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 1/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 1/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 1/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 1/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 1/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 1/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 1/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 1/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A

Epoch 1/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][AEpoch 1/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 1/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 1/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 1/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 1/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A

Epoch 1/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it]Epoch 1/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A[A
Epoch 1/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 1/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 1/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 1/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A

Epoch 1/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][AEpoch 1/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A

Epoch 1/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][AEpoch 1/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 1/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 1/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

Epoch 1/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 1/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=4.0] Epoch 1 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.409e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.446e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.154e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.840e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.482e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.407e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.865e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.080e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.614e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.838e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.058e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.436e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.239e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.651e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.346e+00

  layer model_0__forward_module.module.conv2 act-std: mean=8.640e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.105e+00Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  param model_0__forward_module.module.conv1.bias grad-norm: mean=2.575e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=6.740e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=1.390e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=4.170e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=9.356e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=5.171e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=8.977e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=1.902e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=4.305e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=6.042e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=2.105e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=2.112e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=4.733e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=7.845e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=2.383e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.787e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=3.950e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=1.562e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=2.249e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.715e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=3.784e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=1.578e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=3.101e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=2.644e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=5.690e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=2.820e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=3.579e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=2.063e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=4.451e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.107e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=2.407e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.82it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.76it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]
Training epochs:   3%|â–Ž         | 1/32 [00:21<11:11, 21.67s/it]
Epoch 2/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Epoch 1/32 - Train Loss: 43.981898 - Test Loss: 39.798650
Training epochs:   3%|â–Ž         | 1/32 [00:21<11:12, 21.70s/it]
Epoch 2/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 2/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 2/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A

Epoch 2/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][AEpoch 2/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 2/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 2/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 2/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 2/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 2/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 2/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 2/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 2/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 2/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 2/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A

Epoch 2/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][AEpoch 2/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 2/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 2/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 2/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 2/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 2/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 2/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 2/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 2/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 2/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 2/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

Epoch 2/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 2/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=4.0] Epoch 2 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.410e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.457e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.154e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.845e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.482e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.431e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.867e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.083e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.619e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.855e-01

  layer model_2__forward_module.module.conv1 act-std: mean=1.059e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.454e-01Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  layer model_1__forward_module.module.conv1 act-std: mean=1.239e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.654e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.346e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.662e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.002e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=2.339e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=6.283e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=1.281e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=3.859e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=8.571e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=4.617e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=7.919e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=1.697e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=3.854e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=5.562e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.885e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.870e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=4.202e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=7.101e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=2.117e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.635e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=3.618e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=1.438e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=2.059e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.619e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=3.572e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=1.485e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=2.919e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=2.427e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=5.228e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=2.579e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=3.268e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.928e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=4.162e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.045e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=2.238e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.76it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.76it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.76it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Training epochs:   6%|â–‹         | 2/32 [00:43<10:51, 21.70s/it]
Epoch 3/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.85it/s]
Epoch 2/32 - Train Loss: 44.013428 - Test Loss: 39.791051
Training epochs:   6%|â–‹         | 2/32 [00:43<10:51, 21.72s/it]
Epoch 3/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 3/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 3/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.56s/it][A
Epoch 3/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 3/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A

Epoch 3/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][AEpoch 3/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A

Epoch 3/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][AEpoch 3/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 3/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 3/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 3/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 3/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A

Epoch 3/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][AEpoch 3/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 3/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 3/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A

Epoch 3/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][AEpoch 3/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A

Epoch 3/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][AEpoch 3/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A

Epoch 3/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][AEpoch 3/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 3/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 3/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A

Epoch 3/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 3/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 3/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=4.0] Epoch 3 summary:
Epoch 3/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.408e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.459e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.154e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.848e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.482e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.437e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.869e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.085e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.622e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.864e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.059e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.465e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.239e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.656e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.346e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.673e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=9.091e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=2.125e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=5.781e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=1.161e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=3.532e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=7.846e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=4.285e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=7.102e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=1.534e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=3.491e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=5.288e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.717e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.685e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=3.797e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=6.742e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.926e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.521e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=3.368e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=1.336e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.913e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.530e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=3.383e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=1.411e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=2.776e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=2.272e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=4.885e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=2.399e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=3.039e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.835e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=3.970e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=9.890e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=2.130e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.77it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.77it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A

Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][AEvaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Epoch 3/32 - Train Loss: 43.924262 - Test Loss: 39.787568

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Training epochs:   9%|â–‰         | 3/32 [01:05<10:29, 21.71s/it]
Epoch 4/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:   9%|â–‰         | 3/32 [01:05<10:29, 21.72s/it]
Epoch 4/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 4/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 4/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 4/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 4/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 4/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 4/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 4/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 4/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 4/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 4/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 4/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 4/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 4/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 4/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 4/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 4/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A

Epoch 4/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][AEpoch 4/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 4/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 4/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 4/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 4/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 4/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 4/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A

Epoch 4/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 4/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 4/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]
Epoch 4/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=4.0] Epoch 4 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.410e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.466e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.154e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.850e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.481e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.453e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.870e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.087e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.626e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.873e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.059e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.475e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.239e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.658e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.345e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.686e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=8.596e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=2.007e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=5.605e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=1.102e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=3.475e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=7.664e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=4.277e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=6.861e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=1.416e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=3.227e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=4.980e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.589e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.577e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=3.520e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=6.412e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.788e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.452e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=3.220e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=1.269e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.814e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.475e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=3.264e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=1.362e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=2.679e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=2.167e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=4.657e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=2.282e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=2.882e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.739e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=3.766e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=9.597e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=2.027e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Epoch 4/32 - Train Loss: 43.965493 - Test Loss: 39.784675
Training epochs:  12%|â–ˆâ–Ž        | 4/32 [01:26<10:07, 21.71s/it]
Epoch 5/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Training epochs:  12%|â–ˆâ–Ž        | 4/32 [01:26<10:08, 21.72s/it]
Epoch 5/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 5/32:   8%|â–Š         | 1/13 [00:01<00:20,  1.68s/it][A
Epoch 5/32:   8%|â–Š         | 1/13 [00:01<00:20,  1.70s/it][A
Epoch 5/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:17,  1.60s/it][A
Epoch 5/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:17,  1.61s/it][A
Epoch 5/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.57s/it][A
Epoch 5/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.57s/it][A

Epoch 5/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:14,  1.56s/it][AEpoch 5/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.56s/it][A
Epoch 5/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.55s/it][A
Epoch 5/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.55s/it][A

Epoch 5/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.55s/it][AEpoch 5/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.55s/it][A
Epoch 5/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 5/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 5/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 5/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 5/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 5/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 5/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 5/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A

Epoch 5/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:17<00:03,  1.54s/it][AEpoch 5/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:17<00:03,  1.53s/it][A
Epoch 5/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 5/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 5/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 5/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.52s/it]

[Î²=4.0] Epoch 5 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.411e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.469e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.154e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.851e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.481e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.458e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.872e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.087e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.627e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.879e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.059e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.481e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.239e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.660e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.345e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.697e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=8.158e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.906e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=5.424e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=1.065e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=3.360e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=7.423e-02

  param model_1__forward_module.module.conv2.weight grad-norm: mean=4.173e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=6.449e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=1.337e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=3.040e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=4.998e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.508e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.471e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=3.287e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=6.330e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.678e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.395e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=3.091e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=1.229e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.747e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.432e+00Epoch 5/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it]
[A  param model_5__forward_module.module.conv1.bias grad-norm: mean=3.170e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=1.315e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=2.584e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=2.078e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=4.480e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=2.187e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=2.769e-01
Epoch 5/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.52s/it]  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.696e+00

  param model_7__forward_module.module.conv1.bias grad-norm: mean=3.672e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=9.407e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.987e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.76it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.49it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.61it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Epoch 5/32 - Train Loss: 43.911723 - Test Loss: 39.782640
Training epochs:  16%|â–ˆâ–Œ        | 5/32 [01:48<09:48, 21.78s/it]
Epoch 6/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.80it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.72it/s]
Training epochs:  16%|â–ˆâ–Œ        | 5/32 [01:48<09:49, 21.84s/it]
Epoch 6/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 6/32:   8%|â–Š         | 1/13 [00:01<00:20,  1.68s/it][A
Epoch 6/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][A
Epoch 6/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:17,  1.59s/it][A
Epoch 6/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A

Epoch 6/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.56s/it][AEpoch 6/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 6/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 6/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.55s/it][A

Epoch 6/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][AEpoch 6/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 6/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 6/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A

Epoch 6/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][AEpoch 6/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 6/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 6/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 6/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 6/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 6/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 6/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A

Epoch 6/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:17<00:03,  1.54s/it][AEpoch 6/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 6/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 6/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A

Epoch 6/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 6/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 6/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.52s/it]
Epoch 6/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=4.0] Epoch 6 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.410e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.470e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.154e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.854e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.481e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.465e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.872e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.088e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.630e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.885e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.059e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.487e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.239e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.661e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.345e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.703e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=7.688e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.800e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=5.133e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=9.968e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=3.256e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=7.256e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=3.831e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=6.010e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=1.235e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=2.832e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=4.667e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.405e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.361e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=3.075e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=5.959e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.570e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.328e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=2.950e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=1.165e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.661e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.388e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=3.078e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=1.278e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=2.514e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.976e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=4.253e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=2.078e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=2.620e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.644e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=3.563e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=9.058e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.912e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.81it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Epoch 6/32 - Train Loss: 43.901577 - Test Loss: 39.780612
Training epochs:  19%|â–ˆâ–‰        | 6/32 [02:10<09:26, 21.78s/it]
Epoch 7/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  19%|â–ˆâ–‰        | 6/32 [02:10<09:26, 21.81s/it]
Epoch 7/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 7/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][AEpoch 7/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.55s/it][A
Epoch 7/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 7/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A

Epoch 7/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][AEpoch 7/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 7/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 7/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 7/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 7/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 7/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 7/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 7/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 7/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 7/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 7/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 7/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 7/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A

Epoch 7/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][AEpoch 7/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 7/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 7/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A

Epoch 7/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][AEpoch 7/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 7/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 7/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=4.0] Epoch 7 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.410e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.477e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.154e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.856e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.481e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.473e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.873e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.090e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.632e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.891e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.059e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.494e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.239e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.663e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.345e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.712e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=7.308e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.702e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=4.988e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=9.552e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=3.160e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=6.946e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=3.734e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=5.547e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=1.175e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=2.690e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=4.546e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.308e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.293e+00

  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.892e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=5.717e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.475e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.274e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=2.830e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=1.120e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.586e-01
Epoch 7/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it]  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.347e+00[A
  param model_5__forward_module.module.conv1.bias grad-norm: mean=2.983e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=1.247e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=2.447e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.893e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=4.071e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.972e+00
Epoch 7/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]  param model_6__forward_module.module.conv2.bias grad-norm: mean=2.493e-01

  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.571e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=3.398e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=8.778e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.818e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.83it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]
Training epochs:  22%|â–ˆâ–ˆâ–       | 7/32 [02:32<09:03, 21.75s/it]
Epoch 8/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Epoch 7/32 - Train Loss: 43.942501 - Test Loss: 39.778857
Training epochs:  22%|â–ˆâ–ˆâ–       | 7/32 [02:32<09:04, 21.76s/it]
Epoch 8/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 8/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.56s/it][AEpoch 8/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 8/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 8/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:17,  1.55s/it][A
Epoch 8/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 8/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 8/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 8/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 8/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 8/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 8/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 8/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A

Epoch 8/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][AEpoch 8/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A

Epoch 8/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][AEpoch 8/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A

Epoch 8/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it]Epoch 8/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A[A
Epoch 8/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 8/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A

Epoch 8/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][AEpoch 8/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 8/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 8/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 8/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 8/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

Epoch 8/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 8/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=4.0] Epoch 8 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.410e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.480e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.154e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.858e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.480e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.479e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.874e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.090e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.635e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.897e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.059e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.500e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.239e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.664e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.345e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.717e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=6.922e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.620e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=4.872e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=9.195e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=3.167e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=6.970e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=3.740e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=5.435e-02

  param model_2__forward_module.module.conv1.weight grad-norm: mean=1.114e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=2.546e-01Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  param model_2__forward_module.module.conv2.weight grad-norm: mean=4.448e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.280e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.193e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.700e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=5.506e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.363e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.227e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=2.726e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=1.087e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.535e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.312e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=2.902e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=1.216e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=2.378e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.822e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=3.914e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.898e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=2.389e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.512e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=3.285e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=8.578e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.785e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.74it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.73it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.75it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.75it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Training epochs:  25%|â–ˆâ–ˆâ–Œ       | 8/32 [02:54<08:42, 21.76s/it]
Epoch 9/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.85it/s]
Epoch 8/32 - Train Loss: 43.947153 - Test Loss: 39.777377
Training epochs:  25%|â–ˆâ–ˆâ–Œ       | 8/32 [02:54<08:42, 21.77s/it]
Epoch 9/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 9/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.55s/it][A
Epoch 9/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 9/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 9/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A

Epoch 9/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][AEpoch 9/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 9/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 9/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A

Epoch 9/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][AEpoch 9/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A

Epoch 9/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][AEpoch 9/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 9/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 9/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A

Epoch 9/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][AEpoch 9/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A

Epoch 9/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][AEpoch 9/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 9/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 9/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 9/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 9/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A

Epoch 9/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][AEpoch 9/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 9/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 9/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=4.0] Epoch 9 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.410e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.482e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.154e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.859e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.480e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.484e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.874e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.092e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.636e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.901e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.059e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.504e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.239e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.665e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.345e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.725e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=6.765e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.575e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=4.891e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=9.209e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=3.019e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=6.597e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=3.699e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=5.381e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=1.083e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=2.453e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=4.392e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.218e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.187e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.637e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=5.613e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.363e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.191e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=2.649e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=1.069e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.512e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.286e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=2.847e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=1.188e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=2.334e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.778e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=3.835e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.855e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=2.343e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.547e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=3.339e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=8.558e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.814e-01

Epoch 9/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 9/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A

Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.76it/s][AEvaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.75it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Epoch 9/32 - Train Loss: 43.918666 - Test Loss: 39.776887
Training epochs:  28%|â–ˆâ–ˆâ–Š       | 9/32 [03:15<08:20, 21.74s/it]
Epoch 10/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  28%|â–ˆâ–ˆâ–Š       | 9/32 [03:15<08:20, 21.75s/it]
Epoch 10/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 10/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][AEpoch 10/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 10/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 10/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 10/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 10/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 10/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 10/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 10/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 10/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A

Epoch 10/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][AEpoch 10/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 10/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 10/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 10/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 10/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 10/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 10/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 10/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 10/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A

Epoch 10/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][AEpoch 10/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 10/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 10/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 10/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.43s/it][AEpoch 10/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=4.0] Epoch 10 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.411e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.484e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.154e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.859e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.480e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.488e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.875e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.092e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.636e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.900e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.059e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.505e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.239e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.666e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.345e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.727e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=6.695e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.542e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=4.856e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=8.942e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=3.004e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=6.615e-02

  param model_1__forward_module.module.conv2.weight grad-norm: mean=3.567e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=5.223e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=1.025e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=2.364e-01
Epoch 10/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.43s/it]  param model_2__forward_module.module.conv2.weight grad-norm: mean=4.246e-01[A
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.195e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.115e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.522e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=5.391e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.320e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.170e+00
Epoch 10/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]  param model_4__forward_module.module.conv1.bias grad-norm: mean=2.596e-01

  param model_4__forward_module.module.conv2.weight grad-norm: mean=1.054e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.468e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.262e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=2.796e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=1.174e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=2.301e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.752e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=3.772e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.834e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=2.307e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.456e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=3.157e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=8.139e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.688e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A

Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][AEvaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.77it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.76it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.76it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Epoch 10/32 - Train Loss: 43.908911 - Test Loss: 39.776330
Training epochs:  31%|â–ˆâ–ˆâ–ˆâ–      | 10/32 [03:37<07:58, 21.76s/it]Training epochs:  31%|â–ˆâ–ˆâ–ˆâ–      | 10/32 [03:37<07:58, 21.76s/it]
Epoch 11/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 11/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 11/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 11/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.55s/it][A
Epoch 11/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 11/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 11/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 11/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 11/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 11/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 11/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 11/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A

Epoch 11/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][AEpoch 11/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A

Epoch 11/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][AEpoch 11/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A

Epoch 11/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][AEpoch 11/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A

Epoch 11/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][AEpoch 11/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 11/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 11/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 11/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 11/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A

Epoch 11/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][AEpoch 11/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 11/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 11/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

Epoch 11/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 11/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=4.0] Epoch 11 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.411e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.486e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.154e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.861e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.480e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.491e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.875e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.092e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.637e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.905e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.059e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.508e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.239e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.666e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.345e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.731e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=6.384e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.493e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=4.553e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=8.520e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=2.889e-01

  param model_1__forward_module.module.conv1.bias grad-norm: mean=6.280e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=3.379e-01Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  param model_1__forward_module.module.conv2.bias grad-norm: mean=4.748e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=9.995e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=2.297e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=4.179e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.147e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.124e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.499e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=5.381e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.301e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.145e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=2.547e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=1.023e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.431e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.257e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=2.789e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=1.168e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=2.294e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.709e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=3.674e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.780e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=2.245e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.432e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=3.112e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=8.035e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.662e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.77it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.76it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Training epochs:  34%|â–ˆâ–ˆâ–ˆâ–      | 11/32 [03:59<07:36, 21.75s/it]
Epoch 12/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Epoch 11/32 - Train Loss: 43.918083 - Test Loss: 39.775796
Training epochs:  34%|â–ˆâ–ˆâ–ˆâ–      | 11/32 [03:59<07:36, 21.76s/it]
Epoch 12/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 12/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.56s/it][AEpoch 12/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 12/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 12/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 12/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 12/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A

Epoch 12/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][AEpoch 12/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 12/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 12/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 12/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 12/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 12/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 12/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A

Epoch 12/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][AEpoch 12/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 12/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 12/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 12/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 12/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 12/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 12/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 12/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 12/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A

Epoch 12/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 12/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 12/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=4.0] Epoch 12 summary:
  input  std: mean=1.814e+00Epoch 12/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

  layer model_7__forward_module.module.conv1 act-std: mean=9.412e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.487e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.153e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.861e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.480e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.495e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.877e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.093e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.639e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.907e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.059e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.510e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.239e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.667e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.345e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.734e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=6.294e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.473e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=4.528e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=8.421e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=2.894e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=6.328e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=3.473e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=4.879e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=1.030e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=2.344e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=4.271e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.180e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.057e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.392e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=5.277e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.233e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.133e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=2.519e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=1.014e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.419e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.234e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=2.743e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=1.143e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=2.243e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.689e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=3.638e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.759e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=2.218e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.410e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=3.071e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=7.997e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.643e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Training epochs:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 12/32 [04:21<07:15, 21.75s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][A
Epoch 13/32:   0%|          | 0/13 [00:00<?, ?it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Epoch 12/32 - Train Loss: 43.961283 - Test Loss: 39.775284
Training epochs:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 12/32 [04:21<07:15, 21.76s/it]
Epoch 13/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 13/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][AEpoch 13/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 13/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 13/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 13/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 13/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 13/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 13/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A

Epoch 13/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][AEpoch 13/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A

Epoch 13/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:11,  1.59s/it][AEpoch 13/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:11,  1.59s/it][A
Epoch 13/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.58s/it][A
Epoch 13/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.58s/it][A

Epoch 13/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.57s/it][AEpoch 13/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.57s/it][A
Epoch 13/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.56s/it][A
Epoch 13/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:14<00:06,  1.56s/it][A
Epoch 13/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.55s/it][A
Epoch 13/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.55s/it][A
Epoch 13/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:17<00:03,  1.55s/it]
[AEpoch 13/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:17<00:03,  1.55s/it][A

Epoch 13/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][AEpoch 13/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 13/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.43s/it][AEpoch 13/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.52s/it]

[Î²=4.0] Epoch 13 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.411e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.487e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.153e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.861e-01

  layer model_5__forward_module.module.conv1 act-std: mean=1.480e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.496e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.876e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.093e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.638e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.907e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.059e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.510e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.667e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.345e+00
Epoch 13/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.43s/it]  layer model_0__forward_module.module.conv2 act-std: mean=8.734e-01[A
  param model_0__forward_module.module.conv1.weight grad-norm: mean=6.177e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.434e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=4.597e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=8.331e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=2.895e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=6.295e-02
Epoch 13/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.52s/it]  param model_1__forward_module.module.conv2.weight grad-norm: mean=3.445e-01

  param model_1__forward_module.module.conv2.bias grad-norm: mean=4.787e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=9.564e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=2.197e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=4.208e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.122e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.065e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.394e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=5.087e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.235e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.106e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=2.449e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=1.024e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.402e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.219e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=2.703e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=1.129e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=2.211e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.665e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=3.549e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.755e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=2.166e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.402e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=3.051e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=8.018e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.631e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][A

Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][AEvaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A

Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][AEvaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Epoch 13/32 - Train Loss: 43.846730 - Test Loss: 39.774654
Training epochs:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 13/32 [04:42<06:54, 21.80s/it]Training epochs:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 13/32 [04:42<06:54, 21.80s/it]
Epoch 14/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 14/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 14/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 14/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 14/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 14/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 14/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 14/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 14/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 14/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 14/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 14/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 14/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 14/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 14/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 14/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 14/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 14/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 14/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 14/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 14/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 14/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 14/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 14/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 14/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it]
[AEpoch 14/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 14/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it]
[AEpoch 14/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]
Epoch 14/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 14/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=4.0] Epoch 14 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.411e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.489e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.153e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.862e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.480e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.500e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.876e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.093e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.640e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.911e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.059e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.515e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.668e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.345e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.738e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=6.124e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.424e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=4.624e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=8.239e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=2.781e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=5.961e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=3.606e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=5.020e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=9.256e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=2.134e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=4.081e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.064e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.043e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.347e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=5.208e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.240e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.095e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=2.431e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=9.887e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.376e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.211e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=2.687e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=1.116e+00

  param model_5__forward_module.module.conv2.bias grad-norm: mean=2.187e-01
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.647e+00[A
  param model_6__forward_module.module.conv1.bias grad-norm: mean=3.535e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.716e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=2.151e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.397e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=3.036e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=7.938e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.636e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.76it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.75it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.76it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.75it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.75it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.74it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.85it/s]
Training epochs:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 14/32 [05:04<06:32, 21.78s/it]
Epoch 15/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.84it/s]
Epoch 14/32 - Train Loss: 43.853432 - Test Loss: 39.774187
Training epochs:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 14/32 [05:04<06:32, 21.79s/it]
Epoch 15/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 15/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][AEpoch 15/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.55s/it][A

Epoch 15/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][AEpoch 15/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 15/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 15/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 15/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 15/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 15/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 15/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 15/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 15/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 15/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 15/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A

Epoch 15/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][AEpoch 15/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 15/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 15/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 15/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 15/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A

Epoch 15/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][AEpoch 15/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A

Epoch 15/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][AEpoch 15/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 15/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 15/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=4.0] Epoch 15 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.411e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.489e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.153e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.864e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.480e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.500e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.877e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.093e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.640e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.911e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.059e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.516e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.239e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.668e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.345e+00

  layer model_0__forward_module.module.conv2 act-std: mean=8.738e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=5.892e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.380e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=4.363e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=7.940e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=2.790e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=6.001e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=3.427e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=5.049e-02
Epoch 15/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it]  param model_2__forward_module.module.conv1.weight grad-norm: mean=9.021e-01[A
  param model_2__forward_module.module.conv1.bias grad-norm: mean=2.071e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=3.983e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.035e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.045e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.279e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=5.163e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.200e-01
Epoch 15/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.071e+00

  param model_4__forward_module.module.conv1.bias grad-norm: mean=2.383e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=9.551e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.336e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.201e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=2.665e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=1.116e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=2.188e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.617e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=3.466e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.675e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=2.093e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.365e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.969e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=7.810e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.594e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[AEvaluating:   0%|          | 0/4 [00:00<?, ?it/s][A

Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][AEvaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A

Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][AEvaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Epoch 15/32 - Train Loss: 43.908830 - Test Loss: 39.774062
Training epochs:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 15/32 [05:26<06:09, 21.75s/it]
Epoch 16/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 15/32 [05:26<06:09, 21.75s/it]
Epoch 16/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 16/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 16/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A

Epoch 16/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][AEpoch 16/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 16/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 16/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 16/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 16/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 16/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 16/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A

Epoch 16/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][AEpoch 16/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A

Epoch 16/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][AEpoch 16/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A

Epoch 16/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][AEpoch 16/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A

Epoch 16/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][AEpoch 16/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 16/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 16/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A

Epoch 16/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][AEpoch 16/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 16/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it]
[AEpoch 16/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A

Epoch 16/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 16/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 16/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]
Epoch 16/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=4.0] Epoch 16 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.411e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.491e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.153e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.862e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.480e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.502e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.876e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.093e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.640e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.912e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.059e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.518e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.239e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.669e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.345e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.742e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=5.796e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.358e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=4.325e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=7.781e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=2.895e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=6.336e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=3.579e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=4.942e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=9.258e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=2.112e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=4.134e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.059e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.015e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.266e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=5.148e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.206e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.068e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=2.364e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=9.683e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.341e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.189e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=2.635e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=1.099e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=2.153e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.601e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=3.444e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.690e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=2.127e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.376e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.982e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=8.027e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.592e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.74it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.72it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.76it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Epoch 16/32 - Train Loss: 43.885288 - Test Loss: 39.773826
Training epochs:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 16/32 [05:48<05:47, 21.74s/it]
Epoch 17/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 16/32 [05:48<05:47, 21.74s/it]
Epoch 17/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 17/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 17/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 17/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 17/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A

Epoch 17/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][AEpoch 17/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 17/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 17/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A

Epoch 17/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][AEpoch 17/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 17/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 17/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A

Epoch 17/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][AEpoch 17/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 17/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 17/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 17/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 17/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 17/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 17/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 17/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 17/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A

Epoch 17/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][AEpoch 17/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 17/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 17/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

Epoch 17/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 17/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=4.0] Epoch 17 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.411e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.491e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.153e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.863e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.480e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.503e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.876e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.094e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.640e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.912e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.059e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.517e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.239e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.669e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.345e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.742e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=5.900e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.373e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=4.506e-01

  param model_0__forward_module.module.conv2.bias grad-norm: mean=7.904e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=2.750e-01Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  param model_1__forward_module.module.conv1.bias grad-norm: mean=5.939e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=3.389e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=4.831e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=9.132e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=2.073e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=4.002e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.047e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=9.999e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.232e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=4.936e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.184e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.059e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=2.357e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=9.670e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.350e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.181e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=2.618e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=1.096e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=2.141e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.581e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=3.394e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.661e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=2.076e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.358e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.938e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=7.811e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.577e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A

Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.82it/s][AEvaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A

Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.76it/s][AEvaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Epoch 17/32 - Train Loss: 43.911592 - Test Loss: 39.773657
Training epochs:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 17/32 [06:09<05:26, 21.73s/it]
Epoch 18/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 17/32 [06:09<05:26, 21.73s/it]
Epoch 18/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 18/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 18/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.55s/it][A
Epoch 18/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 18/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A

Epoch 18/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][AEpoch 18/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 18/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 18/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 18/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 18/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 18/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 18/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 18/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 18/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 18/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 18/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A

Epoch 18/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][AEpoch 18/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A

Epoch 18/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][AEpoch 18/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 18/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 18/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A

Epoch 18/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][AEpoch 18/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A

Epoch 18/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 18/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 18/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]
Epoch 18/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=4.0] Epoch 18 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.413e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.492e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.153e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.863e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.480e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.506e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.878e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.094e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.642e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.914e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.059e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.519e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.669e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.345e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.744e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=5.734e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.341e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=4.350e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=7.894e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=2.674e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=5.799e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=3.297e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=4.303e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=8.958e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=2.052e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=4.034e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.068e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=9.424e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.111e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=5.054e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.109e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.062e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=2.365e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=9.568e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.334e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.170e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=2.590e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=1.087e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=2.125e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.589e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=3.416e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.657e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=2.084e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.360e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.951e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=7.835e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.568e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A

Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][AEvaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A

Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][AEvaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Epoch 18/32 - Train Loss: 43.926486 - Test Loss: 39.773406
Training epochs:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 18/32 [06:31<05:04, 21.74s/it]
Epoch 19/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 18/32 [06:31<05:04, 21.74s/it]
Epoch 19/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 19/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 19/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 19/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 19/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 19/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 19/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A

Epoch 19/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][AEpoch 19/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 19/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 19/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A

Epoch 19/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][AEpoch 19/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 19/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 19/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 19/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 19/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 19/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 19/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 19/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 19/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 19/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 19/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 19/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 19/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A

Epoch 19/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 19/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 19/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]
Epoch 19/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=4.0] Epoch 19 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.410e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.490e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.153e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.864e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.480e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.502e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.878e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.094e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.641e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.916e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.059e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.521e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.239e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.669e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.345e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.742e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=5.615e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.305e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=4.293e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=7.663e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=2.815e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=6.071e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=3.427e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=4.816e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=8.802e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=2.008e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=4.055e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.032e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.001e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.205e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=5.006e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.180e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.041e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=2.312e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=9.341e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.305e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.170e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=2.593e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=1.091e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=2.137e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.565e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=3.345e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.643e+00

  param model_6__forward_module.module.conv2.bias grad-norm: mean=2.053e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.367e+00Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.967e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=7.822e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.578e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.76it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.75it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Epoch 19/32 - Train Loss: 43.903014 - Test Loss: 39.773230
Training epochs:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 19/32 [06:53<04:42, 21.72s/it]
Epoch 20/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.71it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.73it/s]
Training epochs:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 19/32 [06:53<04:43, 21.77s/it]
Epoch 20/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 20/32:   8%|â–Š         | 1/13 [00:01<00:19,  1.66s/it][A
Epoch 20/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][A
Epoch 20/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:17,  1.59s/it][A
Epoch 20/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 20/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 20/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.57s/it][A

Epoch 20/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][AEpoch 20/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.55s/it][A
Epoch 20/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 20/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.55s/it][A
Epoch 20/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.55s/it][A
Epoch 20/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 20/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 20/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.55s/it][A

Epoch 20/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][AEpoch 20/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 20/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 20/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A

Epoch 20/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][AEpoch 20/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 20/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:17<00:03,  1.54s/it][A
Epoch 20/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 20/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 20/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A

Epoch 20/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 20/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 20/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]
Epoch 20/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.52s/it]

[Î²=4.0] Epoch 20 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.411e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.493e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.153e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.865e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.480e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.508e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.876e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.095e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.642e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.917e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.059e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.522e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.239e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.670e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.345e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.746e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=5.715e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.328e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=4.338e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=7.997e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=2.734e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=5.928e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=3.363e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=4.603e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=9.188e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=2.083e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=4.082e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.077e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.094e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.421e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=5.156e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.251e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.032e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=2.294e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=9.282e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.286e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.163e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=2.584e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=1.088e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=2.126e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.553e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=3.325e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.607e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=2.034e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.359e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.948e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=7.842e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.567e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.76it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.76it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.76it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.76it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Training epochs:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 20/32 [07:15<04:21, 21.76s/it]
Epoch 21/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.85it/s]
Epoch 20/32 - Train Loss: 43.913882 - Test Loss: 39.772969
Training epochs:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 20/32 [07:15<04:21, 21.78s/it]
Epoch 21/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 21/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 21/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.55s/it][A
Epoch 21/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 21/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A

Epoch 21/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][AEpoch 21/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 21/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 21/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A

Epoch 21/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][AEpoch 21/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A

Epoch 21/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][AEpoch 21/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 21/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 21/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 21/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.60s/it][A
Epoch 21/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.60s/it][A
Epoch 21/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:14<00:06,  1.58s/it][A
Epoch 21/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:14<00:06,  1.58s/it][A

Epoch 21/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.56s/it][AEpoch 21/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.56s/it][A
Epoch 21/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:17<00:03,  1.56s/it][A
Epoch 21/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:17<00:03,  1.56s/it][A

Epoch 21/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.56s/it][AEpoch 21/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.56s/it][A

Epoch 21/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.43s/it][AEpoch 21/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.43s/it][AEpoch 21/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.52s/it]

[Î²=4.0] Epoch 21 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.412e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.494e-01
Epoch 21/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.52s/it]  layer model_6__forward_module.module.conv1 act-std: mean=1.153e+00

  layer model_6__forward_module.module.conv2 act-std: mean=2.864e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.480e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.508e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.877e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.095e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.641e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.915e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.059e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.521e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.239e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.669e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.345e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.743e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=5.520e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.293e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=4.306e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=7.786e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=2.817e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=6.061e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=3.588e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=5.108e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=8.502e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.962e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=3.983e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=9.880e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=9.009e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.035e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=4.917e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.061e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.033e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=2.305e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=9.310e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.297e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.170e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=2.587e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=1.078e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=2.107e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.536e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=3.307e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.597e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=2.001e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.349e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.907e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=7.804e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.561e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.74it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.72it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.76it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.74it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.76it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Training epochs:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 21/32 [07:37<04:00, 21.83s/it]
Epoch 22/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.84it/s]
Epoch 21/32 - Train Loss: 43.838734 - Test Loss: 39.772886
Training epochs:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 21/32 [07:37<04:00, 21.84s/it]
Epoch 22/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 22/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.57s/it][A
Epoch 22/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 22/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:17,  1.55s/it][A
Epoch 22/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A

Epoch 22/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][AEpoch 22/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A

Epoch 22/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][AEpoch 22/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A

Epoch 22/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][AEpoch 22/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 22/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 22/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 22/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 22/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 22/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 22/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 22/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 22/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 22/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 22/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 22/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 22/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 22/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 22/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A

Epoch 22/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 22/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 22/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]
Epoch 22/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=4.0] Epoch 22 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.410e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.493e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.153e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.864e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.480e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.507e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.877e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.095e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.642e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.917e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.059e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.521e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.239e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.670e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.344e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.749e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=5.639e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.315e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=4.414e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=7.775e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=2.701e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=5.839e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=3.409e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=4.461e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=8.512e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.956e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=3.903e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=9.642e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=9.106e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.050e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=4.895e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.095e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.023e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=2.260e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=9.305e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.274e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.157e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=2.565e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=1.077e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=2.106e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.543e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=3.300e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.609e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=2.014e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.315e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.864e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=7.558e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.529e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.77it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.77it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.76it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.75it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.75it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.85it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.85it/s]
Epoch 22/32 - Train Loss: 43.870558 - Test Loss: 39.772785
Training epochs:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 22/32 [07:58<03:38, 21.83s/it]
Epoch 23/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 22/32 [07:58<03:38, 21.84s/it]
Epoch 23/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 23/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 23/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.55s/it][A
Epoch 23/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 23/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A

Epoch 23/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][AEpoch 23/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A

Epoch 23/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][AEpoch 23/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A

Epoch 23/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][AEpoch 23/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A

Epoch 23/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][AEpoch 23/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A

Epoch 23/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][AEpoch 23/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 23/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 23/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A

Epoch 23/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.55s/it][AEpoch 23/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.55s/it][A
Epoch 23/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 23/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A

Epoch 23/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][AEpoch 23/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A

Epoch 23/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][AEpoch 23/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A

Epoch 23/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 23/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 23/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=4.0] Epoch 23 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.411e-01Epoch 23/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

  layer model_7__forward_module.module.conv2 act-std: mean=7.493e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.153e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.865e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.480e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.510e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.877e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.094e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.642e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.917e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.059e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.522e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.239e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.670e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.345e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.745e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=5.447e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.277e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=4.175e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=7.424e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=2.702e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=5.841e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=3.352e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=4.563e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=8.508e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.957e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=3.930e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=9.772e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=9.906e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.180e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=5.083e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.170e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.016e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=2.263e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=9.279e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.284e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.151e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=2.558e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=1.068e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=2.096e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.520e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=3.282e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.599e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=2.005e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.330e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.899e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=7.819e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.588e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A

Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.77it/s][AEvaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.76it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.74it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.76it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Training epochs:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 23/32 [08:20<03:16, 21.82s/it]
Epoch 24/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.85it/s]
Epoch 23/32 - Train Loss: 43.905307 - Test Loss: 39.772695
Training epochs:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 23/32 [08:20<03:16, 21.83s/it]
Epoch 24/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 24/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.55s/it][AEpoch 24/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 24/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 24/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 24/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 24/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A

Epoch 24/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][AEpoch 24/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 24/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 24/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 24/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 24/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 24/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 24/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 24/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 24/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 24/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 24/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 24/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 24/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 24/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 24/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 24/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 24/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 24/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 24/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

Epoch 24/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 24/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]


[Î²=4.0] Epoch 24 summary:
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  input  std: mean=1.814e+00[A
  layer model_7__forward_module.module.conv1 act-std: mean=9.411e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.492e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.153e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.865e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.480e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.508e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.877e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.094e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.643e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.917e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.059e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.522e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.239e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.670e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.345e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.746e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=5.541e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.285e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=4.267e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=7.493e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=2.843e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=6.159e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=3.427e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=4.485e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=8.394e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.932e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=3.921e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=9.644e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=9.162e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.039e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=4.974e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.114e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.018e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=2.263e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=9.130e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.266e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.149e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=2.555e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=1.066e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=2.086e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.525e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=3.284e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.596e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=2.008e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.327e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.883e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=7.474e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.506e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.77it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.76it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Epoch 24/32 - Train Loss: 43.846456 - Test Loss: 39.772602
Training epochs:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 24/32 [08:42<02:54, 21.80s/it]
Epoch 25/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 24/32 [08:42<02:54, 21.80s/it]
Epoch 25/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 25/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 25/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 25/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 25/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 25/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 25/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 25/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 25/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 25/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 25/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A

Epoch 25/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][AEpoch 25/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 25/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 25/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A

Epoch 25/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][AEpoch 25/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A

Epoch 25/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][AEpoch 25/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A

Epoch 25/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][AEpoch 25/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A

Epoch 25/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][AEpoch 25/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 25/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 25/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 25/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 25/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=4.0] Epoch 25 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.412e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.495e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.153e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.865e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.480e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.512e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.877e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.095e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.643e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.919e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.059e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.524e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.239e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.670e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.345e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.748e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=5.518e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.285e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=4.165e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=7.453e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=2.636e-01

  param model_1__forward_module.module.conv1.bias grad-norm: mean=5.715e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=3.188e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=4.265e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=8.628e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.968e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=3.953e-01
Epoch 25/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it]  param model_2__forward_module.module.conv2.bias grad-norm: mean=9.882e-02[A
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.047e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.320e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=4.948e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.202e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.014e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=2.257e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=9.188e-01
Epoch 25/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.280e-01

  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.152e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=2.559e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=1.067e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=2.095e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.516e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=3.258e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.581e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.982e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.314e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.859e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=7.609e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.528e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A

Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.76it/s][AEvaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.76it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.76it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.75it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]

Training epochs:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 25/32 [09:04<02:32, 21.79s/it]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.85it/s]
Epoch 25/32 - Train Loss: 43.860095 - Test Loss: 39.772480

Epoch 26/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 25/32 [09:04<02:32, 21.79s/it]
Epoch 26/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 26/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][AEpoch 26/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.55s/it][A
Epoch 26/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 26/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 26/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 26/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 26/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 26/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A

Epoch 26/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][AEpoch 26/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 26/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 26/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 26/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 26/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 26/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 26/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A

Epoch 26/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][AEpoch 26/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A

Epoch 26/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][AEpoch 26/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 26/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 26/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 26/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 26/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 26/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 26/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=4.0] Epoch 26 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.412e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.495e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.153e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.866e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.480e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.512e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.879e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.095e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.642e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.916e-01

  layer model_2__forward_module.module.conv1 act-std: mean=1.059e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.522e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.239e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.670e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.345e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.748e-01
Epoch 26/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it]  param model_0__forward_module.module.conv1.weight grad-norm: mean=5.584e-01[A
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.298e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=4.270e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=7.644e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=2.678e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=5.845e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=3.399e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=4.669e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=8.087e-01
Epoch 26/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.866e-01

  param model_2__forward_module.module.conv2.weight grad-norm: mean=3.833e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=9.481e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=9.146e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.027e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=4.897e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.072e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.010e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=2.242e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=9.192e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.262e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.150e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=2.553e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=1.067e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=2.090e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.528e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=3.262e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.587e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.981e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.312e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.845e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=7.715e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.534e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A

Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][AEvaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Epoch 26/32 - Train Loss: 43.881714 - Test Loss: 39.772410
Training epochs:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 26/32 [09:25<02:10, 21.77s/it]
Epoch 27/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 26/32 [09:26<02:10, 21.77s/it]
Epoch 27/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 27/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 27/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.55s/it][A
Epoch 27/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 27/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 27/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 27/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A

Epoch 27/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][AEpoch 27/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 27/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 27/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A

Epoch 27/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][AEpoch 27/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A

Epoch 27/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][AEpoch 27/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A

Epoch 27/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][AEpoch 27/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 27/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 27/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A

Epoch 27/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][AEpoch 27/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 27/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 27/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 27/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 27/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A

Epoch 27/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 27/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 27/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]
Epoch 27/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=4.0] Epoch 27 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.412e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.494e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.153e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.865e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.480e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.511e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.876e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.096e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.642e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.917e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.059e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.523e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.239e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.670e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.345e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.750e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=5.458e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.273e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=4.303e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=7.558e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=2.611e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=5.582e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=3.268e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=4.171e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=8.328e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.905e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=3.949e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=9.677e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=8.717e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.964e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=4.908e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.056e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.003e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=2.231e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=9.230e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.272e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.145e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=2.545e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=1.067e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=2.092e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.506e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=3.234e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.554e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.944e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.314e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.868e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=7.437e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.529e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.77it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Training epochs:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 27/32 [09:47<01:48, 21.74s/it]
Epoch 28/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Epoch 27/32 - Train Loss: 43.923885 - Test Loss: 39.772368
Training epochs:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 27/32 [09:47<01:48, 21.74s/it]
Epoch 28/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 28/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 28/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.55s/it][A

Epoch 28/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][AEpoch 28/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A

Epoch 28/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][AEpoch 28/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 28/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 28/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 28/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 28/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 28/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 28/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 28/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 28/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 28/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it]
[AEpoch 28/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A

Epoch 28/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it]Epoch 28/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A[A

Epoch 28/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][AEpoch 28/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 28/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 28/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A

Epoch 28/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][AEpoch 28/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 28/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 28/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

Epoch 28/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 28/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=4.0] Epoch 28 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.412e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.494e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.153e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.865e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.480e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.511e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.876e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.096e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.642e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.919e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.059e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.524e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.239e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.670e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.344e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.748e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=5.814e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.346e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=4.459e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=7.687e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=2.673e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=5.665e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=3.556e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=4.621e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=8.137e-01

  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.884e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=3.784e-01Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  param model_2__forward_module.module.conv2.bias grad-norm: mean=9.313e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=9.439e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.078e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=4.909e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.114e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.001e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=2.225e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=9.207e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.269e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.141e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=2.532e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=1.062e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=2.074e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.503e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=3.222e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.572e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.965e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.327e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.893e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=7.843e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.557e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Training epochs:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 28/32 [10:09<01:26, 21.74s/it]

Epoch 29/32:   0%|          | 0/13 [00:00<?, ?it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][A[AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Epoch 28/32 - Train Loss: 43.947437 - Test Loss: 39.772330
Training epochs:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 28/32 [10:09<01:26, 21.74s/it]
Epoch 29/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 29/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 29/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.55s/it][A
Epoch 29/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 29/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 29/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 29/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 29/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 29/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A

Epoch 29/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it]Epoch 29/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A[A
Epoch 29/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 29/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A

Epoch 29/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.59s/it][AEpoch 29/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.59s/it][A
Epoch 29/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.57s/it][A
Epoch 29/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.57s/it][A
Epoch 29/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.56s/it][A
Epoch 29/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.56s/it][A

Epoch 29/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.55s/it][AEpoch 29/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.55s/it][A

Epoch 29/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:17<00:03,  1.54s/it][AEpoch 29/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:17<00:03,  1.54s/it][A
Epoch 29/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 29/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 29/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 29/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.52s/it]

Epoch 29/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 29/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.52s/it]

[Î²=4.0] Epoch 29 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.412e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.494e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.153e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.866e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.480e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.511e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.878e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.096e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.643e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.919e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.059e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.524e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.671e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.345e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.751e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=5.606e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.292e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=4.200e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=7.585e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=2.796e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=5.992e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=3.514e-01

  param model_1__forward_module.module.conv2.bias grad-norm: mean=4.740e-02
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  param model_2__forward_module.module.conv1.weight grad-norm: mean=8.136e-01[A
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.885e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=3.878e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=9.426e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=9.333e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.070e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=4.915e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.070e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.005e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=2.237e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=9.218e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.271e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.133e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=2.520e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=1.065e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=2.083e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.501e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=3.219e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.579e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.980e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.312e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.848e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=7.564e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.527e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Epoch 29/32 - Train Loss: 43.936880 - Test Loss: 39.772254
Training epochs:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 29/32 [10:31<01:05, 21.78s/it]
Epoch 30/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 29/32 [10:31<01:05, 21.78s/it]
Epoch 30/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 30/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][AEpoch 30/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 30/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 30/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 30/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 30/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 30/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 30/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 30/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 30/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 30/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 30/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A

Epoch 30/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][AEpoch 30/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 30/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 30/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A

Epoch 30/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][AEpoch 30/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 30/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 30/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 30/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 30/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 30/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 30/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 30/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 30/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=4.0] Epoch 30 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.411e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.494e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.153e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.866e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.480e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.511e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.877e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.095e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.642e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.919e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.059e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.525e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.670e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.345e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.750e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=5.379e-01

  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.257e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=4.209e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=7.519e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=2.725e-01
Epoch 30/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it]  param model_1__forward_module.module.conv1.bias grad-norm: mean=5.907e-02[A
  param model_1__forward_module.module.conv2.weight grad-norm: mean=3.431e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=4.736e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=8.250e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.884e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=3.841e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=9.586e-02
Epoch 30/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]  param model_3__forward_module.module.conv1.weight grad-norm: mean=9.034e-01

  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.024e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=4.803e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.079e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=1.003e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=2.236e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=9.148e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.266e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.143e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=2.536e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=1.066e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=2.084e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.513e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=3.253e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.565e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.967e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.306e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.842e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=7.570e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.516e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.77it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.76it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Training epochs:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 30/32 [10:53<00:43, 21.77s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.85it/s]
Epoch 30/32 - Train Loss: 43.875517 - Test Loss: 39.772211

Epoch 31/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 30/32 [10:53<00:43, 21.77s/it]
Epoch 31/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 31/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 31/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A

Epoch 31/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][AEpoch 31/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 31/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 31/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 31/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 31/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A

Epoch 31/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][AEpoch 31/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 31/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 31/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 31/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 31/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 31/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 31/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 31/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 31/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 31/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 31/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A

Epoch 31/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][AEpoch 31/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 31/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 31/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 31/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][A
Epoch 31/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]
Epoch 31/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][A
[Î²=4.0] Epoch 31 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.410e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.494e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.153e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.865e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.480e+00
Epoch 31/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]  layer model_5__forward_module.module.conv2 act-std: mean=9.510e-01

  layer model_4__forward_module.module.conv1 act-std: mean=9.878e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.095e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.642e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.919e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.059e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.525e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.239e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.671e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.345e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.749e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=5.313e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.247e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=4.231e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=7.610e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=2.727e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=5.921e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=3.272e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=4.369e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=8.322e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.905e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=3.853e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=9.522e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=9.192e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.056e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=4.833e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.068e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=9.988e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=2.214e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=9.069e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.243e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.137e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=2.525e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=1.054e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=2.063e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.491e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=3.184e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.552e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.924e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.302e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.832e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=7.584e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.524e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.75it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.85it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.85it/s]
Epoch 31/32 - Train Loss: 43.930265 - Test Loss: 39.772182
Training epochs:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 31/32 [11:14<00:21, 21.77s/it]
Epoch 32/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 31/32 [11:14<00:21, 21.77s/it]
Epoch 32/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 32/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it]Epoch 32/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A[A
Epoch 32/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 32/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 32/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 32/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 32/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 32/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 32/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 32/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 32/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 32/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 32/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 32/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A

Epoch 32/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][AEpoch 32/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A

Epoch 32/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][AEpoch 32/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A

Epoch 32/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][AEpoch 32/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 32/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 32/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 32/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 32/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 32/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 32/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=4.0] Epoch 32 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.411e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.495e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.153e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.866e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.480e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.513e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.878e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.095e+00

  layer model_3__forward_module.module.conv1 act-std: mean=6.643e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.920e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.059e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.525e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.239e+00
Epoch 32/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it]  layer model_1__forward_module.module.conv2 act-std: mean=1.671e+00[A
  layer model_0__forward_module.module.conv1 act-std: mean=1.345e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.749e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=5.420e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.262e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=4.201e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=7.574e-02Epoch 32/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

  param model_1__forward_module.module.conv1.weight grad-norm: mean=2.647e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=5.738e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=3.170e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=4.144e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=8.186e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.862e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=3.866e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=9.323e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=8.728e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.945e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=4.741e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.039e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=9.989e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=2.217e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=9.189e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.267e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=1.129e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=2.508e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=1.052e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=2.060e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.495e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=3.217e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.570e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.962e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.291e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.804e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=7.437e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.508e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.74it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.73it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.76it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.76it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.85it/s]
Training epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [11:36<00:00, 21.77s/it]Training epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [11:36<00:00, 21.77s/it]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.83it/s]
Epoch 32/32 - Train Loss: 43.920749 - Test Loss: 39.772163
Training epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [11:36<00:00, 21.77s/it]Training epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [11:36<00:00, 21.77s/it]
Loaded best models from epoch 32 with loss 39.772163

>>> Completed beta = 4.0
>>> Time for this beta: 0:11:36
>>> Total elapsed time: 0:46:07
==================================================
Loaded data shape: torch.Size([4096, 2, 64, 64])
Training data shape: torch.Size([3276, 2, 64, 64])
Testing data shape: torch.Size([820, 2, 64, 64])

>>> Training the model at beta =  4.5
Training epochs:   0%|          | 0/32 [00:00<?, ?it/s]
>>> Training the model at beta = 4.5

Training epochs:   0%|          | 0/32 [00:00<?, ?it/s]
Epoch 1/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 1/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 1/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 1/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 1/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 1/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 1/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 1/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A

Epoch 1/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][AEpoch 1/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 1/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 1/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A

Epoch 1/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][AEpoch 1/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 1/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 1/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 1/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 1/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 1/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 1/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A

Epoch 1/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][AEpoch 1/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 1/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.58s/it][A
Epoch 1/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.58s/it][A
Epoch 1/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.57s/it][A
Epoch 1/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.57s/it][A

Epoch 1/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.44s/it][AEpoch 1/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.44s/it][AEpoch 1/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]
Epoch 1/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=4.5] Epoch 1 summary:
  input  std: mean=1.813e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.274e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.213e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.152e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.743e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.490e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.161e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.788e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.061e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.541e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.698e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.063e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.306e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.619e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.356e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.490e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.752e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=4.075e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.037e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.178e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=6.227e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.393e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=8.535e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=1.522e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.236e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=7.259e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=9.374e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.590e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.918e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=8.666e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.280e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.298e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.659e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=5.842e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.339e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.361e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.980e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=6.554e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.693e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=5.332e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=4.043e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=8.692e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.241e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.428e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.941e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=8.402e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.938e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.451e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.77it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]
Training epochs:   3%|â–Ž         | 1/32 [00:21<11:15, 21.80s/it]
Epoch 2/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Epoch 1/32 - Train Loss: 45.979035 - Test Loss: 41.463709
Training epochs:   3%|â–Ž         | 1/32 [00:21<11:16, 21.82s/it]
Epoch 2/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 2/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 2/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.55s/it][A
Epoch 2/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 2/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 2/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 2/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A

Epoch 2/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][AEpoch 2/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A

Epoch 2/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][AEpoch 2/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 2/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 2/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 2/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 2/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 2/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 2/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A

Epoch 2/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][AEpoch 2/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 2/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 2/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 2/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 2/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A

Epoch 2/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][AEpoch 2/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 2/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 2/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

Epoch 2/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 2/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=4.5] Epoch 2 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.276e-01

  layer model_7__forward_module.module.conv2 act-std: mean=7.213e-01
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  layer model_6__forward_module.module.conv1 act-std: mean=1.152e+00[A
  layer model_6__forward_module.module.conv2 act-std: mean=2.743e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.490e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.163e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.789e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.060e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.540e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.699e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.063e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.307e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.620e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.356e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.490e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.755e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=4.080e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.036e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.179e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=6.238e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.396e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=8.513e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=1.521e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.235e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=7.257e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=9.406e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.587e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.896e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=8.620e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.278e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.280e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.673e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=5.876e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.341e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.374e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.984e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=6.563e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.698e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=5.341e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=4.026e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=8.658e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.248e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.436e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.939e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=8.394e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.938e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.458e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.81it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Epoch 2/32 - Train Loss: 45.988228 - Test Loss: 41.463446
Training epochs:   6%|â–‹         | 2/32 [00:43<10:51, 21.71s/it]
Epoch 3/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:   6%|â–‹         | 2/32 [00:43<10:51, 21.71s/it]
Epoch 3/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 3/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 3/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A

Epoch 3/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][AEpoch 3/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 3/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 3/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A

Epoch 3/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][AEpoch 3/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 3/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 3/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 3/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 3/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 3/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 3/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 3/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 3/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 3/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 3/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 3/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 3/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A

Epoch 3/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][AEpoch 3/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 3/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 3/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A

Epoch 3/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 3/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 3/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]
Epoch 3/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=4.5] Epoch 3 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.275e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.214e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.152e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.743e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.490e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.165e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.787e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.061e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.540e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.699e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.063e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.307e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.620e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.356e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.493e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.747e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=4.062e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.030e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.171e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=6.282e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.410e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=8.508e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=1.523e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.216e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=7.216e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=9.348e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.566e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.894e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=8.617e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.281e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.277e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.666e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=5.856e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.343e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.364e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.979e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=6.550e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.693e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=5.329e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=4.044e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=8.692e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.250e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.438e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.932e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=8.384e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.943e+00

  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.443e-01
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A

Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][AEvaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.76it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Epoch 3/32 - Train Loss: 46.024032 - Test Loss: 41.463220

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Training epochs:   9%|â–‰         | 3/32 [01:05<10:28, 21.67s/it]
Epoch 4/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:   9%|â–‰         | 3/32 [01:05<10:28, 21.67s/it]
Epoch 4/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 4/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][AEpoch 4/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A

Epoch 4/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][AEpoch 4/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 4/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 4/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 4/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 4/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A

Epoch 4/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][AEpoch 4/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 4/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 4/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A

Epoch 4/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][AEpoch 4/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A

Epoch 4/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][AEpoch 4/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 4/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 4/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A

Epoch 4/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][AEpoch 4/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 4/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 4/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A

Epoch 4/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][AEpoch 4/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A

Epoch 4/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 4/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 4/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]
Epoch 4/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=4.5] Epoch 4 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.276e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.215e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.152e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.743e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.490e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.165e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.788e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.060e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.541e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.699e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.063e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.307e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.620e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.356e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.490e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.745e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=4.058e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.035e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.175e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=6.218e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.391e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=8.567e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=1.519e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.228e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=7.237e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=9.328e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.577e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.902e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=8.632e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.281e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.284e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.654e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=5.836e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.336e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.360e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.985e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=6.563e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.704e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=5.345e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=4.034e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=8.676e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.243e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.434e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.924e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=8.364e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.932e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.436e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.82it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.81it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.81it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.81it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]
Epoch 4/32 - Train Loss: 46.023472 - Test Loss: 41.462967

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]
Training epochs:  12%|â–ˆâ–Ž        | 4/32 [01:26<10:05, 21.64s/it]
Epoch 5/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  12%|â–ˆâ–Ž        | 4/32 [01:26<10:06, 21.65s/it]
Epoch 5/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 5/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 5/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A

Epoch 5/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][AEpoch 5/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 5/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 5/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 5/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:14,  1.58s/it][A
Epoch 5/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:14,  1.59s/it][A
Epoch 5/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.56s/it][A
Epoch 5/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.56s/it][A

Epoch 5/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.55s/it][AEpoch 5/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.55s/it][A
Epoch 5/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 5/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A

Epoch 5/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][AEpoch 5/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 5/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 5/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 5/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 5/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 5/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 5/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A

Epoch 5/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][AEpoch 5/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A

Epoch 5/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 5/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 5/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=4.5] Epoch 5 summary:
Epoch 5/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.276e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.214e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.152e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.743e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.490e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.165e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.789e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.061e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.541e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.699e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.063e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.308e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.619e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.356e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.491e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.746e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=4.059e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.027e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.164e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=6.225e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.396e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=8.454e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=1.513e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.224e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=7.234e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=9.385e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.579e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.899e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=8.627e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.282e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.280e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.656e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=5.840e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.326e+00

  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.348e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.966e+00Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  param model_5__forward_module.module.conv1.bias grad-norm: mean=6.522e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.678e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=5.307e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=4.033e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=8.667e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.239e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.426e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.921e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=8.359e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.925e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.420e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.77it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.81it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.81it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.81it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.97it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]
Training epochs:  16%|â–ˆâ–Œ        | 5/32 [01:48<09:45, 21.68s/it]

Epoch 6/32:   0%|          | 0/13 [00:00<?, ?it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][A[AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]
Epoch 5/32 - Train Loss: 46.058470 - Test Loss: 41.462731
Training epochs:  16%|â–ˆâ–Œ        | 5/32 [01:48<09:45, 21.68s/it]
Epoch 6/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 6/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 6/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.55s/it][A
Epoch 6/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 6/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 6/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 6/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 6/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 6/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 6/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 6/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 6/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 6/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 6/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 6/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A

Epoch 6/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][AEpoch 6/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 6/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 6/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A

Epoch 6/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][AEpoch 6/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 6/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 6/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 6/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 6/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A

Epoch 6/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 6/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 6/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]
Epoch 6/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

[Î²=4.5] Epoch 6 summary:
  input  std: mean=1.813e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.275e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.214e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.152e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.744e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.490e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.165e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.787e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.061e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.540e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.699e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.063e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.307e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.620e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.356e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.492e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.737e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=4.040e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.031e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.164e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=6.173e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.382e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=8.491e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=1.512e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.223e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=7.232e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=9.361e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.581e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.892e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=8.611e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.276e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.274e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.657e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=5.836e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.334e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.357e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.980e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=6.552e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.695e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=5.335e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=4.020e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=8.640e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.234e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.424e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.929e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=8.376e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.936e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.435e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.77it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.76it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.76it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Training epochs:  19%|â–ˆâ–‰        | 6/32 [02:09<09:22, 21.65s/it]
Epoch 7/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.85it/s]
Epoch 6/32 - Train Loss: 46.031890 - Test Loss: 41.462485
Training epochs:  19%|â–ˆâ–‰        | 6/32 [02:10<09:22, 21.65s/it]
Epoch 7/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 7/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 7/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.55s/it][A
Epoch 7/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 7/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A

Epoch 7/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][AEpoch 7/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A

Epoch 7/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][AEpoch 7/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 7/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 7/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 7/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 7/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 7/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 7/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 7/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 7/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A

Epoch 7/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][AEpoch 7/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 7/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 7/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A

Epoch 7/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][AEpoch 7/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A

Epoch 7/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][AEpoch 7/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 7/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 7/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=4.5] Epoch 7 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.274e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.214e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.152e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.743e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.490e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.163e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.788e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.061e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.540e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.699e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.063e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.308e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.620e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.356e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.493e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.732e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=4.026e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.030e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.159e-01

  param model_1__forward_module.module.conv1.weight grad-norm: mean=6.201e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.388e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=8.451e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=1.502e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.205e+00Epoch 7/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it]
[A  param model_2__forward_module.module.conv1.bias grad-norm: mean=7.189e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=9.345e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.561e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.891e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=8.608e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.274e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.272e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.646e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=5.817e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.332e+00Epoch 7/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.346e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.976e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=6.542e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.689e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=5.324e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=4.011e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=8.623e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.213e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.397e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.918e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=8.347e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.928e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.425e-01


Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][AEvaluating:   0%|          | 0/4 [00:00<?, ?it/s][A

Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.75it/s][AEvaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.76it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Training epochs:  22%|â–ˆâ–ˆâ–       | 7/32 [02:31<09:01, 21.66s/it]
Epoch 8/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Epoch 7/32 - Train Loss: 46.003762 - Test Loss: 41.462293
Training epochs:  22%|â–ˆâ–ˆâ–       | 7/32 [02:31<09:01, 21.66s/it]
Epoch 8/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 8/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][AEpoch 8/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 8/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 8/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A

Epoch 8/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][AEpoch 8/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 8/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 8/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 8/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 8/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A

Epoch 8/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][AEpoch 8/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 8/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 8/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A

Epoch 8/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][AEpoch 8/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 8/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 8/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A

Epoch 8/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][AEpoch 8/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A

Epoch 8/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][AEpoch 8/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A

Epoch 8/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][AEpoch 8/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 8/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 8/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

Epoch 8/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 8/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=4.5] Epoch 8 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.274e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.215e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.152e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.744e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.490e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.165e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.788e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.061e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.540e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.700e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.063e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.308e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.620e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.356e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.493e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.735e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=4.037e-01

  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.027e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.158e-01Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  param model_1__forward_module.module.conv1.weight grad-norm: mean=6.219e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.389e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=8.457e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=1.505e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.209e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=7.198e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=9.348e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.573e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.886e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=8.597e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.276e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.272e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.647e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=5.817e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.326e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.346e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.969e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=6.528e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.688e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=5.321e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.996e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=8.593e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.208e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.387e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.926e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=8.366e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.935e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.434e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.81it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.81it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Epoch 8/32 - Train Loss: 46.054559 - Test Loss: 41.462073
Training epochs:  25%|â–ˆâ–ˆâ–Œ       | 8/32 [02:53<08:39, 21.64s/it]
Epoch 9/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  25%|â–ˆâ–ˆâ–Œ       | 8/32 [02:53<08:39, 21.64s/it]
Epoch 9/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 9/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 9/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A

Epoch 9/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][AEpoch 9/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 9/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 9/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 9/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 9/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 9/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 9/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 9/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 9/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A

Epoch 9/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it]Epoch 9/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A[A
Epoch 9/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 9/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 9/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 9/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A

Epoch 9/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][AEpoch 9/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 9/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 9/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 9/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 9/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 9/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 9/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=4.5] Epoch 9 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.275e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.215e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.152e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.744e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.490e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.167e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.788e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.061e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.541e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.700e-01

  layer model_2__forward_module.module.conv1 act-std: mean=1.063e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.309e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.620e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.356e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.491e-01
Epoch 9/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it]  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.738e+00[A
  param model_0__forward_module.module.conv1.bias grad-norm: mean=4.043e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.029e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.168e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=6.213e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.395e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=8.434e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=1.509e-01Epoch 9/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.204e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=7.192e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=9.261e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.560e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.877e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=8.580e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.272e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.261e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.637e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=5.797e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.312e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.330e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.965e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=6.522e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.685e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=5.313e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=4.006e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=8.616e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.217e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.399e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.920e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=8.358e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.930e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.429e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.76it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A

Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][AEvaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Epoch 9/32 - Train Loss: 46.016167 - Test Loss: 41.461856
Training epochs:  28%|â–ˆâ–ˆâ–Š       | 9/32 [03:14<08:17, 21.63s/it]
Epoch 10/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  28%|â–ˆâ–ˆâ–Š       | 9/32 [03:14<08:17, 21.63s/it]
Epoch 10/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 10/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 10/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 10/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 10/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 10/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 10/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A

Epoch 10/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][AEpoch 10/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 10/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 10/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 10/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 10/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A

Epoch 10/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it]Epoch 10/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A[A
Epoch 10/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 10/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 10/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 10/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 10/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 10/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 10/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 10/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A

Epoch 10/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][AEpoch 10/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A

Epoch 10/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 10/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 10/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]
Epoch 10/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

[Î²=4.5] Epoch 10 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.274e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.214e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.152e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.744e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.490e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.166e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.789e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.060e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.540e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.700e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.063e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.307e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.620e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.356e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.492e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.729e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=4.022e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.025e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.151e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=6.189e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.386e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=8.453e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=1.500e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.205e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=7.190e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=9.330e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.559e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.878e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=8.582e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.270e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.258e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.646e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=5.817e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.327e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.350e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.966e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=6.523e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.682e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=5.308e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.999e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=8.597e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.201e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.376e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.923e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=8.361e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.933e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.433e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.77it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]
Training epochs:  31%|â–ˆâ–ˆâ–ˆâ–      | 10/32 [03:36<07:55, 21.61s/it]
Epoch 11/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Epoch 10/32 - Train Loss: 45.981034 - Test Loss: 41.461668
Training epochs:  31%|â–ˆâ–ˆâ–ˆâ–      | 10/32 [03:36<07:55, 21.61s/it]
Epoch 11/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 11/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 11/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 11/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 11/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 11/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 11/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 11/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 11/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A

Epoch 11/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][AEpoch 11/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 11/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 11/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A

Epoch 11/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][AEpoch 11/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A

Epoch 11/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][AEpoch 11/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 11/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 11/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 11/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 11/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A

Epoch 11/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][AEpoch 11/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A

Epoch 11/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][AEpoch 11/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A

Epoch 11/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 11/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 11/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]
Epoch 11/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=4.5] Epoch 11 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.274e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.214e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.152e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.743e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.490e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.164e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.788e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.061e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.541e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.701e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.063e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.309e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.620e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.356e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.492e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.741e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=4.050e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.028e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.167e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=6.265e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.399e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=8.699e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=1.549e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.201e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=7.184e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=9.303e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.556e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.874e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=8.575e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.270e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.261e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.642e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=5.806e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.317e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.333e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.970e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=6.534e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.689e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=5.317e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=4.005e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=8.613e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.221e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.405e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.906e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=8.326e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.919e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.413e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Training epochs:  34%|â–ˆâ–ˆâ–ˆâ–      | 11/32 [03:58<07:33, 21.61s/it]
Epoch 12/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Epoch 11/32 - Train Loss: 46.007136 - Test Loss: 41.461455
Training epochs:  34%|â–ˆâ–ˆâ–ˆâ–      | 11/32 [03:58<07:33, 21.61s/it]
Epoch 12/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 12/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.55s/it][A
Epoch 12/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 12/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 12/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A

Epoch 12/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][AEpoch 12/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A

Epoch 12/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][AEpoch 12/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 12/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 12/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 12/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 12/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A

Epoch 12/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][AEpoch 12/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 12/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 12/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 12/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 12/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 12/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 12/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A

Epoch 12/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][AEpoch 12/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A

Epoch 12/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][AEpoch 12/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 12/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it]
[AEpoch 12/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it]Epoch 12/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it][A
Epoch 12/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=4.5] Epoch 12 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.276e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.215e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.152e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.743e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.490e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.167e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.788e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.061e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.541e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.701e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.063e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.309e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.620e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.356e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.495e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.734e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=4.032e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.024e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.158e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=6.191e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.388e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=8.404e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=1.502e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.202e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=7.187e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=9.286e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.550e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.879e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=8.583e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.272e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.257e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.644e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=5.812e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.336e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.355e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.961e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=6.512e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.684e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=5.309e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=4.012e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=8.628e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.213e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.396e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.906e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=8.324e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.925e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.415e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A

Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][AEvaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.82it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.96it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]
Epoch 12/32 - Train Loss: 46.025020 - Test Loss: 41.461279

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.96it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]
Training epochs:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 12/32 [04:19<07:12, 21.60s/it]
Epoch 13/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 12/32 [04:19<07:12, 21.61s/it]
Epoch 13/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 13/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 13/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][A

Epoch 13/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][AEpoch 13/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 13/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 13/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A

Epoch 13/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][AEpoch 13/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 13/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 13/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 13/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:11,  1.58s/it][A
Epoch 13/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:11,  1.58s/it][A

Epoch 13/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.57s/it][AEpoch 13/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.57s/it][A
Epoch 13/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.55s/it][A
Epoch 13/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.55s/it][A

Epoch 13/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.55s/it]Epoch 13/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.55s/it][A[A
Epoch 13/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 13/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A

Epoch 13/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][AEpoch 13/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 13/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 13/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 13/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][A
Epoch 13/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]
Epoch 13/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 13/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=4.5] Epoch 13 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.275e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.215e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.152e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.745e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.490e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.166e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.788e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.061e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.543e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.703e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.063e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.311e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.621e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.356e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.495e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.726e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=4.014e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.024e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.149e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=6.163e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.378e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=8.375e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=1.497e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.193e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=7.165e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=9.292e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.550e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.878e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=8.580e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.274e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.266e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.654e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=5.834e-01

  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.327e+00
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.349e-01[A
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.951e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=6.487e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.670e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=5.284e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=4.018e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=8.637e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.238e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.414e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.890e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=8.289e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.917e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.400e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A

Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.77it/s][AEvaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.76it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.76it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.75it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.85it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.84it/s]
Epoch 13/32 - Train Loss: 46.040965 - Test Loss: 41.461089
Training epochs:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 13/32 [04:41<06:51, 21.67s/it]
Epoch 14/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 13/32 [04:41<06:51, 21.67s/it]
Epoch 14/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 14/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 14/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A

Epoch 14/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][AEpoch 14/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A

Epoch 14/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][AEpoch 14/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 14/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 14/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 14/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 14/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 14/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 14/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 14/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 14/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A

Epoch 14/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][AEpoch 14/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A

Epoch 14/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][AEpoch 14/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 14/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 14/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 14/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 14/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A

Epoch 14/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][AEpoch 14/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A

Epoch 14/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 14/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 14/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]
Epoch 14/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]
[Î²=4.5] Epoch 14 summary:

  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.275e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.214e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.152e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.744e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.490e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.167e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.788e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.061e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.541e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.701e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.063e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.310e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.620e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.356e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.496e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.734e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=4.033e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.028e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.159e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=6.223e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.396e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=8.568e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=1.519e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.181e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=7.140e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=9.289e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.534e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.847e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=8.517e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.265e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.223e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.647e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=5.819e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.324e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.341e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.958e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=6.508e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.675e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=5.294e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=4.012e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=8.619e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.224e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.401e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.903e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=8.316e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.922e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.413e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.77it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.77it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]
Training epochs:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 14/32 [05:03<06:29, 21.65s/it]
Epoch 15/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Epoch 14/32 - Train Loss: 46.050291 - Test Loss: 41.460885
Training epochs:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 14/32 [05:03<06:29, 21.65s/it]
Epoch 15/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 15/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.55s/it][AEpoch 15/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 15/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 15/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 15/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 15/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 15/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 15/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A

Epoch 15/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][AEpoch 15/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 15/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 15/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 15/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 15/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A

Epoch 15/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it]Epoch 15/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A[A
Epoch 15/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 15/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A

Epoch 15/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][AEpoch 15/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 15/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 15/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A

Epoch 15/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][AEpoch 15/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A

Epoch 15/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.47s/it][AEpoch 15/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.47s/it][AEpoch 15/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]Epoch 15/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]


[Î²=4.5] Epoch 15 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.275e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.215e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.152e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.744e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.490e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.167e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.788e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.061e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.542e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.702e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.063e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.310e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.621e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.356e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.493e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.727e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=4.018e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.023e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.147e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=6.190e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.387e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=8.433e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=1.502e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.188e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=7.156e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=9.246e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.541e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.860e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=8.544e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.264e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.242e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.634e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=5.785e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.314e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.327e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.963e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=6.519e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.679e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=5.304e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.983e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=8.561e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.192e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.365e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.906e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=8.327e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.926e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.419e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.76it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Epoch 15/32 - Train Loss: 45.997449 - Test Loss: 41.460714
Training epochs:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 15/32 [05:24<06:08, 21.70s/it]
Epoch 16/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 15/32 [05:24<06:08, 21.70s/it]
Epoch 16/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 16/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 16/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 16/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 16/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 16/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 16/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 16/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 16/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 16/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 16/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A

Epoch 16/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][AEpoch 16/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A

Epoch 16/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][AEpoch 16/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 16/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 16/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A

Epoch 16/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it]Epoch 16/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A[A
Epoch 16/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 16/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A

Epoch 16/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it]Epoch 16/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A[A

Epoch 16/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][AEpoch 16/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 16/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 16/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=4.5] Epoch 16 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.276e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.216e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.152e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.744e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.490e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.169e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.789e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.061e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.542e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.702e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.063e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.310e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.621e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.356e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.496e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.720e+00

  param model_0__forward_module.module.conv1.bias grad-norm: mean=4.001e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.025e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.143e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=6.120e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.371e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=8.367e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=1.492e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.179e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=7.136e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=9.273e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.530e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.863e+00
Epoch 16/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it]  param model_3__forward_module.module.conv1.bias grad-norm: mean=8.550e-01[A
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.269e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.246e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.640e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=5.805e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.319e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.338e-01
Epoch 16/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.952e+00

  param model_5__forward_module.module.conv1.bias grad-norm: mean=6.491e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.674e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=5.286e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=4.017e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=8.641e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.210e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.392e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.897e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=8.307e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.923e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.413e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[AEvaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.81it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Epoch 16/32 - Train Loss: 46.003179 - Test Loss: 41.460542
Training epochs:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 16/32 [05:46<05:46, 21.67s/it]
Epoch 17/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Training epochs:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 16/32 [05:46<05:46, 21.68s/it]
Epoch 17/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 17/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 17/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][A
Epoch 17/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 17/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 17/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 17/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A

Epoch 17/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][AEpoch 17/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A

Epoch 17/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][AEpoch 17/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 17/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 17/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 17/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 17/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A

Epoch 17/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][AEpoch 17/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A

Epoch 17/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][AEpoch 17/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 17/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 17/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 17/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 17/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 17/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 17/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 17/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 17/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

Epoch 17/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 17/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

[Î²=4.5] Epoch 17 summary:
  input  std: mean=1.813e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.276e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.216e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.152e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.744e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.490e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.170e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.788e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.061e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.541e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.702e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.063e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.310e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.620e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.356e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.496e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.724e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=4.012e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.022e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.148e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=6.214e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.392e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=8.440e-01

  param model_1__forward_module.module.conv2.bias grad-norm: mean=1.506e-01
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.190e+00[A
  param model_2__forward_module.module.conv1.bias grad-norm: mean=7.161e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=9.316e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.549e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.869e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=8.564e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.273e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.261e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.633e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=5.788e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.318e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.333e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.946e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=6.486e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.672e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=5.286e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.991e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=8.581e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.193e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.368e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.897e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=8.309e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.919e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.403e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.96it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]

Training epochs:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 17/32 [06:08<05:24, 21.64s/it]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]
Epoch 17/32 - Train Loss: 46.063385 - Test Loss: 41.460370

Epoch 18/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 17/32 [06:08<05:24, 21.64s/it]
Epoch 18/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 18/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 18/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 18/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 18/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A

Epoch 18/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][AEpoch 18/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A

Epoch 18/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it]Epoch 18/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A[A
Epoch 18/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 18/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 18/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 18/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 18/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 18/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 18/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 18/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 18/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 18/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 18/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 18/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 18/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 18/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 18/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 18/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 18/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 18/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

Epoch 18/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 18/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=4.5] Epoch 18 summary:
  input  std: mean=1.813e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.276e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.217e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.152e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.744e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.490e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.170e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.788e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.062e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.541e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.701e-01

  layer model_2__forward_module.module.conv1 act-std: mean=1.063e+00Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  layer model_2__forward_module.module.conv2 act-std: mean=4.310e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.620e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.356e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.498e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.726e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=4.014e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.023e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.147e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=6.212e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.386e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=8.436e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=1.503e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.178e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=7.132e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=9.248e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.537e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.860e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=8.544e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.268e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.247e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.617e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=5.755e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.303e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.309e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.962e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=6.517e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.679e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=5.307e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.992e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=8.580e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.195e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.368e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.908e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=8.331e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.937e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.437e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.81it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s]Training epochs:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 18/32 [06:29<05:02, 21.64s/it][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Epoch 18/32 - Train Loss: 45.986357 - Test Loss: 41.460198

Epoch 19/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 18/32 [06:29<05:02, 21.64s/it]
Epoch 19/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 19/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 19/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][A
Epoch 19/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 19/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A

Epoch 19/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][AEpoch 19/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 19/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 19/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 19/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 19/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A

Epoch 19/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][AEpoch 19/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 19/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 19/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 19/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 19/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 19/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 19/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 19/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 19/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 19/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 19/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A

Epoch 19/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][AEpoch 19/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 19/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 19/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=4.5] Epoch 19 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.276e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.216e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.152e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.745e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.490e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.167e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.790e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.061e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.541e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.703e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.063e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.312e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.621e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.356e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.497e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.713e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=3.987e-01

  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.021e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.147e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=6.166e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.379e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=8.352e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=1.489e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.183e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=7.144e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=9.240e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.538e-01
Epoch 19/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it]  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.855e+00[A
  param model_3__forward_module.module.conv1.bias grad-norm: mean=8.534e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.268e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.231e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.621e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=5.757e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.304e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.314e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.942e+00Epoch 19/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

  param model_5__forward_module.module.conv1.bias grad-norm: mean=6.473e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.661e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=5.268e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.985e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=8.572e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.189e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.369e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.899e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=8.309e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.924e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.406e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.83it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.83it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.81it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.81it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]
Epoch 19/32 - Train Loss: 46.000619 - Test Loss: 41.460012

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Training epochs:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 19/32 [06:51<04:41, 21.62s/it]
Epoch 20/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 19/32 [06:51<04:41, 21.63s/it]
Epoch 20/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 20/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][AEpoch 20/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 20/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 20/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 20/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 20/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A

Epoch 20/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][AEpoch 20/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 20/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 20/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A

Epoch 20/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][AEpoch 20/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 20/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 20/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A

Epoch 20/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][AEpoch 20/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 20/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 20/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 20/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 20/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A

Epoch 20/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][AEpoch 20/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 20/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 20/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 20/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 20/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

Epoch 20/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 20/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

[Î²=4.5] Epoch 20 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.275e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.216e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.152e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.744e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.490e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.168e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.789e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.061e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.542e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.702e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.063e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.311e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.621e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.356e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.496e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.719e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=4.000e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.018e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.134e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=6.161e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.382e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=8.333e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=1.482e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.160e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=7.096e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=9.234e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.510e-01

  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.831e+00
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  param model_3__forward_module.module.conv1.bias grad-norm: mean=8.482e-01[A
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.260e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.206e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.634e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=5.791e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.308e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.322e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.960e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=6.513e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.675e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=5.299e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.999e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=8.598e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.198e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.373e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.899e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=8.310e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.921e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.408e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.76it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.81it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Training epochs:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 20/32 [07:12<04:19, 21.60s/it]
Epoch 21/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.85it/s]
Epoch 20/32 - Train Loss: 46.014033 - Test Loss: 41.459871
Training epochs:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 20/32 [07:12<04:19, 21.61s/it]
Epoch 21/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 21/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][A
Epoch 21/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.56s/it][A
Epoch 21/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 21/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A

Epoch 21/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][AEpoch 21/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 21/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 21/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 21/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 21/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 21/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 21/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 21/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 21/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 21/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.58s/it][A
Epoch 21/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.58s/it][A
Epoch 21/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.57s/it][A
Epoch 21/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.57s/it][A
Epoch 21/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.55s/it][A
Epoch 21/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.55s/it][A
Epoch 21/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.55s/it][A
Epoch 21/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:17<00:03,  1.55s/it][A
Epoch 21/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 21/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 21/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 21/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=4.5] Epoch 21 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.274e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.215e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.152e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.744e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.490e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.166e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.788e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.061e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.541e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.702e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.063e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.310e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.620e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.356e+00

  layer model_0__forward_module.module.conv2 act-std: mean=8.495e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.712e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=3.984e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.017e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.130e-01Epoch 21/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it]
[A  param model_1__forward_module.module.conv1.weight grad-norm: mean=6.155e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.381e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=8.378e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=1.492e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.172e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=7.120e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=9.220e-01Epoch 21/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.517e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.838e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=8.496e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.261e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.224e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.630e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=5.783e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.303e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.318e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.954e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=6.498e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.671e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=5.287e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.972e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=8.535e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.173e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.340e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.889e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=8.285e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.914e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.398e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]
Training epochs:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 21/32 [07:34<03:58, 21.67s/it]
Epoch 22/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Epoch 21/32 - Train Loss: 45.997759 - Test Loss: 41.459704
Training epochs:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 21/32 [07:34<03:58, 21.67s/it]
Epoch 22/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 22/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][AEpoch 22/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 22/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 22/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A

Epoch 22/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][AEpoch 22/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 22/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 22/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 22/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 22/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 22/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 22/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 22/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 22/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 22/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 22/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A

Epoch 22/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][AEpoch 22/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A

Epoch 22/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it]Epoch 22/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A[A
Epoch 22/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 22/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 22/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 22/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A

Epoch 22/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 22/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 22/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]
Epoch 22/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=4.5] Epoch 22 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.273e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.213e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.152e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.743e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.490e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.163e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.788e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.061e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.541e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.701e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.063e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.310e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.620e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.356e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.494e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.713e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=3.985e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.018e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.129e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=6.103e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.368e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=8.358e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=1.483e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.176e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=7.128e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=9.328e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.542e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.838e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=8.496e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.266e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.225e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.638e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=5.797e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.320e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.334e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.946e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=6.481e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.668e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=5.279e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.989e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=8.576e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.199e+00

  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.371e-01
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.903e+00[A
  param model_7__forward_module.module.conv1.bias grad-norm: mean=8.315e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.925e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.416e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.77it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.82it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.96it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]
Training epochs:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 22/32 [07:56<03:36, 21.64s/it]
Epoch 23/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Epoch 22/32 - Train Loss: 45.970288 - Test Loss: 41.459557
Training epochs:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 22/32 [07:56<03:36, 21.65s/it]
Epoch 23/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 23/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.57s/it][A
Epoch 23/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A

Epoch 23/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it]Epoch 23/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A[A

Epoch 23/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][AEpoch 23/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A

Epoch 23/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][AEpoch 23/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 23/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 23/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 23/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 23/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A

Epoch 23/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][AEpoch 23/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A

Epoch 23/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][AEpoch 23/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A

Epoch 23/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it]Epoch 23/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A[A

Epoch 23/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][AEpoch 23/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 23/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 23/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A

Epoch 23/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][AEpoch 23/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 23/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 23/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

Epoch 23/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 23/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=4.5] Epoch 23 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.276e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.217e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.152e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.744e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.490e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.170e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.789e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.061e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.542e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.703e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.063e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.312e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.621e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.356e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.497e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.711e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=3.981e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.016e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.128e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=6.138e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.375e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=8.407e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=1.496e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.176e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=7.128e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=9.267e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.532e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.839e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=8.497e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.265e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.223e-01

  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.620e+00
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  param model_4__forward_module.module.conv1.bias grad-norm: mean=5.757e-01[A
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.312e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.317e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.950e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=6.491e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.671e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=5.287e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.965e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=8.525e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.157e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.325e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.897e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=8.307e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.923e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.406e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.83it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.82it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Epoch 23/32 - Train Loss: 46.043213 - Test Loss: 41.459397

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Training epochs:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 23/32 [08:17<03:14, 21.66s/it]
Epoch 24/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 23/32 [08:17<03:14, 21.66s/it]
Epoch 24/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 24/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][AEpoch 24/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A

Epoch 24/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][AEpoch 24/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 24/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 24/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 24/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 24/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 24/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 24/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A

Epoch 24/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][AEpoch 24/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 24/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 24/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A

Epoch 24/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][AEpoch 24/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A

Epoch 24/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][AEpoch 24/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A

Epoch 24/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][AEpoch 24/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 24/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 24/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A

Epoch 24/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][AEpoch 24/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 24/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 24/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

Epoch 24/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 24/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=4.5] Epoch 24 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.276e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.217e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.152e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.745e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.490e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.172e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.788e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.062e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.542e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.702e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.063e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.311e-01

  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.621e+00Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  layer model_0__forward_module.module.conv1 act-std: mean=1.356e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.500e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.716e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=3.993e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.017e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.138e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=6.169e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.382e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=8.363e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=1.498e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.166e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=7.109e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=9.176e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.509e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.855e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=8.536e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.264e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.233e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.627e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=5.778e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.311e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.320e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.948e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=6.486e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.667e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=5.281e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.979e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=8.558e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.182e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.361e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.887e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=8.289e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.913e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.390e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.76it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.76it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.76it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Epoch 24/32 - Train Loss: 46.026083 - Test Loss: 41.459239
Training epochs:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 24/32 [08:39<02:53, 21.66s/it]
Epoch 25/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 24/32 [08:39<02:53, 21.65s/it]
Epoch 25/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 25/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 25/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 25/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 25/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A

Epoch 25/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][AEpoch 25/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 25/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 25/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A

Epoch 25/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][AEpoch 25/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A

Epoch 25/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][AEpoch 25/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A

Epoch 25/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][AEpoch 25/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 25/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 25/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 25/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 25/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A

Epoch 25/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][AEpoch 25/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 25/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 25/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 25/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 25/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 25/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 25/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=4.5] Epoch 25 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.276e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.216e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.152e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.744e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.490e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.171e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.788e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.061e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.542e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.704e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.063e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.312e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.621e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.356e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.498e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.711e+00

  param model_0__forward_module.module.conv1.bias grad-norm: mean=3.980e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.014e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.128e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=6.083e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.367e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=8.311e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=1.486e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.169e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=7.113e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=9.254e-01
Epoch 25/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it]  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.527e-01[A
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.837e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=8.492e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.260e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.214e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.619e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=5.758e-01Epoch 25/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.298e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.309e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.942e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=6.471e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.664e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=5.273e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.973e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=8.540e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.184e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.352e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.883e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=8.277e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.913e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.393e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.77it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.75it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Training epochs:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 25/32 [09:01<02:31, 21.67s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Epoch 25/32 - Train Loss: 46.032446 - Test Loss: 41.459120

Epoch 26/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 25/32 [09:01<02:31, 21.67s/it]
Epoch 26/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 26/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it]Epoch 26/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A[A

Epoch 26/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][AEpoch 26/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 26/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 26/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 26/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 26/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 26/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 26/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 26/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 26/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 26/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 26/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A

Epoch 26/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][AEpoch 26/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A

Epoch 26/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it]Epoch 26/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A[A
Epoch 26/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 26/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A

Epoch 26/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][AEpoch 26/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A

Epoch 26/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][AEpoch 26/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A

Epoch 26/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 26/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 26/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]
Epoch 26/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=4.5] Epoch 26 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.275e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.216e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.152e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.744e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.490e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.166e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.789e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.061e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.542e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.704e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.063e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.311e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.621e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.356e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.496e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.711e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=3.984e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.013e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.128e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=6.119e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.373e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=8.329e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=1.492e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.179e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=7.138e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=9.290e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.532e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.847e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=8.516e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.268e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.229e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.623e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=5.767e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.296e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.306e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.944e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=6.479e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.666e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=5.278e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.972e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=8.541e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.177e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.347e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.879e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=8.272e-01

  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.912e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.382e-01Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.77it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.75it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Epoch 26/32 - Train Loss: 45.992597 - Test Loss: 41.458955
Training epochs:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 26/32 [09:22<02:10, 21.67s/it]
Epoch 27/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 26/32 [09:23<02:10, 21.67s/it]
Epoch 27/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 27/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 27/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 27/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 27/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A

Epoch 27/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][AEpoch 27/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A

Epoch 27/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][AEpoch 27/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 27/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 27/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 27/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 27/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 27/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 27/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 27/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 27/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A

Epoch 27/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][AEpoch 27/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 27/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 27/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A

Epoch 27/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it]Epoch 27/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A[A
Epoch 27/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 27/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 27/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 27/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

Epoch 27/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 27/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=4.5] Epoch 27 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.276e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.217e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.152e+00

  layer model_6__forward_module.module.conv2 act-std: mean=2.745e-01
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  layer model_5__forward_module.module.conv1 act-std: mean=1.490e+00[A
  layer model_5__forward_module.module.conv2 act-std: mean=9.170e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.790e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.061e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.542e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.704e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.063e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.313e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.621e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.356e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.497e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.705e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=3.968e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.011e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.125e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=6.119e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.369e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=8.336e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=1.481e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.158e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=7.089e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=9.223e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.515e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.821e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=8.459e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.261e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.203e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.616e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=5.753e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.294e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.305e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.945e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=6.478e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.664e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=5.273e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.971e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=8.533e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.188e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.354e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.882e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=8.273e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.916e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.389e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Training epochs:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 27/32 [09:44<01:48, 21.66s/it]
Epoch 28/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Epoch 27/32 - Train Loss: 46.005591 - Test Loss: 41.458802
Training epochs:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 27/32 [09:44<01:48, 21.66s/it]
Epoch 28/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 28/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.55s/it][A
Epoch 28/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 28/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 28/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 28/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 28/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 28/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 28/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 28/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 28/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A

Epoch 28/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][AEpoch 28/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 28/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it]
[AEpoch 28/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A

Epoch 28/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][AEpoch 28/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A

Epoch 28/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][AEpoch 28/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A

Epoch 28/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][AEpoch 28/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 28/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 28/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 28/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 28/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 28/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 28/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=4.5] Epoch 28 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.274e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.215e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.152e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.744e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.490e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.167e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.789e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.061e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.542e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.703e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.063e+00

  layer model_2__forward_module.module.conv2 act-std: mean=4.311e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.621e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.356e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.498e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.708e+00
Epoch 28/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it]  param model_0__forward_module.module.conv1.bias grad-norm: mean=3.975e-01[A
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.013e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.126e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=6.117e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.370e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=8.352e-01
Epoch 28/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]  param model_1__forward_module.module.conv2.bias grad-norm: mean=1.485e-01

  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.155e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=7.084e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=9.208e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.510e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.829e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=8.476e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.261e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.213e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.611e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=5.740e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.294e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.299e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.935e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=6.459e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.658e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=5.261e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.961e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=8.517e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.167e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.337e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.884e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=8.280e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.911e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.388e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.87it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.83it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.82it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.82it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.81it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]Training epochs:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 28/32 [10:06<01:26, 21.66s/it]
Epoch 28/32 - Train Loss: 46.010868 - Test Loss: 41.458638

Epoch 29/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 28/32 [10:06<01:26, 21.66s/it]
Epoch 29/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 29/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 29/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 29/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 29/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 29/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 29/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 29/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 29/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 29/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 29/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 29/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 29/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 29/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 29/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 29/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 29/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A

Epoch 29/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it]Epoch 29/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A[A
Epoch 29/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.58s/it][A
Epoch 29/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.58s/it][A
Epoch 29/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.56s/it][A
Epoch 29/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.56s/it][A

Epoch 29/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.55s/it][AEpoch 29/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.55s/it][A
Epoch 29/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.43s/it][AEpoch 29/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=4.5] Epoch 29 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.277e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.218e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.152e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.745e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.490e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.172e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.787e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.061e+00

  layer model_3__forward_module.module.conv1 act-std: mean=6.542e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.703e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.063e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.313e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.621e+00
Epoch 29/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.43s/it]  layer model_0__forward_module.module.conv1 act-std: mean=1.356e+00[A
  layer model_0__forward_module.module.conv2 act-std: mean=8.496e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.716e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=3.993e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.019e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.136e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=6.116e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.372e-01
Epoch 29/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]  param model_1__forward_module.module.conv2.weight grad-norm: mean=8.399e-01

  param model_1__forward_module.module.conv2.bias grad-norm: mean=1.490e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.150e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=7.073e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=9.268e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.517e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.820e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=8.456e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.265e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.216e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.613e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=5.743e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.301e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.305e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.950e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=6.488e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.667e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=5.282e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.977e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=8.548e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.178e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.344e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.872e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=8.251e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.907e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.372e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.76it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Training epochs:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 29/32 [10:28<01:05, 21.71s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]

Epoch 30/32:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 29/32 - Train Loss: 46.005229 - Test Loss: 41.458543[A
Training epochs:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 29/32 [10:28<01:05, 21.71s/it]
Epoch 30/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 30/32:   8%|â–Š         | 1/13 [00:01<00:20,  1.68s/it][A
Epoch 30/32:   8%|â–Š         | 1/13 [00:01<00:20,  1.70s/it][A
Epoch 30/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:17,  1.59s/it][A
Epoch 30/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:17,  1.60s/it][A
Epoch 30/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.56s/it][A
Epoch 30/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.56s/it][A

Epoch 30/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.55s/it][AEpoch 30/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.55s/it][A

Epoch 30/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.55s/it][AEpoch 30/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 30/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 30/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 30/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 30/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 30/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 30/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A

Epoch 30/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it]Epoch 30/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A[A
Epoch 30/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 30/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 30/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 30/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 30/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 30/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A

Epoch 30/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 30/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it]Epoch 30/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it][A
Epoch 30/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=4.5] Epoch 30 summary:
  input  std: mean=1.813e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.275e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.216e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.152e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.745e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.490e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.170e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.788e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.061e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.542e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.702e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.063e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.311e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.620e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.356e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.496e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.708e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=3.974e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.014e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.127e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=6.099e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.364e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=8.342e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=1.472e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.152e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=7.076e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=9.219e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.497e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.819e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=8.455e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.262e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.198e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.622e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=5.762e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.302e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.308e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.938e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=6.466e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.658e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=5.260e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.971e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=8.538e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.190e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.362e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.876e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=8.265e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.915e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.385e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.82it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Training epochs:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 30/32 [10:49<00:43, 21.74s/it]
Epoch 31/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Epoch 30/32 - Train Loss: 46.031979 - Test Loss: 41.458434
Training epochs:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 30/32 [10:49<00:43, 21.74s/it]
Epoch 31/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 31/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.55s/it][A
Epoch 31/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 31/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 31/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 31/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 31/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 31/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 31/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 31/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 31/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A

Epoch 31/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][AEpoch 31/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 31/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 31/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 31/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 31/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 31/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 31/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 31/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 31/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A

Epoch 31/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][AEpoch 31/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 31/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 31/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A

Epoch 31/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 31/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 31/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]
Epoch 31/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=4.5] Epoch 31 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.276e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.217e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.152e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.744e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.490e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.171e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.788e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.061e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.542e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.704e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.063e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.313e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.621e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.356e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.500e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.703e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=3.965e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.010e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.122e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=6.119e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.372e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=8.313e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=1.482e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.160e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=7.096e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=9.198e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.510e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.826e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=8.470e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.260e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.209e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.625e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=5.773e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.303e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.318e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.943e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=6.477e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.660e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=5.271e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.986e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=8.572e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.188e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.364e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.888e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=8.292e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.919e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.399e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.77it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.76it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.96it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]
Training epochs:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 31/32 [11:11<00:21, 21.71s/it]
Epoch 32/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Epoch 31/32 - Train Loss: 45.997612 - Test Loss: 41.458289
Training epochs:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 31/32 [11:11<00:21, 21.71s/it]
Epoch 32/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 32/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 32/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.55s/it][A
Epoch 32/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 32/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A

Epoch 32/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it]Epoch 32/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A[A
Epoch 32/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 32/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 32/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 32/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A

Epoch 32/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][AEpoch 32/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 32/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 32/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A

Epoch 32/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][AEpoch 32/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 32/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 32/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A

Epoch 32/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][AEpoch 32/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A

Epoch 32/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][AEpoch 32/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A

Epoch 32/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][AEpoch 32/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 32/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 32/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=4.5] Epoch 32 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.276e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.216e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.152e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.744e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.490e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.169e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.788e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.061e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.541e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.703e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.063e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.312e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.621e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.356e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.494e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.704e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=3.965e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.015e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.129e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=6.109e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.372e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=8.361e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=1.486e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.144e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=7.058e-01

  param model_2__forward_module.module.conv2.weight grad-norm: mean=9.186e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.501e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.822e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=8.462e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.263e+00
Epoch 32/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it]  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.205e-01[A
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.621e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=5.765e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=2.310e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.325e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.942e+00
Epoch 32/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]  param model_5__forward_module.module.conv1.bias grad-norm: mean=6.469e-01

  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.661e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=5.264e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.973e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=8.542e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.167e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.337e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.885e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=8.286e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=1.919e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.399e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.96it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]
Training epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [11:33<00:00, 21.69s/it]Training epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [11:33<00:00, 21.66s/it]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Epoch 32/32 - Train Loss: 45.944018 - Test Loss: 41.458127
Training epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [11:33<00:00, 21.69s/it]Training epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [11:33<00:00, 21.66s/it]
Loaded best models from epoch 32 with loss 41.458127

>>> Completed beta = 4.5
>>> Time for this beta: 0:11:33
>>> Total elapsed time: 0:57:41
==================================================
Loaded data shape: torch.Size([4096, 2, 64, 64])
Training data shape: torch.Size([3276, 2, 64, 64])
Testing data shape: torch.Size([820, 2, 64, 64])

>>> Training the model at beta =  5.0

>>> Training the model at beta = 5.0

Training epochs:   0%|          | 0/32 [00:00<?, ?it/s]Training epochs:   0%|          | 0/32 [00:00<?, ?it/s]

Epoch 1/32:   0%|          | 0/13 [00:00<?, ?it/s][AEpoch 1/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 1/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 1/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A

Epoch 1/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][AEpoch 1/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 1/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 1/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 1/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 1/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 1/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 1/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 1/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 1/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A

Epoch 1/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][AEpoch 1/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 1/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 1/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A

Epoch 1/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][AEpoch 1/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 1/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 1/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A

Epoch 1/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][AEpoch 1/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 1/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 1/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 1/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 1/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=5.0] Epoch 1 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.159e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.012e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.150e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.668e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.498e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.900e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.704e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.034e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.448e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.529e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.065e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.142e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.579e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.364e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.278e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.871e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=6.561e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.617e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.494e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=9.905e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.191e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.289e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.434e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=5.267e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.165e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.418e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=5.750e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=6.067e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.332e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.931e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=6.601e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=4.547e+00

  param model_4__forward_module.module.conv1.bias grad-norm: mean=9.855e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.962e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=5.762e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=4.598e+00
Epoch 1/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it]  param model_5__forward_module.module.conv1.bias grad-norm: mean=9.911e-01[A
  param model_5__forward_module.module.conv2.weight grad-norm: mean=4.091e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=8.042e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=6.635e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.415e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=7.233e+00
Epoch 1/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]  param model_6__forward_module.module.conv2.bias grad-norm: mean=9.148e-01

  param model_7__forward_module.module.conv1.weight grad-norm: mean=5.879e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.238e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.896e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=6.599e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A

Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][AEvaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]
Epoch 1/32 - Train Loss: 48.073149 - Test Loss: 43.395937
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]
Training epochs:   3%|â–Ž         | 1/32 [00:21<11:09, 21.59s/it]
Epoch 2/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:   3%|â–Ž         | 1/32 [00:21<11:09, 21.59s/it]
Epoch 2/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 2/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][AEpoch 2/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 2/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 2/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 2/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 2/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 2/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 2/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A

Epoch 2/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][AEpoch 2/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 2/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 2/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 2/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 2/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 2/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 2/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A

Epoch 2/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][AEpoch 2/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A

Epoch 2/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][AEpoch 2/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 2/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 2/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 2/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 2/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 2/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][A
Epoch 2/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it]Epoch 2/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it][A
Epoch 2/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=5.0] Epoch 2 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.159e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.012e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.150e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.668e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.498e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.900e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.704e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.033e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.447e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.526e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.065e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.141e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.578e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.364e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.274e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.868e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=6.552e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.620e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.496e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=9.924e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.189e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.290e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.434e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=5.279e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.168e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.421e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=5.769e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=6.081e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.335e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.937e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=6.622e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=4.563e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=9.891e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.976e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=5.781e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=4.594e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=9.900e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=4.085e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=8.030e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=6.648e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.417e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=7.240e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=9.157e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=5.877e+00

  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.237e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.890e+00Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  param model_7__forward_module.module.conv2.bias grad-norm: mean=6.592e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A

Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.77it/s]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.77it/s][A[A

Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][AEvaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Epoch 2/32 - Train Loss: 48.033738 - Test Loss: 43.395641
Training epochs:   6%|â–‹         | 2/32 [00:43<10:48, 21.63s/it]
Epoch 3/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:   6%|â–‹         | 2/32 [00:43<10:48, 21.63s/it]
Epoch 3/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 3/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 3/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 3/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 3/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 3/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 3/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 3/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 3/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 3/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 3/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 3/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 3/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 3/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 3/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A

Epoch 3/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][AEpoch 3/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A

Epoch 3/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][AEpoch 3/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A

Epoch 3/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][AEpoch 3/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 3/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 3/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A

Epoch 3/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][AEpoch 3/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 3/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 3/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=5.0] Epoch 3 summary:
  input  std: mean=1.813e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.160e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.013e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.150e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.668e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.498e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.902e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.704e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.033e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.446e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.527e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.065e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.141e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.578e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.364e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.277e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.869e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=6.557e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.616e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.497e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=9.855e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.183e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.283e+00

  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.433e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=5.266e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.165e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.419e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=5.758e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=6.067e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.332e+00
Epoch 3/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it]  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.930e+00[A
  param model_3__forward_module.module.conv2.bias grad-norm: mean=6.601e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=4.556e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=9.876e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.976e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=5.781e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=4.598e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=9.909e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=4.086e+00
Epoch 3/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]  param model_5__forward_module.module.conv2.bias grad-norm: mean=8.039e-01

  param model_6__forward_module.module.conv1.weight grad-norm: mean=6.641e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.416e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=7.236e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=9.157e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=5.869e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.236e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.882e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=6.589e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A

Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][AEvaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Epoch 3/32 - Train Loss: 48.024171 - Test Loss: 43.395253

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Training epochs:   9%|â–‰         | 3/32 [01:04<10:27, 21.63s/it]
Epoch 4/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:   9%|â–‰         | 3/32 [01:04<10:27, 21.63s/it]
Epoch 4/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 4/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 4/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A

Epoch 4/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][AEpoch 4/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A

Epoch 4/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][AEpoch 4/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A

Epoch 4/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][AEpoch 4/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 4/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 4/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 4/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 4/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A

Epoch 4/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][AEpoch 4/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 4/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 4/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 4/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 4/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 4/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 4/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A

Epoch 4/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][AEpoch 4/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 4/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 4/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 4/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 4/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=5.0] Epoch 4 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.159e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.012e-01

  layer model_6__forward_module.module.conv1 act-std: mean=1.150e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.668e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.498e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.899e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.704e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.034e+00
Epoch 4/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it]  layer model_3__forward_module.module.conv1 act-std: mean=6.448e-01[A
  layer model_3__forward_module.module.conv2 act-std: mean=3.529e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.065e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.143e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.579e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.364e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.277e-01
Epoch 4/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.884e+00

  param model_0__forward_module.module.conv1.bias grad-norm: mean=6.589e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.623e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.513e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=9.833e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.175e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.283e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.427e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=5.277e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.167e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.421e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=5.767e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=6.051e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.328e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.932e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=6.584e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=4.561e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=9.881e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.972e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=5.778e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=4.590e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=9.895e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=4.083e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=8.029e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=6.652e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.418e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=7.247e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=9.169e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=5.846e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.231e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.875e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=6.565e-01


Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][AEvaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.96it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]
Epoch 4/32 - Train Loss: 48.030384 - Test Loss: 43.394889

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]
Training epochs:  12%|â–ˆâ–Ž        | 4/32 [01:26<10:05, 21.61s/it]
Epoch 5/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  12%|â–ˆâ–Ž        | 4/32 [01:26<10:05, 21.61s/it]
Epoch 5/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 5/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 5/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 5/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 5/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 5/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 5/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 5/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:14,  1.59s/it][A
Epoch 5/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:14,  1.59s/it][A
Epoch 5/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.57s/it][A
Epoch 5/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.57s/it][A

Epoch 5/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.56s/it][AEpoch 5/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.56s/it][A
Epoch 5/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.55s/it][A
Epoch 5/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.55s/it][A

Epoch 5/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][AEpoch 5/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A

Epoch 5/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][AEpoch 5/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A

Epoch 5/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][AEpoch 5/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A

Epoch 5/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][AEpoch 5/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A

Epoch 5/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][AEpoch 5/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 5/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 5/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=5.0] Epoch 5 summary:
  input  std: mean=1.813e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.159e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.012e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.150e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.668e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.498e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.897e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.704e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.034e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.447e-01

  layer model_3__forward_module.module.conv2 act-std: mean=3.530e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.065e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.143e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.579e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.364e+00
Epoch 5/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it]  layer model_0__forward_module.module.conv2 act-std: mean=8.279e-01[A
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.887e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=6.600e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.623e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.512e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=9.839e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.179e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.280e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.417e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=5.279e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.168e+00
Epoch 5/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.419e+00

  param model_2__forward_module.module.conv2.bias grad-norm: mean=5.772e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=6.073e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.333e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.931e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=6.616e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=4.550e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=9.864e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.952e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=5.755e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=4.605e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=9.927e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=4.100e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=8.058e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=6.635e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.415e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=7.209e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=9.119e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=5.863e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.235e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.876e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=6.579e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.84it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.84it/s][A

Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.82it/s][AEvaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.82it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][A[AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]
Epoch 5/32 - Train Loss: 48.083317 - Test Loss: 43.394573
Training epochs:  16%|â–ˆâ–Œ        | 5/32 [01:48<09:45, 21.68s/it]Training epochs:  16%|â–ˆâ–Œ        | 5/32 [01:48<09:45, 21.68s/it]
Epoch 6/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 6/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 6/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][AEpoch 6/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 6/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 6/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 6/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 6/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A

Epoch 6/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][AEpoch 6/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A

Epoch 6/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][AEpoch 6/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 6/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 6/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 6/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 6/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A

Epoch 6/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][AEpoch 6/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 6/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 6/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A

Epoch 6/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][AEpoch 6/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 6/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 6/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 6/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 6/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A

Epoch 6/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 6/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]
Epoch 6/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][A
[Î²=5.0] Epoch 6 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.161e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.015e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.150e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.668e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.498e+00Epoch 6/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

  layer model_5__forward_module.module.conv2 act-std: mean=8.906e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.704e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.034e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.448e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.528e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.065e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.142e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.578e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.364e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.277e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.867e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=6.552e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.617e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.492e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=9.827e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.172e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.280e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.425e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=5.263e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.164e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.416e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=5.750e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=6.045e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.327e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.924e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=6.577e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=4.555e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=9.868e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.968e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=5.771e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=4.587e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=9.883e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=4.078e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=8.012e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=6.634e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.414e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=7.223e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=9.135e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=5.853e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.233e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.880e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=6.579e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.77it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.81it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.76it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]
Training epochs:  19%|â–ˆâ–‰        | 6/32 [02:09<09:23, 21.68s/it]
Epoch 7/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Epoch 6/32 - Train Loss: 48.082624 - Test Loss: 43.394264
Training epochs:  19%|â–ˆâ–‰        | 6/32 [02:09<09:23, 21.69s/it]
Epoch 7/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 7/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.55s/it][A
Epoch 7/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A

Epoch 7/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][AEpoch 7/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 7/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 7/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 7/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 7/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 7/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 7/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A

Epoch 7/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][AEpoch 7/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 7/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 7/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 7/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 7/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 7/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 7/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A

Epoch 7/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][AEpoch 7/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A

Epoch 7/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][AEpoch 7/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A

Epoch 7/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][AEpoch 7/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 7/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 7/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

Epoch 7/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 7/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=5.0] Epoch 7 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.160e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.012e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.150e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.668e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.498e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.900e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.703e-01

  layer model_4__forward_module.module.conv2 act-std: mean=2.034e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.447e-01Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  layer model_3__forward_module.module.conv2 act-std: mean=3.528e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.065e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.141e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.578e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.364e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.276e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.882e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=6.586e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.623e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.517e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=9.871e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.186e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.282e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.428e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=5.264e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.165e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.417e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=5.750e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=6.064e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.331e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.934e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=6.600e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=4.538e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=9.833e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.951e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=5.749e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=4.603e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=9.922e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=4.088e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=8.042e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=6.618e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.411e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=7.213e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=9.124e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=5.868e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.235e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.880e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=6.582e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.81it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.96it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.96it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]
Epoch 7/32 - Train Loss: 48.040318 - Test Loss: 43.393997
Training epochs:  22%|â–ˆâ–ˆâ–       | 7/32 [02:31<09:01, 21.67s/it]Training epochs:  22%|â–ˆâ–ˆâ–       | 7/32 [02:31<09:01, 21.67s/it]
Epoch 8/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 8/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 8/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 8/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 8/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 8/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A

Epoch 8/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][AEpoch 8/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 8/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 8/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 8/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 8/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A

Epoch 8/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][AEpoch 8/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A

Epoch 8/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][AEpoch 8/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A

Epoch 8/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][AEpoch 8/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 8/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 8/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 8/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 8/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A

Epoch 8/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][AEpoch 8/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A

Epoch 8/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][AEpoch 8/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A

Epoch 8/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 8/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 8/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=5.0] Epoch 8 summary:
  input  std: mean=1.813e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.159e-01
Epoch 8/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]  layer model_7__forward_module.module.conv2 act-std: mean=7.014e-01

  layer model_6__forward_module.module.conv1 act-std: mean=1.150e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.668e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.498e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.901e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.703e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.034e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.447e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.528e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.065e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.142e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.578e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.364e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.277e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.866e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=6.553e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.615e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.495e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=9.803e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.171e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.276e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.413e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=5.278e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.168e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.424e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=5.764e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=6.069e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.332e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.938e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=6.606e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=4.545e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=9.851e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.952e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=5.753e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=4.588e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=9.894e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=4.081e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=8.030e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=6.635e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.415e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=7.230e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=9.149e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=5.854e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.233e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.882e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=6.573e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.76it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.75it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Training epochs:  25%|â–ˆâ–ˆâ–Œ       | 8/32 [02:53<08:39, 21.66s/it]
Epoch 9/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.84it/s]
Epoch 8/32 - Train Loss: 48.060153 - Test Loss: 43.393691
Training epochs:  25%|â–ˆâ–ˆâ–Œ       | 8/32 [02:53<08:40, 21.67s/it]
Epoch 9/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 9/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][AEpoch 9/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 9/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 9/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 9/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 9/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 9/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 9/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 9/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 9/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 9/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 9/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A

Epoch 9/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][AEpoch 9/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 9/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 9/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A

Epoch 9/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][AEpoch 9/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A

Epoch 9/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][AEpoch 9/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 9/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 9/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 9/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 9/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 9/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 9/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

Epoch 9/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 9/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

[Î²=5.0] Epoch 9 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.159e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.013e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.150e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.668e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.498e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.902e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.704e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.034e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.447e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.528e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.065e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.141e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.578e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.364e+00

  layer model_0__forward_module.module.conv2 act-std: mean=8.280e-01
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.870e+00[A
  param model_0__forward_module.module.conv1.bias grad-norm: mean=6.560e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.617e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.500e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=9.845e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.179e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.276e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.417e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=5.247e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.161e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.416e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=5.732e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=6.036e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.325e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.923e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=6.569e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=4.527e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=9.815e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.943e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=5.734e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=4.599e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=9.914e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=4.090e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=8.045e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=6.615e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.410e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=7.193e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=9.097e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=5.852e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.232e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.877e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=6.572e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.76it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Training epochs:  28%|â–ˆâ–ˆâ–Š       | 9/32 [03:14<08:17, 21.64s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Epoch 9/32 - Train Loss: 48.067295 - Test Loss: 43.393379

Epoch 10/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  28%|â–ˆâ–ˆâ–Š       | 9/32 [03:14<08:17, 21.64s/it]
Epoch 10/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 10/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 10/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 10/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 10/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A

Epoch 10/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][AEpoch 10/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 10/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 10/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 10/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 10/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 10/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 10/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A

Epoch 10/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][AEpoch 10/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A

Epoch 10/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][AEpoch 10/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 10/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 10/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A

Epoch 10/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][AEpoch 10/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 10/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 10/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 10/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 10/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 10/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 10/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

Epoch 10/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 10/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=5.0] Epoch 10 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.159e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.012e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.150e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.667e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.498e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.900e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.703e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.034e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.448e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.528e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.065e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.142e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.578e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.364e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.277e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.874e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=6.571e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.618e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.504e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=9.832e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.175e-01

  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.282e+00
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.419e-01[A
  param model_2__forward_module.module.conv1.weight grad-norm: mean=5.248e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.161e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.413e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=5.733e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=6.044e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.327e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.924e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=6.582e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=4.543e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=9.848e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.958e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=5.763e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=4.599e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=9.915e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=4.091e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=8.041e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=6.642e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.416e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=7.236e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=9.152e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=5.860e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.235e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.878e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=6.576e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Epoch 10/32 - Train Loss: 48.042788 - Test Loss: 43.393097
Training epochs:  31%|â–ˆâ–ˆâ–ˆâ–      | 10/32 [03:36<07:55, 21.64s/it]Training epochs:  31%|â–ˆâ–ˆâ–ˆâ–      | 10/32 [03:36<07:55, 21.63s/it]
Epoch 11/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 11/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 11/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 11/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 11/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 11/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 11/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 11/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 11/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 11/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A

Epoch 11/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it]Epoch 11/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A[A
Epoch 11/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 11/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 11/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 11/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 11/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 11/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A

Epoch 11/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.58s/it][AEpoch 11/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.58s/it][A
Epoch 11/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.56s/it][A
Epoch 11/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.57s/it][A

Epoch 11/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.55s/it][AEpoch 11/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.55s/it][A
Epoch 11/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.55s/it][A
Epoch 11/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.55s/it][A
Epoch 11/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 11/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

Epoch 11/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 11/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=5.0] Epoch 11 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.159e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.013e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.150e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.668e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.498e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.901e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.703e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.034e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.447e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.529e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.065e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.142e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.578e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.364e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.278e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.849e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=6.513e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.609e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.470e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=9.797e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.167e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.277e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.408e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=5.247e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.160e+00

  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.416e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=5.735e-01Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  param model_3__forward_module.module.conv1.weight grad-norm: mean=6.044e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.326e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.927e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=6.582e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=4.548e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=9.854e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.960e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=5.758e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=4.581e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=9.876e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=4.071e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=8.007e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=6.614e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.410e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=7.204e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=9.111e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=5.866e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.235e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.885e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=6.589e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.77it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.74it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.76it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.74it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.76it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Training epochs:  34%|â–ˆâ–ˆâ–ˆâ–      | 11/32 [03:58<07:35, 21.68s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.85it/s]
Epoch 11/32 - Train Loss: 48.029554 - Test Loss: 43.392829

Epoch 12/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  34%|â–ˆâ–ˆâ–ˆâ–      | 11/32 [03:58<07:35, 21.68s/it]
Epoch 12/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 12/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 12/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.55s/it][A
Epoch 12/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:17,  1.55s/it][A
Epoch 12/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A

Epoch 12/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][AEpoch 12/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A

Epoch 12/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][AEpoch 12/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 12/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 12/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A

Epoch 12/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][AEpoch 12/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A

Epoch 12/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][AEpoch 12/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 12/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 12/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 12/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 12/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 12/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 12/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A

Epoch 12/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][AEpoch 12/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A

Epoch 12/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][AEpoch 12/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A

Epoch 12/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 12/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 12/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=5.0] Epoch 12 summary:
Epoch 12/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]  input  std: mean=1.814e+00

  layer model_7__forward_module.module.conv1 act-std: mean=9.159e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.014e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.150e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.669e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.498e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.902e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.704e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.034e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.448e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.530e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.065e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.145e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.579e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.364e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.279e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.863e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=6.543e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.614e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.489e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=9.860e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.181e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.275e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.404e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=5.269e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.166e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.420e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=5.759e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=6.046e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.327e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.925e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=6.576e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=4.528e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=9.814e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.947e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=5.743e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=4.586e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=9.886e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=4.076e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=8.016e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=6.625e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.412e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=7.219e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=9.129e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=5.862e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.235e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.883e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=6.577e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.76it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.75it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Epoch 12/32 - Train Loss: 48.126293 - Test Loss: 43.392553
Training epochs:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 12/32 [04:19<07:13, 21.69s/it]
Training epochs:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 12/32 [04:19<07:13, 21.68s/it]Epoch 13/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 13/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 13/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 13/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 13/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it]
[AEpoch 13/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A

Epoch 13/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it]Epoch 13/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A[A
Epoch 13/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 13/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 13/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 13/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 13/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 13/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A

Epoch 13/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][AEpoch 13/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 13/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 13/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 13/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.58s/it][A
Epoch 13/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.58s/it][A

Epoch 13/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.57s/it][AEpoch 13/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.57s/it][A
Epoch 13/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.55s/it][A
Epoch 13/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.55s/it][A
Epoch 13/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 13/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.55s/it][A
Epoch 13/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 13/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=5.0] Epoch 13 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.160e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.014e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.150e+00

  layer model_6__forward_module.module.conv2 act-std: mean=2.668e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.498e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.902e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.705e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.034e+00
Epoch 13/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it]  layer model_3__forward_module.module.conv1 act-std: mean=6.447e-01[A
  layer model_3__forward_module.module.conv2 act-std: mean=3.530e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.065e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.144e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.578e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.364e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.279e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.846e+00
Epoch 13/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]  param model_0__forward_module.module.conv1.bias grad-norm: mean=6.501e-01

  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.613e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.470e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=9.906e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.184e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.270e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.393e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=5.238e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.159e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.415e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=5.721e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=6.039e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.326e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.927e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=6.568e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=4.536e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=9.828e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.952e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=5.747e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=4.582e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=9.870e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=4.077e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=8.012e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=6.597e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.407e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=7.191e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=9.097e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=5.851e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.232e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.874e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=6.560e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A

Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][AEvaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.76it/s][A

Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][AEvaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Epoch 13/32 - Train Loss: 48.032808 - Test Loss: 43.392297

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Training epochs:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 13/32 [04:41<06:52, 21.72s/it]
Epoch 14/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 13/32 [04:41<06:52, 21.72s/it]
Epoch 14/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 14/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][AEpoch 14/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][A

Epoch 14/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][AEpoch 14/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A

Epoch 14/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][AEpoch 14/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A

Epoch 14/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][AEpoch 14/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 14/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 14/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A

Epoch 14/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][AEpoch 14/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 14/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 14/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 14/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 14/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A

Epoch 14/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][AEpoch 14/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 14/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 14/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 14/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 14/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 14/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 14/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 14/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 14/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

Epoch 14/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 14/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=5.0] Epoch 14 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.159e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.013e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.150e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.668e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.498e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.900e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.704e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.034e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.448e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.530e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.065e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.144e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.579e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.364e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.279e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.865e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=6.549e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.612e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.494e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=9.834e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.175e-01

  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.281e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.421e-01Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  param model_2__forward_module.module.conv1.weight grad-norm: mean=5.232e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.158e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.410e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=5.721e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=6.031e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.324e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.927e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=6.573e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=4.526e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=9.813e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.940e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=5.730e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=4.588e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=9.893e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=4.080e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=8.021e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=6.596e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.406e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=7.184e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=9.088e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=5.848e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.232e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.874e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=6.567e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.75it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.76it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Epoch 14/32 - Train Loss: 48.066472 - Test Loss: 43.392023
Training epochs:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 14/32 [05:03<06:30, 21.69s/it]Training epochs:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 14/32 [05:03<06:30, 21.69s/it]
Epoch 15/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 15/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 15/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it]
[AEpoch 15/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A

Epoch 15/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][AEpoch 15/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 15/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 15/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 15/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 15/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 15/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 15/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A

Epoch 15/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][AEpoch 15/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A

Epoch 15/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][AEpoch 15/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 15/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 15/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 15/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 15/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A

Epoch 15/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][AEpoch 15/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A

Epoch 15/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][AEpoch 15/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 15/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 15/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 15/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 15/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=5.0] Epoch 15 summary:
  input  std: mean=1.813e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.160e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.013e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.150e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.668e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.498e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.902e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.704e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.034e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.448e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.529e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.065e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.143e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.578e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.364e+00

  layer model_0__forward_module.module.conv2 act-std: mean=8.280e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.859e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=6.531e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.615e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.481e-01
Epoch 15/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it]  param model_1__forward_module.module.conv1.weight grad-norm: mean=9.856e-01[A
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.176e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.275e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.404e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=5.236e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.159e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.409e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=5.723e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=6.025e+00
Epoch 15/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.323e+00

  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.924e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=6.562e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=4.535e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=9.827e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.949e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=5.747e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=4.590e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=9.897e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=4.081e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=8.027e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=6.598e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.407e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=7.189e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=9.095e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=5.846e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.231e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.871e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=6.560e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A

Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A[A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Epoch 15/32 - Train Loss: 48.015569 - Test Loss: 43.391764
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Training epochs:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 15/32 [05:25<06:08, 21.67s/it]Training epochs:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 15/32 [05:25<06:08, 21.68s/it]
Epoch 16/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 16/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 16/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 16/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 16/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 16/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 16/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 16/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A

Epoch 16/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][AEpoch 16/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 16/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 16/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 16/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 16/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A

Epoch 16/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][AEpoch 16/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 16/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 16/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A

Epoch 16/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it]Epoch 16/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A[A

Epoch 16/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][AEpoch 16/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 16/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 16/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 16/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 16/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 16/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 16/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=5.0] Epoch 16 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.159e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.014e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.150e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.668e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.498e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.902e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.703e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.034e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.447e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.529e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.065e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.143e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00

  layer model_1__forward_module.module.conv2 act-std: mean=1.578e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.364e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.279e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.856e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=6.527e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.613e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.492e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=9.802e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.167e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.278e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.416e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=5.249e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.161e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.417e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=5.737e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=6.025e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.322e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.923e+00
Epoch 16/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it]  param model_3__forward_module.module.conv2.bias grad-norm: mean=6.558e-01[A
  param model_4__forward_module.module.conv1.weight grad-norm: mean=4.534e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=9.826e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.955e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=5.749e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=4.578e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=9.871e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=4.074e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=8.007e-01
Epoch 16/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]  param model_6__forward_module.module.conv1.weight grad-norm: mean=6.591e+00

  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.405e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=7.186e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=9.089e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=5.828e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.228e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.873e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=6.558e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.77it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.76it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Epoch 16/32 - Train Loss: 48.063539 - Test Loss: 43.391480
Training epochs:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 16/32 [05:46<05:46, 21.66s/it]
Epoch 17/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 16/32 [05:46<05:46, 21.66s/it]
Epoch 17/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 17/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][A
Epoch 17/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 17/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 17/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A

Epoch 17/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][AEpoch 17/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 17/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 17/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A

Epoch 17/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][AEpoch 17/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A

Epoch 17/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][AEpoch 17/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 17/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it]
[AEpoch 17/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 17/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 17/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 17/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 17/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A

Epoch 17/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][AEpoch 17/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 17/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 17/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 17/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 17/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A

Epoch 17/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 17/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 17/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]
Epoch 17/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=5.0] Epoch 17 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.159e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.013e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.150e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.669e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.498e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.902e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.705e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.035e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.448e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.530e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.065e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.144e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.578e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.364e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.281e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.862e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=6.541e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.617e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.494e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=9.847e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.172e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.283e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.414e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=5.233e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.158e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.417e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=5.724e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=6.025e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.323e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.924e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=6.556e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=4.517e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=9.790e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.940e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=5.728e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=4.601e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=9.921e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=4.094e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=8.050e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=6.591e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.406e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=7.169e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=9.073e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=5.866e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.236e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.885e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=6.584e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A

Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][AEvaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.81it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.96it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]
Epoch 17/32 - Train Loss: 48.069119 - Test Loss: 43.391243

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]
Training epochs:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 17/32 [06:08<05:24, 21.63s/it]
Epoch 18/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 17/32 [06:08<05:24, 21.64s/it]
Epoch 18/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 18/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 18/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 18/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 18/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A

Epoch 18/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][AEpoch 18/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A

Epoch 18/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][AEpoch 18/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A

Epoch 18/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][AEpoch 18/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 18/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 18/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 18/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 18/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 18/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 18/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 18/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 18/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 18/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 18/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 18/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 18/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 18/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 18/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 18/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 18/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

Epoch 18/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 18/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=5.0] Epoch 18 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.159e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.014e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.150e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.669e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.498e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.902e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.704e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.035e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.448e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.530e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.065e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.144e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.579e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.364e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.280e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.855e+00

  param model_0__forward_module.module.conv1.bias grad-norm: mean=6.523e-01
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.615e+00[A
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.489e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=9.777e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.162e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.280e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.421e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=5.249e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.161e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.416e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=5.736e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=6.050e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.328e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.928e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=6.582e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=4.519e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=9.798e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.932e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=5.721e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=4.591e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=9.901e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=4.081e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=8.028e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=6.624e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.413e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=7.204e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=9.115e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=5.845e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.231e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.864e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=6.552e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Epoch 18/32 - Train Loss: 48.088605 - Test Loss: 43.390961
Training epochs:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 18/32 [06:29<05:02, 21.62s/it]
Epoch 19/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 18/32 [06:29<05:02, 21.62s/it]
Epoch 19/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 19/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 19/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A

Epoch 19/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][AEpoch 19/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 19/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 19/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 19/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 19/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 19/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 19/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A

Epoch 19/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][AEpoch 19/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A

Epoch 19/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][AEpoch 19/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A

Epoch 19/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][AEpoch 19/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A

Epoch 19/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][AEpoch 19/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 19/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 19/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 19/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 19/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 19/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 19/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 19/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 19/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=5.0] Epoch 19 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.160e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.016e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.150e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.668e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.498e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.904e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.704e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.035e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.448e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.531e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.065e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.145e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.579e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.364e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.281e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.847e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=6.504e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.610e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.469e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=9.846e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.177e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.272e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.403e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=5.241e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.160e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.414e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=5.733e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=6.056e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.329e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.924e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=6.590e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=4.534e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=9.829e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.947e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=5.745e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=4.573e+00

  param model_5__forward_module.module.conv1.bias grad-norm: mean=9.859e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=4.066e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=7.995e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=6.594e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.406e+00
Epoch 19/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it]  param model_6__forward_module.module.conv2.weight grad-norm: mean=7.176e+00[A
  param model_6__forward_module.module.conv2.bias grad-norm: mean=9.075e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=5.846e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.232e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.872e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=6.563e-01
Epoch 19/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A

Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][AEvaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.82it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.81it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.81it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.97it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]
Epoch 19/32 - Train Loss: 48.088313 - Test Loss: 43.390701

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.96it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]
Training epochs:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 19/32 [06:51<04:41, 21.62s/it]Training epochs:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 19/32 [06:51<04:41, 21.62s/it]
Epoch 20/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 20/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 20/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][A
Epoch 20/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][A

Epoch 20/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][AEpoch 20/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 20/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 20/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A

Epoch 20/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][AEpoch 20/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A

Epoch 20/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][AEpoch 20/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 20/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 20/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 20/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 20/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 20/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 20/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 20/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 20/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A

Epoch 20/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][AEpoch 20/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 20/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 20/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 20/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 20/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A

Epoch 20/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 20/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]
Epoch 20/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it]
[Î²=5.0] Epoch 20 summary:[A
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.157e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.011e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.150e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.668e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.498e+00Epoch 20/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

  layer model_5__forward_module.module.conv2 act-std: mean=8.899e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.703e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.034e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.447e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.528e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.065e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.143e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.578e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.364e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.278e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.858e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=6.533e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.606e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.479e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=9.738e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.156e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.272e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.409e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=5.235e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.158e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.412e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=5.725e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=6.035e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.325e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.922e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=6.564e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=4.504e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=9.763e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.926e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=5.709e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=4.584e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=9.884e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=4.079e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=8.021e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=6.574e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.402e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=7.164e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=9.064e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=5.842e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.231e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.864e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=6.547e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.84it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.82it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.82it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.82it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]
Epoch 20/32 - Train Loss: 48.021258 - Test Loss: 43.390447

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]
Training epochs:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 20/32 [07:12<04:19, 21.59s/it]
Epoch 21/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 20/32 [07:12<04:19, 21.59s/it]
Epoch 21/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 21/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][A
Epoch 21/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 21/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 21/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 21/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 21/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 21/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 21/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A

Epoch 21/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][AEpoch 21/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 21/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 21/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 21/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 21/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 21/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 21/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A

Epoch 21/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][AEpoch 21/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 21/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 21/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A

Epoch 21/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.58s/it]Epoch 21/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.58s/it][A[A
Epoch 21/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.56s/it][A
Epoch 21/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.56s/it][A
Epoch 21/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.44s/it][AEpoch 21/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=5.0] Epoch 21 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.159e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.013e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.150e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.668e-01

  layer model_5__forward_module.module.conv1 act-std: mean=1.498e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.901e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.703e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.034e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.448e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.530e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.065e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.144e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.579e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.364e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.281e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.851e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=6.518e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.605e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.475e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=9.749e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.159e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.262e+00
Epoch 21/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.44s/it]  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.391e-01[A
  param model_2__forward_module.module.conv1.weight grad-norm: mean=5.231e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.157e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.411e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=5.717e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=6.020e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.322e+00Epoch 21/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.923e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=6.557e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=4.516e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=9.789e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.936e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=5.729e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=4.576e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=9.865e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=4.066e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=7.994e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=6.579e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.403e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=7.163e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=9.062e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=5.832e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.229e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.864e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=6.541e-01


Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][AEvaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A

Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][AEvaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Epoch 21/32 - Train Loss: 48.060608 - Test Loss: 43.390207

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Training epochs:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 21/32 [07:34<03:58, 21.65s/it]
Epoch 22/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 21/32 [07:34<03:58, 21.65s/it]
Epoch 22/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 22/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][A
Epoch 22/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 22/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it]
[AEpoch 22/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A

Epoch 22/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][AEpoch 22/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 22/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 22/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 22/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 22/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 22/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 22/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A

Epoch 22/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][AEpoch 22/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 22/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 22/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A

Epoch 22/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][AEpoch 22/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A

Epoch 22/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][AEpoch 22/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A

Epoch 22/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][AEpoch 22/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 22/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 22/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 22/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 22/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=5.0] Epoch 22 summary:

  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.159e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.014e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.150e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.669e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.498e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.905e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.703e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.035e+00
Epoch 22/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it]  layer model_3__forward_module.module.conv1 act-std: mean=6.447e-01[A
  layer model_3__forward_module.module.conv2 act-std: mean=3.529e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.065e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.143e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.579e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.364e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.280e-01Epoch 22/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.848e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=6.510e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.608e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.473e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=9.739e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.155e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.266e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.392e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=5.226e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.156e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.408e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=5.708e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=6.010e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.319e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.918e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=6.539e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=4.518e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=9.794e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.940e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=5.723e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=4.584e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=9.882e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=4.074e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=8.011e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=6.578e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.402e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=7.156e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=9.052e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=5.832e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.228e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.862e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=6.539e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.81it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.81it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Epoch 22/32 - Train Loss: 48.077834 - Test Loss: 43.389982
Training epochs:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 22/32 [07:56<03:36, 21.63s/it]
Epoch 23/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 22/32 [07:56<03:36, 21.63s/it]
Epoch 23/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 23/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][AEpoch 23/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A

Epoch 23/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][AEpoch 23/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 23/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 23/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 23/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 23/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A

Epoch 23/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][AEpoch 23/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 23/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 23/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 23/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 23/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A

Epoch 23/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it]Epoch 23/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A[A

Epoch 23/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][AEpoch 23/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 23/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 23/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 23/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 23/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 23/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 23/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 23/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 23/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=5.0] Epoch 23 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.158e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.013e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.150e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.668e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.498e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.900e-01

  layer model_4__forward_module.module.conv1 act-std: mean=9.705e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.034e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.448e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.530e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.065e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.144e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.578e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.364e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.277e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.845e+00Epoch 23/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it]
[A  param model_0__forward_module.module.conv1.bias grad-norm: mean=6.507e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.603e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.468e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=9.759e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.161e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.261e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.387e-01Epoch 23/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

  param model_2__forward_module.module.conv1.weight grad-norm: mean=5.220e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.155e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.409e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=5.704e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=6.014e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.320e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.915e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=6.544e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=4.531e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=9.821e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.938e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=5.736e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=4.581e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=9.877e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=4.071e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=8.010e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=6.592e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.406e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=7.177e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=9.075e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=5.835e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.230e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.864e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=6.536e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.76it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Epoch 23/32 - Train Loss: 48.043753 - Test Loss: 43.389741
Training epochs:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 23/32 [08:17<03:14, 21.63s/it]Training epochs:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 23/32 [08:17<03:14, 21.63s/it]
Epoch 24/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 24/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 24/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 24/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 24/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 24/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 24/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 24/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A

Epoch 24/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][AEpoch 24/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 24/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 24/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A

Epoch 24/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][AEpoch 24/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 24/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 24/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A

Epoch 24/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][AEpoch 24/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 24/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 24/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 24/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 24/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 24/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 24/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 24/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 24/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 24/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][A
Epoch 24/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]
Epoch 24/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][A
[Î²=5.0] Epoch 24 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.159e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.015e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.150e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.669e-01
Epoch 24/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]  layer model_5__forward_module.module.conv1 act-std: mean=1.498e+00

  layer model_5__forward_module.module.conv2 act-std: mean=8.904e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.704e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.034e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.447e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.530e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.065e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.145e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.579e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.364e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.279e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.843e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=6.501e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.603e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.464e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=9.799e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.167e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.276e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.410e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=5.209e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.153e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.404e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=5.691e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=6.010e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.320e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.915e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=6.539e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=4.528e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=9.813e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.941e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=5.729e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=4.583e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=9.879e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=4.070e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=8.003e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=6.602e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.408e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=7.172e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=9.077e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=5.832e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.229e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.867e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=6.549e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Epoch 24/32 - Train Loss: 48.106343 - Test Loss: 43.389503
Training epochs:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 24/32 [08:39<02:53, 21.63s/it]Training epochs:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 24/32 [08:39<02:53, 21.63s/it]
Epoch 25/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 25/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 25/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 25/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 25/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 25/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 25/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 25/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 25/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 25/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 25/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 25/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A

Epoch 25/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][AEpoch 25/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A

Epoch 25/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][AEpoch 25/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 25/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 25/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 25/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 25/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 25/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 25/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 25/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 25/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 25/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 25/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A

Epoch 25/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 25/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 25/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

[Î²=5.0] Epoch 25 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.159e-01
Epoch 25/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]  layer model_7__forward_module.module.conv2 act-std: mean=7.013e-01

  layer model_6__forward_module.module.conv1 act-std: mean=1.150e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.668e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.498e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.902e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.704e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.035e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.448e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.530e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.065e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.143e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.579e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.364e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.280e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.845e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=6.503e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.611e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.471e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=9.747e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.158e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.266e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.392e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=5.202e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.151e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.412e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=5.694e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=5.979e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.313e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.915e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=6.517e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=4.518e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=9.791e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.936e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=5.725e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=4.575e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=9.861e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=4.064e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=7.996e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=6.595e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.406e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=7.182e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=9.081e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=5.830e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.228e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.868e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=6.550e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:02,  1.35it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.58it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.69it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Epoch 25/32 - Train Loss: 48.057640 - Test Loss: 43.389263
Training epochs:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 25/32 [09:01<02:31, 21.61s/it]
Epoch 26/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.84it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.73it/s]
Training epochs:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 25/32 [09:01<02:31, 21.67s/it]
Epoch 26/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 26/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.50s/it][AEpoch 26/32:   8%|â–Š         | 1/13 [00:01<00:20,  1.69s/it][A

Epoch 26/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:17,  1.59s/it][AEpoch 26/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.51s/it][A

Epoch 26/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.56s/it][AEpoch 26/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 26/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 26/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.55s/it][A
Epoch 26/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 26/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A

Epoch 26/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][AEpoch 26/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 26/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 26/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A

Epoch 26/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][AEpoch 26/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 26/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 26/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 26/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 26/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A

Epoch 26/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][AEpoch 26/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A

Epoch 26/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][AEpoch 26/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 26/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 26/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]


[Î²=5.0] Epoch 26 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.160e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.014e-01
Epoch 26/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it]  layer model_6__forward_module.module.conv1 act-std: mean=1.150e+00[A
  layer model_6__forward_module.module.conv2 act-std: mean=2.668e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.498e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.903e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.704e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.034e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.448e-01
Epoch 26/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]  layer model_3__forward_module.module.conv2 act-std: mean=3.531e-01

  layer model_2__forward_module.module.conv1 act-std: mean=1.065e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.145e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.579e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.364e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.279e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.850e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=6.517e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.604e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.466e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=9.728e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.153e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.265e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.393e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=5.219e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.155e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.408e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=5.701e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=6.015e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.320e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.918e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=6.545e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=4.508e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=9.772e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.931e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=5.716e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=4.585e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=9.887e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=4.081e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=8.025e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=6.568e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.401e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=7.154e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=9.047e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=5.837e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.230e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.869e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=6.554e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Epoch 26/32 - Train Loss: 48.067316 - Test Loss: 43.389029

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Training epochs:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 26/32 [09:22<02:10, 21.67s/it]
Epoch 27/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 26/32 [09:22<02:09, 21.66s/it]
Epoch 27/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 27/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 27/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 27/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 27/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 27/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 27/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 27/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 27/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A

Epoch 27/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][AEpoch 27/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 27/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 27/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A

Epoch 27/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][AEpoch 27/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A

Epoch 27/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][AEpoch 27/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 27/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 27/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 27/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 27/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A

Epoch 27/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][AEpoch 27/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 27/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 27/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 27/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 27/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

Epoch 27/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 27/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=5.0] Epoch 27 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.159e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.015e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.150e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.668e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.498e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.902e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.705e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.034e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.449e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.533e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.065e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.146e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.579e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.364e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.281e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.850e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=6.516e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.609e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.481e-01

  param model_1__forward_module.module.conv1.weight grad-norm: mean=9.792e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.169e-01Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.276e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.407e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=5.218e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.155e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.415e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=5.706e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=6.050e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.328e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.924e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=6.580e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=4.505e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=9.768e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.923e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=5.705e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=4.569e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=9.853e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=4.058e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=7.983e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=6.574e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.402e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=7.138e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=9.031e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=5.826e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.228e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.864e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=6.538e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.76it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Training epochs:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 27/32 [09:44<01:48, 21.64s/it]
Epoch 28/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Epoch 27/32 - Train Loss: 48.092996 - Test Loss: 43.388775
Training epochs:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 27/32 [09:44<01:48, 21.66s/it]
Epoch 28/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 28/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.55s/it][AEpoch 28/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A

Epoch 28/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][AEpoch 28/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 28/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 28/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A

Epoch 28/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][AEpoch 28/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A

Epoch 28/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][AEpoch 28/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 28/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 28/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 28/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 28/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 28/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 28/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A

Epoch 28/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][AEpoch 28/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 28/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 28/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 28/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 28/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A

Epoch 28/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][AEpoch 28/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 28/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 28/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=5.0] Epoch 28 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.159e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.014e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.150e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.668e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.498e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.905e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.703e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.035e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.449e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.532e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.065e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.145e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.579e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.364e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.282e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.837e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=6.490e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.595e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.457e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=9.695e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.148e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.261e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.387e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=5.202e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.151e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.404e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=5.688e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=5.992e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.316e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.910e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=6.522e-01

  param model_4__forward_module.module.conv1.weight grad-norm: mean=4.499e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=9.753e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.915e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=5.698e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=4.578e+00
Epoch 28/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it]  param model_5__forward_module.module.conv1.bias grad-norm: mean=9.872e-01[A
  param model_5__forward_module.module.conv2.weight grad-norm: mean=4.073e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=8.013e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=6.548e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.396e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=7.119e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=9.007e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=5.846e+00Epoch 28/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.232e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.869e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=6.558e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A

Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.82it/s][AEvaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.82it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.96it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]
Epoch 28/32 - Train Loss: 48.069605 - Test Loss: 43.388598

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]
Training epochs:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 28/32 [10:06<01:26, 21.63s/it]
Epoch 29/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 28/32 [10:06<01:26, 21.63s/it]
Epoch 29/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 29/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 29/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][A
Epoch 29/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.51s/it][A
Epoch 29/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 29/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 29/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A

Epoch 29/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][AEpoch 29/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 29/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 29/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A

Epoch 29/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][AEpoch 29/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A

Epoch 29/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][AEpoch 29/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 29/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 29/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 29/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 29/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A

Epoch 29/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.58s/it]Epoch 29/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.58s/it][A[A
Epoch 29/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.56s/it][A
Epoch 29/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.56s/it][A

Epoch 29/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.55s/it][AEpoch 29/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.55s/it][A

Epoch 29/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.43s/it]Epoch 29/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.43s/it][A[AEpoch 29/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]
Epoch 29/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=5.0] Epoch 29 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.161e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.015e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.150e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.668e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.498e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.907e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.704e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.035e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.448e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.531e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.065e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.145e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.579e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.364e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.284e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.832e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=6.474e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.599e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.450e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=9.680e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.142e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.262e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.383e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=5.204e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.152e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.408e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=5.690e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=5.994e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.316e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.916e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=6.525e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=4.507e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=9.770e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.931e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=5.719e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=4.562e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=9.833e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=4.054e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=7.974e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=6.558e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.399e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=7.141e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=9.034e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=5.814e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.225e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.855e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=6.523e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.77it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.81it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Epoch 29/32 - Train Loss: 48.103078 - Test Loss: 43.388385
Training epochs:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 29/32 [10:27<01:05, 21.68s/it]Training epochs:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 29/32 [10:27<01:05, 21.68s/it]
Epoch 30/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 30/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 30/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 30/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 30/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 30/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 30/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 30/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 30/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 30/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 30/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 30/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 30/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 30/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 30/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 30/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A

Epoch 30/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it]Epoch 30/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A[A
Epoch 30/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 30/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 30/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 30/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A

Epoch 30/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][AEpoch 30/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 30/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 30/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 30/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 30/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=5.0] Epoch 30 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.159e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.015e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.150e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.669e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.498e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.904e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.703e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.035e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.448e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.531e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.065e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.145e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00

  layer model_1__forward_module.module.conv2 act-std: mean=1.579e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.364e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.281e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.852e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=6.519e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.608e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.478e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=9.685e-01Epoch 30/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it]
[A  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.143e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.263e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.387e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=5.205e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.152e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.402e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=5.689e-01Epoch 30/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

  param model_3__forward_module.module.conv1.weight grad-norm: mean=5.974e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.312e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.907e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=6.507e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=4.513e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=9.781e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.929e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=5.716e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=4.577e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=9.867e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=4.063e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=7.989e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=6.558e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.399e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=7.136e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=9.032e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=5.829e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.228e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.863e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=6.546e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.84it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.83it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.81it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]

Training epochs:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 30/32 [10:49<00:43, 21.67s/it]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Epoch 30/32 - Train Loss: 48.083014 - Test Loss: 43.388223

Epoch 31/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 30/32 [10:49<00:43, 21.67s/it]
Epoch 31/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 31/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 31/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 31/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 31/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A

Epoch 31/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][AEpoch 31/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 31/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 31/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 31/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 31/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 31/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 31/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A

Epoch 31/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][AEpoch 31/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A

Epoch 31/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][AEpoch 31/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 31/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 31/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A

Epoch 31/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][AEpoch 31/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 31/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 31/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 31/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 31/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A

Epoch 31/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 31/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=5.0] Epoch 31 summary:
  input  std: mean=1.813e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.160e-01Epoch 31/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it]
[A  layer model_7__forward_module.module.conv2 act-std: mean=7.015e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.150e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.668e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.498e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.904e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.703e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.035e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.449e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.531e-01
Epoch 31/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]  layer model_2__forward_module.module.conv1 act-std: mean=1.065e+00

  layer model_2__forward_module.module.conv2 act-std: mean=4.146e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.579e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.364e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.283e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.843e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=6.499e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.612e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.474e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=9.813e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.169e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.270e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.397e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=5.190e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.149e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.405e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=5.675e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=5.967e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.310e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.911e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=6.491e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=4.517e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=9.788e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.940e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=5.730e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=4.571e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=9.851e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=4.066e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=7.992e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=6.569e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.401e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=7.154e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=9.049e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=5.819e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.225e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.866e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=6.533e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.75it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.74it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.76it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.74it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]

Epoch 31/32 - Train Loss: 48.059295 - Test Loss: 43.387994
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Training epochs:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 31/32 [11:11<00:21, 21.66s/it]Training epochs:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 31/32 [11:11<00:21, 21.65s/it]
Epoch 32/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 32/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 32/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][AEpoch 32/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 32/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 32/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 32/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 32/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 32/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it]
[AEpoch 32/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A

Epoch 32/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][AEpoch 32/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A

Epoch 32/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][AEpoch 32/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 32/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 32/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 32/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 32/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 32/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 32/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A

Epoch 32/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][AEpoch 32/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 32/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 32/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 32/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 32/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 32/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.45s/it][AEpoch 32/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

Epoch 32/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.45s/it][AEpoch 32/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=5.0] Epoch 32 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.158e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.015e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.150e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.668e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.498e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.903e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.704e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.035e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.448e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.531e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.065e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.146e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.579e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.364e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.283e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.838e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=6.490e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.601e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.463e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=9.669e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.144e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.261e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.382e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=5.209e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.153e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.404e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=5.689e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=5.996e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.317e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=1.914e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=6.533e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=4.506e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=9.768e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.922e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=5.711e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=4.582e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=9.881e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=4.068e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=8.002e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=6.577e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.402e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=7.142e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=9.041e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=5.828e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.228e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.858e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=6.529e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.83it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.82it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.83it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.83it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.81it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.81it/s][A

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.45it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.45it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.55it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.55it/s]

Epoch 32/32 - Train Loss: 47.968625 - Test Loss: 43.387744
Training epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [11:33<00:00, 21.91s/it]Training epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [11:33<00:00, 21.68s/it]
Training epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [11:33<00:00, 21.91s/it]Training epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [11:33<00:00, 21.68s/it]
Loaded best models from epoch 32 with loss 43.404611

>>> Completed beta = 5.0
>>> Time for this beta: 0:11:34
>>> Total elapsed time: 1:09:15
==================================================
Loaded data shape: torch.Size([4096, 2, 64, 64])
Training data shape: torch.Size([3276, 2, 64, 64])
Testing data shape: torch.Size([820, 2, 64, 64])

>>> Training the model at beta =  5.5
Training epochs:   0%|          | 0/32 [00:00<?, ?it/s]
>>> Training the model at beta = 5.5

Training epochs:   0%|          | 0/32 [00:00<?, ?it/s]
Epoch 1/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 1/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 1/32:   8%|â–Š         | 1/13 [00:01<00:22,  1.84s/it][AEpoch 1/32:   8%|â–Š         | 1/13 [00:01<00:22,  1.84s/it][A
Epoch 1/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:18,  1.65s/it][A
Epoch 1/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:18,  1.65s/it][A
Epoch 1/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:16,  1.60s/it][A
Epoch 1/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:16,  1.61s/it][A
Epoch 1/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:14,  1.57s/it][A
Epoch 1/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:14,  1.57s/it][A
Epoch 1/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.55s/it][A
Epoch 1/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.55s/it][A
Epoch 1/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.55s/it][A
Epoch 1/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.55s/it][A
Epoch 1/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 1/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 1/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 1/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 1/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:14<00:06,  1.53s/it][A
Epoch 1/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:14<00:06,  1.53s/it][A
Epoch 1/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 1/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A

Epoch 1/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:17<00:03,  1.53s/it][AEpoch 1/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:17<00:03,  1.53s/it][A
Epoch 1/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 1/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A

Epoch 1/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 1/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 1/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.52s/it]
Epoch 1/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.52s/it]

[Î²=5.5] Epoch 1 summary:
  input  std: mean=1.813e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.055e-01
  layer model_7__forward_module.module.conv2 act-std: mean=6.856e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.148e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.619e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.505e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.682e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.624e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.011e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.360e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.387e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.067e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.006e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.239e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.542e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.370e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.082e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=4.370e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=9.879e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.347e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=5.206e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.567e+00
  param model_1__forward_module.module.conv1.bias grad-norm: mean=3.476e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.007e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.979e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=7.095e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.555e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.878e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=7.668e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=8.846e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.911e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.658e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=9.531e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=6.381e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.367e+00
  param model_4__forward_module.module.conv2.weight grad-norm: mean=5.378e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=7.883e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=6.507e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.395e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=5.697e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.124e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=9.093e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.913e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.004e+01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.259e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=8.017e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.680e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.838e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=8.987e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.84it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.83it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]
Training epochs:   3%|â–Ž         | 1/32 [00:21<11:17, 21.87s/it]
Epoch 2/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Epoch 1/32 - Train Loss: 49.903822 - Test Loss: 44.958784
Training epochs:   3%|â–Ž         | 1/32 [00:21<11:18, 21.88s/it]
Epoch 2/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 2/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 2/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][A
Epoch 2/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 2/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 2/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 2/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 2/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 2/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 2/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 2/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 2/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 2/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 2/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 2/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 2/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 2/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 2/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 2/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 2/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 2/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A

Epoch 2/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it]Epoch 2/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A[A
Epoch 2/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 2/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 2/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 2/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]


[Î²=5.5] Epoch 2 summary:
  input  std: mean=1.813e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.055e-01
  layer model_7__forward_module.module.conv2 act-std: mean=6.856e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.148e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.619e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.505e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.682e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.625e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.011e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.359e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.387e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.067e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.006e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.239e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.542e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.370e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.083e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=4.369e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=9.874e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.346e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=5.198e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.569e+00
  param model_1__forward_module.module.conv1.bias grad-norm: mean=3.478e-01Epoch 2/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it]
[A  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.008e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.977e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=7.099e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.555e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.894e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=7.656e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=8.862e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.914e+00
Epoch 2/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.668e+00

  param model_3__forward_module.module.conv2.bias grad-norm: mean=9.540e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=6.380e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.366e+00
  param model_4__forward_module.module.conv2.weight grad-norm: mean=5.380e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=7.883e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=6.496e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.392e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=5.685e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.121e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=9.083e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.911e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.002e+01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.257e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=8.010e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.678e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.840e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=8.982e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.84it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.83it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.83it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.81it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.96it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s]
Training epochs:   6%|â–‹         | 2/32 [00:43<10:50, 21.67s/it]
Epoch 3/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]
Epoch 2/32 - Train Loss: 49.862364 - Test Loss: 44.958385
Training epochs:   6%|â–‹         | 2/32 [00:43<10:50, 21.68s/it]
Epoch 3/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 3/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 3/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.56s/it][A
Epoch 3/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 3/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 3/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 3/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 3/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 3/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 3/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 3/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 3/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 3/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A

Epoch 3/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it]Epoch 3/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A[A
Epoch 3/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 3/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 3/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 3/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 3/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 3/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 3/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 3/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A

Epoch 3/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][AEpoch 3/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A

Epoch 3/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 3/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 3/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

[Î²=5.5] Epoch 3 summary:
  input  std: mean=1.813e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.054e-01
  layer model_7__forward_module.module.conv2 act-std: mean=6.855e-01Epoch 3/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

  layer model_6__forward_module.module.conv1 act-std: mean=1.148e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.619e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.505e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.682e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.625e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.011e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.360e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.388e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.067e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.007e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.239e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.542e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.370e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.082e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=4.356e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=9.844e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.341e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=5.182e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.567e+00
  param model_1__forward_module.module.conv1.bias grad-norm: mean=3.475e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.004e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.965e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=7.066e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.545e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.893e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=7.607e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=8.831e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.907e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.662e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=9.504e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=6.377e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.366e+00
  param model_4__forward_module.module.conv2.weight grad-norm: mean=5.373e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=7.877e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=6.498e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.392e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=5.690e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.122e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=9.093e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.912e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.004e+01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.259e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=8.007e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.677e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.853e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=8.997e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.87it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.87it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.82it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.82it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.83it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.81it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.99it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.98it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s]
Epoch 3/32 - Train Loss: 49.951216 - Test Loss: 44.957969
Training epochs:   9%|â–‰         | 3/32 [01:04<10:26, 21.61s/it]
Epoch 4/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:   9%|â–‰         | 3/32 [01:04<10:26, 21.61s/it]
Epoch 4/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 4/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][AEpoch 4/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 4/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 4/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 4/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 4/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A

Epoch 4/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][AEpoch 4/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A

Epoch 4/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][AEpoch 4/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A

Epoch 4/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][AEpoch 4/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A

Epoch 4/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][AEpoch 4/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A

Epoch 4/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it]Epoch 4/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A[A
Epoch 4/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 4/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 4/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 4/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 4/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 4/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 4/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 4/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 4/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 4/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

[Î²=5.5] Epoch 4 summary:
  input  std: mean=1.813e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.057e-01
  layer model_7__forward_module.module.conv2 act-std: mean=6.857e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.148e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.619e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.505e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.685e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.625e-01

  layer model_4__forward_module.module.conv2 act-std: mean=2.011e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.360e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.389e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.067e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.007e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.239e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.542e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.370e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.085e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=4.363e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=9.863e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.343e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=5.198e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.565e+00
  param model_1__forward_module.module.conv1.bias grad-norm: mean=3.474e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.998e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.963e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=7.079e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.552e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.880e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=7.646e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=8.851e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.912e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.658e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=9.530e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=6.380e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.366e+00
  param model_4__forward_module.module.conv2.weight grad-norm: mean=5.375e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=7.875e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=6.508e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.395e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=5.699e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.124e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=9.101e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.915e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.004e+01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.261e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=8.005e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.676e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.836e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=8.980e-01
Epoch 4/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 4/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Epoch 4/32 - Train Loss: 49.935295 - Test Loss: 44.957555

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Training epochs:  12%|â–ˆâ–Ž        | 4/32 [01:26<10:03, 21.57s/it]
Epoch 5/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  12%|â–ˆâ–Ž        | 4/32 [01:26<10:04, 21.58s/it]
Epoch 5/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 5/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 5/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A

Epoch 5/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.51s/it][AEpoch 5/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 5/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 5/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A

Epoch 5/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][AEpoch 5/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 5/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 5/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A

Epoch 5/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][AEpoch 5/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A

Epoch 5/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:11<00:10,  1.68s/it][AEpoch 5/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:11<00:10,  1.68s/it][A

Epoch 5/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:08,  1.63s/it][AEpoch 5/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:08,  1.63s/it][A

Epoch 5/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:14<00:06,  1.60s/it][AEpoch 5/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:14<00:06,  1.60s/it][A

Epoch 5/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.57s/it][AEpoch 5/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.57s/it][A
Epoch 5/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:17<00:03,  1.56s/it][A
Epoch 5/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:17<00:03,  1.56s/it][A

Epoch 5/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.55s/it][AEpoch 5/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.55s/it][A
Epoch 5/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 5/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.53s/it]

[Î²=5.5] Epoch 5 summary:
  input  std: mean=1.813e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.054e-01
  layer model_7__forward_module.module.conv2 act-std: mean=6.855e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.148e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.619e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.505e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.682e-01

  layer model_4__forward_module.module.conv1 act-std: mean=9.623e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.012e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.360e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.387e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.067e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.006e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.239e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.541e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.370e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.081e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=4.350e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=9.832e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.335e+00Epoch 5/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it]
[A  param model_0__forward_module.module.conv2.bias grad-norm: mean=5.172e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.564e+00
  param model_1__forward_module.module.conv1.bias grad-norm: mean=3.469e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.002e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.960e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=7.063e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.548e+00
Epoch 5/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.53s/it]  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.880e+00

  param model_2__forward_module.module.conv2.bias grad-norm: mean=7.621e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=8.836e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.908e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.656e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=9.513e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=6.367e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.363e+00
  param model_4__forward_module.module.conv2.weight grad-norm: mean=5.366e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=7.865e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=6.492e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.391e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=5.688e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.121e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=9.078e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.909e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.002e+01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.257e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=7.998e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.675e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.830e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=8.973e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A

Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.82it/s][AEvaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.82it/s][A

Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.82it/s][AEvaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.82it/s][A

Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.83it/s][AEvaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.83it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.96it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.96it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]
Epoch 5/32 - Train Loss: 49.860105 - Test Loss: 44.957166
Training epochs:  16%|â–ˆâ–Œ        | 5/32 [01:48<09:46, 21.73s/it]
Epoch 6/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  16%|â–ˆâ–Œ        | 5/32 [01:48<09:46, 21.73s/it]
Epoch 6/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 6/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 6/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 6/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 6/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A

Epoch 6/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][AEpoch 6/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 6/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 6/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 6/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 6/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 6/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 6/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 6/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 6/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 6/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 6/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 6/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.51s/it][A
Epoch 6/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 6/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 6/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 6/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.51s/it][A
Epoch 6/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 6/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 6/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 6/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 6/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

Epoch 6/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 6/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

[Î²=5.5] Epoch 6 summary:
  input  std: mean=1.813e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.055e-01
  layer model_7__forward_module.module.conv2 act-std: mean=6.856e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.148e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.619e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.505e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.683e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.624e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.011e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.359e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.388e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.067e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.007e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.239e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.542e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.370e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.082e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=4.353e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=9.841e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.339e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=5.181e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.568e+00
  param model_1__forward_module.module.conv1.bias grad-norm: mean=3.479e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.008e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.972e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=7.066e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.549e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.875e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=7.631e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=8.833e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.908e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.654e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=9.509e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=6.374e+00

  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.365e+00
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  param model_4__forward_module.module.conv2.weight grad-norm: mean=5.374e+00[A
  param model_4__forward_module.module.conv2.bias grad-norm: mean=7.876e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=6.485e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.390e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=5.680e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.120e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=9.067e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.907e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.001e+01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.257e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=7.999e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.675e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.839e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=8.983e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Epoch 6/32 - Train Loss: 49.944883 - Test Loss: 44.956764
Training epochs:  19%|â–ˆâ–‰        | 6/32 [02:09<09:22, 21.65s/it]
Epoch 7/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  19%|â–ˆâ–‰        | 6/32 [02:09<09:22, 21.65s/it]
Epoch 7/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 7/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][AEpoch 7/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A

Epoch 7/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][AEpoch 7/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.51s/it][A
Epoch 7/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 7/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 7/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 7/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A

Epoch 7/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][AEpoch 7/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 7/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 7/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 7/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 7/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 7/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 7/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 7/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 7/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 7/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 7/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A

Epoch 7/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.57s/it][AEpoch 7/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.57s/it][A

Epoch 7/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.56s/it][AEpoch 7/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.56s/it][A

Epoch 7/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.43s/it][AEpoch 7/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.43s/it][AEpoch 7/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]Epoch 7/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]


[Î²=5.5] Epoch 7 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.055e-01
  layer model_7__forward_module.module.conv2 act-std: mean=6.856e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.148e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.619e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.505e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.682e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.624e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.011e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.358e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.387e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.067e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.006e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.239e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.542e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.371e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.084e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=4.362e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=9.862e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.344e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=5.201e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.567e+00
  param model_1__forward_module.module.conv1.bias grad-norm: mean=3.475e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.007e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.971e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=7.084e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.552e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.880e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=7.651e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=8.856e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.912e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.661e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=9.536e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=6.371e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.365e+00
  param model_4__forward_module.module.conv2.weight grad-norm: mean=5.380e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=7.879e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=6.482e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.389e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=5.680e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.120e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=9.059e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.906e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.000e+01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.255e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=7.987e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.673e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.819e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=8.957e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.88it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.83it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.83it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.81it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.84it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.83it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  2.00it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s]
Training epochs:  22%|â–ˆâ–ˆâ–       | 7/32 [02:31<09:01, 21.64s/it]
Epoch 8/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.97it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s]
Epoch 7/32 - Train Loss: 49.851486 - Test Loss: 44.956347
Training epochs:  22%|â–ˆâ–ˆâ–       | 7/32 [02:31<09:01, 21.65s/it]
Epoch 8/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 8/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][A
Epoch 8/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 8/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 8/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.51s/it][A
Epoch 8/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.51s/it][A
Epoch 8/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A

Epoch 8/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][AEpoch 8/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.51s/it][A
Epoch 8/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 8/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 8/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 8/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A

Epoch 8/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][AEpoch 8/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 8/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 8/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.51s/it][A
Epoch 8/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 8/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 8/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 8/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 8/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 8/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A

Epoch 8/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][AEpoch 8/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 8/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 8/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

[Î²=5.5] Epoch 8 summary:

  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.055e-01
  layer model_7__forward_module.module.conv2 act-std: mean=6.857e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.148e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.619e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.505e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.683e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.623e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.011e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.360e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.389e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.067e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.007e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.239e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.542e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.370e+00Epoch 8/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it]
[A  layer model_0__forward_module.module.conv2 act-std: mean=8.084e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=4.349e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=9.829e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.337e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=5.173e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.566e+00
  param model_1__forward_module.module.conv1.bias grad-norm: mean=3.474e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.001e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.956e-01Epoch 8/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

  param model_2__forward_module.module.conv1.weight grad-norm: mean=7.028e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.540e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.870e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=7.582e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=8.797e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.900e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.649e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=9.468e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=6.367e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.363e+00
  param model_4__forward_module.module.conv2.weight grad-norm: mean=5.366e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=7.863e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=6.493e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.391e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=5.684e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.122e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=9.058e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.905e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.000e+01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.255e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=7.994e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.674e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.836e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=8.976e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.83it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.82it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]
Epoch 8/32 - Train Loss: 49.924444 - Test Loss: 44.955930
Training epochs:  25%|â–ˆâ–ˆâ–Œ       | 8/32 [02:53<08:38, 21.59s/it]
Epoch 9/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  25%|â–ˆâ–ˆâ–Œ       | 8/32 [02:53<08:38, 21.59s/it]
Epoch 9/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 9/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][A
Epoch 9/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][A
Epoch 9/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.51s/it][A
Epoch 9/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A

Epoch 9/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.51s/it][AEpoch 9/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.51s/it][A
Epoch 9/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 9/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A

Epoch 9/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][AEpoch 9/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A

Epoch 9/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][AEpoch 9/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A

Epoch 9/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][AEpoch 9/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 9/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 9/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 9/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 9/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 9/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 9/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 9/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 9/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 9/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 9/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 9/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 9/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

Epoch 9/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 9/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

[Î²=5.5] Epoch 9 summary:
  input  std: mean=1.813e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.055e-01
  layer model_7__forward_module.module.conv2 act-std: mean=6.857e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.148e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.619e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.505e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.685e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.624e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.012e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.361e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.389e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.067e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.008e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.239e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.542e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.370e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.086e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=4.354e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=9.842e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.342e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=5.181e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.563e+00
  param model_1__forward_module.module.conv1.bias grad-norm: mean=3.467e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.003e+00

  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.963e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=7.020e+00Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.539e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.868e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=7.579e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=8.816e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.904e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.651e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=9.493e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=6.373e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.365e+00
  param model_4__forward_module.module.conv2.weight grad-norm: mean=5.378e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=7.879e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=6.503e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.393e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=5.688e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.122e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=9.066e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.907e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.001e+01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.256e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=8.006e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.676e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.839e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=8.989e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A

Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.81it/s][AEvaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.81it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.82it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.82it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.98it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.97it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s]
Epoch 9/32 - Train Loss: 49.922178 - Test Loss: 44.955565
Training epochs:  28%|â–ˆâ–ˆâ–Š       | 9/32 [03:14<08:15, 21.56s/it]
Epoch 10/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  28%|â–ˆâ–ˆâ–Š       | 9/32 [03:14<08:15, 21.56s/it]
Epoch 10/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 10/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][AEpoch 10/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][A
Epoch 10/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 10/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 10/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.51s/it][A
Epoch 10/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.51s/it][A
Epoch 10/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 10/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A

Epoch 10/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][AEpoch 10/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A

Epoch 10/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][AEpoch 10/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 10/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 10/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 10/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 10/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A

Epoch 10/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][AEpoch 10/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A

Epoch 10/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][AEpoch 10/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 10/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 10/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A

Epoch 10/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][AEpoch 10/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A

Epoch 10/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 10/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 10/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]
Epoch 10/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

[Î²=5.5] Epoch 10 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.055e-01
  layer model_7__forward_module.module.conv2 act-std: mean=6.856e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.148e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.619e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.505e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.683e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.623e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.011e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.359e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.389e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.067e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.007e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.239e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.542e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.370e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.083e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=4.346e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=9.826e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.338e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=5.178e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.558e+00
  param model_1__forward_module.module.conv1.bias grad-norm: mean=3.458e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.995e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.946e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=7.069e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.548e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.878e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=7.633e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=8.824e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.906e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.658e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=9.502e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=6.359e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.362e+00
  param model_4__forward_module.module.conv2.weight grad-norm: mean=5.364e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=7.858e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=6.500e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.393e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=5.699e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.124e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=9.086e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.911e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.003e+01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.259e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=7.992e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.673e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.830e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=8.977e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.81it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]
Epoch 10/32 - Train Loss: 49.869761 - Test Loss: 44.955173
Training epochs:  31%|â–ˆâ–ˆâ–ˆâ–      | 10/32 [03:36<07:54, 21.55s/it]Training epochs:  31%|â–ˆâ–ˆâ–ˆâ–      | 10/32 [03:36<07:54, 21.55s/it]
Epoch 11/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 11/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 11/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 11/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 11/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.51s/it][A
Epoch 11/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.51s/it][A
Epoch 11/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 11/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 11/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 11/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A

Epoch 11/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][AEpoch 11/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 11/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 11/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 11/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 11/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A

Epoch 11/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][AEpoch 11/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 11/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 11/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A

Epoch 11/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][AEpoch 11/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 11/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 11/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 11/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 11/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 11/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 11/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

Epoch 11/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 11/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]


[Î²=5.5] Epoch 11 summary:
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A  input  std: mean=1.813e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.055e-01
  layer model_7__forward_module.module.conv2 act-std: mean=6.857e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.148e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.619e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.505e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.684e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.623e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.012e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.360e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.388e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.067e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.007e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.239e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.542e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.370e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.084e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=4.352e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=9.841e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.340e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=5.188e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.564e+00
  param model_1__forward_module.module.conv1.bias grad-norm: mean=3.469e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.003e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.971e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=7.060e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.547e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.876e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=7.617e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=8.808e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.903e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.648e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=9.488e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=6.361e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.363e+00
  param model_4__forward_module.module.conv2.weight grad-norm: mean=5.361e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=7.859e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=6.486e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.390e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=5.681e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.121e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=9.059e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.906e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=9.996e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.254e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=7.974e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.670e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.813e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=8.943e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.84it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.83it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.85it/s]
Training epochs:  34%|â–ˆâ–ˆâ–ˆâ–      | 11/32 [03:57<07:32, 21.54s/it]
Epoch 12/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.84it/s]
Epoch 11/32 - Train Loss: 49.892558 - Test Loss: 44.954795
Training epochs:  34%|â–ˆâ–ˆâ–ˆâ–      | 11/32 [03:57<07:32, 21.54s/it]
Epoch 12/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 12/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 12/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A

Epoch 12/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][AEpoch 12/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 12/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 12/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 12/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 12/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 12/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 12/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 12/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 12/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 12/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 12/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 12/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 12/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 12/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 12/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A

Epoch 12/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][AEpoch 12/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A

Epoch 12/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][AEpoch 12/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 12/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 12/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 12/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 12/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

[Î²=5.5] Epoch 12 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.055e-01
  layer model_7__forward_module.module.conv2 act-std: mean=6.856e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.148e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.619e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.505e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.685e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.623e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.012e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.360e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.388e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.067e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.007e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.239e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.542e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.370e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.086e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=4.343e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=9.817e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.334e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=5.169e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.558e+00
  param model_1__forward_module.module.conv1.bias grad-norm: mean=3.457e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.995e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.952e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=7.052e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.546e+00

  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.870e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=7.612e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=8.823e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.906e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.650e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=9.498e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=6.354e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.361e+00Epoch 12/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it]
[A  param model_4__forward_module.module.conv2.weight grad-norm: mean=5.355e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=7.847e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=6.483e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.389e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=5.675e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.120e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=9.051e+00
Epoch 12/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.904e+00

  param model_6__forward_module.module.conv2.weight grad-norm: mean=9.992e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.254e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=7.982e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.672e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.822e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=8.958e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.82it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.81it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]
Epoch 12/32 - Train Loss: 49.892450 - Test Loss: 44.954411
Training epochs:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 12/32 [04:19<07:10, 21.54s/it]Training epochs:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 12/32 [04:19<07:10, 21.54s/it]
Epoch 13/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 13/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 13/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][A
Epoch 13/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][A
Epoch 13/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.51s/it][A
Epoch 13/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.51s/it][A
Epoch 13/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 13/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A

Epoch 13/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][AEpoch 13/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 13/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 13/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 13/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 13/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A

Epoch 13/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it]Epoch 13/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A[A

Epoch 13/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][AEpoch 13/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 13/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.57s/it][A
Epoch 13/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.57s/it][A
Epoch 13/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.56s/it][A
Epoch 13/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.56s/it][A
Epoch 13/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 13/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 13/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 13/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A

Epoch 13/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 13/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 13/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=5.5] Epoch 13 summary:
Epoch 13/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]  input  std: mean=1.813e+00

  layer model_7__forward_module.module.conv1 act-std: mean=9.055e-01
  layer model_7__forward_module.module.conv2 act-std: mean=6.856e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.148e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.619e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.505e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.686e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.624e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.012e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.360e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.389e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.067e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.007e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.239e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.542e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.370e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.085e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=4.349e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=9.834e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.342e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=5.185e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.560e+00
  param model_1__forward_module.module.conv1.bias grad-norm: mean=3.461e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.991e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.943e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=7.053e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.546e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.875e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=7.619e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=8.799e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.901e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.648e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=9.479e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=6.356e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.361e+00
  param model_4__forward_module.module.conv2.weight grad-norm: mean=5.362e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=7.856e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=6.502e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.393e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=5.688e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.122e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=9.050e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.904e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=9.982e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.252e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=7.970e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.669e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.816e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=8.941e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A

Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.83it/s][AEvaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.83it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.84it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.83it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.81it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.81it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]
Epoch 13/32 - Train Loss: 49.831211 - Test Loss: 44.954064

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]
Training epochs:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 13/32 [04:40<06:49, 21.58s/it]
Epoch 14/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 13/32 [04:40<06:50, 21.58s/it]
Epoch 14/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 14/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 14/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A

Epoch 14/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][AEpoch 14/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 14/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 14/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 14/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 14/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 14/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 14/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 14/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 14/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 14/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 14/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A

Epoch 14/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][AEpoch 14/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 14/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 14/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 14/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 14/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 14/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 14/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 14/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 14/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 14/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 14/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

[Î²=5.5] Epoch 14 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.055e-01
  layer model_7__forward_module.module.conv2 act-std: mean=6.857e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.148e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.619e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.505e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.685e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.624e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.011e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.359e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.388e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.067e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.007e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.239e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.542e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.370e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.086e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=4.344e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=9.820e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.336e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=5.172e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.559e+00

  param model_1__forward_module.module.conv1.bias grad-norm: mean=3.458e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.995e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.945e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=7.037e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.542e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.875e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=7.591e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=8.800e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.901e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.649e+00
Epoch 14/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it]  param model_3__forward_module.module.conv2.bias grad-norm: mean=9.475e-01[A
  param model_4__forward_module.module.conv1.weight grad-norm: mean=6.356e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.361e+00
  param model_4__forward_module.module.conv2.weight grad-norm: mean=5.354e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=7.846e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=6.493e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.391e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=5.680e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.121e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=9.046e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.903e+00
Epoch 14/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]  param model_6__forward_module.module.conv2.weight grad-norm: mean=9.974e+00

  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.252e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=7.967e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.668e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.817e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=8.937e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.81it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.82it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.97it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s]
Training epochs:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 14/32 [05:02<06:28, 21.56s/it]

Epoch 15/32:   0%|          | 0/13 [00:00<?, ?it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.96it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]
Epoch 14/32 - Train Loss: 49.911743 - Test Loss: 44.953740
Training epochs:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 14/32 [05:02<06:28, 21.56s/it]
Epoch 15/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 15/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 15/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][A

Epoch 15/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][AEpoch 15/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 15/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 15/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 15/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 15/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 15/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 15/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 15/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 15/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 15/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 15/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A

Epoch 15/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][AEpoch 15/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 15/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 15/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A

Epoch 15/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][AEpoch 15/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 15/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 15/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A

Epoch 15/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][AEpoch 15/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 15/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 15/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

[Î²=5.5] Epoch 15 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.056e-01

  layer model_7__forward_module.module.conv2 act-std: mean=6.857e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.148e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.619e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.505e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.688e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.624e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.012e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.361e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.390e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.067e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.008e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.239e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.543e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.370e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.087e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=4.346e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=9.826e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.337e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=5.177e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.561e+00
  param model_1__forward_module.module.conv1.bias grad-norm: mean=3.461e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.996e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.948e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=7.040e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.542e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.876e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=7.594e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=8.778e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.896e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.639e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=9.449e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=6.345e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.359e+00
  param model_4__forward_module.module.conv2.weight grad-norm: mean=5.349e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=7.838e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=6.470e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.387e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=5.665e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.118e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=9.019e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.897e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=9.963e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.250e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=7.973e+00
Epoch 15/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it]  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.670e+00[A
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.814e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=8.939e-01
Epoch 15/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.82it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.81it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]
Training epochs:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 15/32 [05:23<06:06, 21.55s/it]

Epoch 16/32:   0%|          | 0/13 [00:00<?, ?it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][A[AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Epoch 15/32 - Train Loss: 49.899384 - Test Loss: 44.953373
Training epochs:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 15/32 [05:23<06:06, 21.56s/it]
Epoch 16/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 16/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it]
[AEpoch 16/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 16/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 16/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 16/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 16/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A

Epoch 16/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][AEpoch 16/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 16/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 16/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 16/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 16/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A

Epoch 16/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][AEpoch 16/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A

Epoch 16/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][AEpoch 16/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 16/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 16/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 16/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 16/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A

Epoch 16/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][AEpoch 16/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 16/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 16/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 16/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 16/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]


[Î²=5.5] Epoch 16 summary:
  input  std: mean=1.813e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.056e-01
  layer model_7__forward_module.module.conv2 act-std: mean=6.858e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.148e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.620e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.505e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.686e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.623e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.012e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.361e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.390e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.067e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.009e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.239e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.542e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.370e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.086e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=4.353e+00
Epoch 16/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it]  param model_0__forward_module.module.conv1.bias grad-norm: mean=9.843e-01[A
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.341e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=5.189e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.562e+00
  param model_1__forward_module.module.conv1.bias grad-norm: mean=3.468e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.999e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.962e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=7.067e+00
Epoch 16/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.549e+00

  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.878e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=7.637e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=8.824e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.906e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.655e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=9.506e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=6.343e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.359e+00
  param model_4__forward_module.module.conv2.weight grad-norm: mean=5.351e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=7.840e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=6.478e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.388e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=5.678e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.119e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=9.049e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.904e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=9.979e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.253e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=7.971e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.670e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.819e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=8.939e-01


Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][AEvaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A

Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.81it/s][AEvaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.81it/s][A

Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.81it/s][AEvaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.81it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.96it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]
Epoch 16/32 - Train Loss: 49.932599 - Test Loss: 44.953032
Training epochs:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 16/32 [05:45<05:44, 21.54s/it]Training epochs:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 16/32 [05:45<05:44, 21.54s/it]
Epoch 17/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 17/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 17/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][AEpoch 17/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][A
Epoch 17/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.51s/it][A
Epoch 17/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.51s/it][A
Epoch 17/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 17/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 17/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 17/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 17/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 17/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 17/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 17/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 17/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 17/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 17/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 17/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 17/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 17/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 17/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 17/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A

Epoch 17/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][AEpoch 17/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 17/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 17/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A

Epoch 17/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 17/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 17/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]
Epoch 17/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

[Î²=5.5] Epoch 17 summary:
  input  std: mean=1.813e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.055e-01
  layer model_7__forward_module.module.conv2 act-std: mean=6.857e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.148e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.620e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.505e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.685e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.625e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.011e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.360e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.389e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.067e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.008e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.239e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.542e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.370e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.088e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=4.347e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=9.829e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.335e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=5.182e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.558e+00
  param model_1__forward_module.module.conv1.bias grad-norm: mean=3.456e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.996e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.948e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=7.056e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.547e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.873e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=7.617e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=8.794e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.900e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.643e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=9.471e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=6.356e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.362e+00
  param model_4__forward_module.module.conv2.weight grad-norm: mean=5.362e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=7.859e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=6.476e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.388e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=5.664e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.118e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=9.069e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.908e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.000e+01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.255e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=7.971e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.670e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.817e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=8.937e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A

Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][AEvaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Epoch 17/32 - Train Loss: 49.907936 - Test Loss: 44.952697
Training epochs:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 17/32 [06:06<05:23, 21.54s/it]
Epoch 18/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 17/32 [06:06<05:23, 21.54s/it]
Epoch 18/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 18/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 18/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 18/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 18/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A

Epoch 18/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][AEpoch 18/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A

Epoch 18/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][AEpoch 18/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 18/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 18/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 18/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 18/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A

Epoch 18/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][AEpoch 18/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A

Epoch 18/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][AEpoch 18/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 18/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 18/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A

Epoch 18/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][AEpoch 18/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 18/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 18/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 18/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 18/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A

Epoch 18/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 18/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 18/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

[Î²=5.5] Epoch 18 summary:
  input  std: mean=1.814e+00
Epoch 18/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]  layer model_7__forward_module.module.conv1 act-std: mean=9.055e-01

  layer model_7__forward_module.module.conv2 act-std: mean=6.857e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.148e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.620e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.505e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.686e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.624e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.011e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.360e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.389e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.067e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.009e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.239e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.542e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.370e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.088e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=4.324e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=9.777e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.325e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=5.146e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.554e+00
  param model_1__forward_module.module.conv1.bias grad-norm: mean=3.446e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.992e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.941e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=7.041e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.543e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.874e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=7.606e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=8.827e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.906e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.654e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=9.503e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=6.355e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.361e+00
  param model_4__forward_module.module.conv2.weight grad-norm: mean=5.357e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=7.849e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=6.470e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.386e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=5.668e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.118e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=9.049e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.903e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=9.992e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.254e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=7.973e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.670e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.820e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=8.947e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.82it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.82it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.82it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.81it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.81it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Epoch 18/32 - Train Loss: 49.935872 - Test Loss: 44.952375
Training epochs:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 18/32 [06:28<05:01, 21.53s/it]
Epoch 19/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 18/32 [06:28<05:01, 21.53s/it]
Epoch 19/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 19/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 19/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][A

Epoch 19/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.51s/it][AEpoch 19/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A

Epoch 19/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it]Epoch 19/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.51s/it][A[A

Epoch 19/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.51s/it][AEpoch 19/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A

Epoch 19/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.51s/it][AEpoch 19/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.51s/it][A
Epoch 19/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 19/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 19/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 19/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 19/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 19/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A

Epoch 19/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][AEpoch 19/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 19/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 19/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A

Epoch 19/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][AEpoch 19/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 19/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 19/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 19/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 19/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

Epoch 19/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 19/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

[Î²=5.5] Epoch 19 summary:
  input  std: mean=1.813e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.056e-01
  layer model_7__forward_module.module.conv2 act-std: mean=6.857e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.148e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.619e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.505e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.686e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.625e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.011e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.360e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.389e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.067e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.008e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.239e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.542e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.370e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.086e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=4.333e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=9.791e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.334e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=5.150e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.559e+00
  param model_1__forward_module.module.conv1.bias grad-norm: mean=3.460e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.995e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.936e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=7.052e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.540e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.899e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=7.562e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=8.784e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.897e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.650e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=9.453e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=6.349e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.360e+00
  param model_4__forward_module.module.conv2.weight grad-norm: mean=5.354e+00

  param model_4__forward_module.module.conv2.bias grad-norm: mean=7.843e-01
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  param model_5__forward_module.module.conv1.weight grad-norm: mean=6.483e+00[A
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.389e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=5.682e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.121e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=9.065e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.907e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.000e+01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.254e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=7.969e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.669e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.825e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=8.957e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.85it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.84it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.82it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.83it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.98it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s]
Training epochs:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 19/32 [06:49<04:39, 21.52s/it]
Epoch 20/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]
Epoch 19/32 - Train Loss: 49.889854 - Test Loss: 44.952064
Training epochs:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 19/32 [06:49<04:39, 21.53s/it]
Epoch 20/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 20/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.55s/it][AEpoch 20/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][A
Epoch 20/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 20/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 20/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 20/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 20/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 20/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A

Epoch 20/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][AEpoch 20/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 20/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 20/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 20/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 20/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 20/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 20/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 20/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 20/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A

Epoch 20/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][AEpoch 20/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A

Epoch 20/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][AEpoch 20/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 20/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 20/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 20/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 20/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=5.5] Epoch 20 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.056e-01
  layer model_7__forward_module.module.conv2 act-std: mean=6.856e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.148e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.619e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.505e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.686e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.624e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.011e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.360e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.390e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.067e+00

  layer model_2__forward_module.module.conv2 act-std: mean=4.008e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.239e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.542e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.370e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.086e-01
Epoch 20/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it]  param model_0__forward_module.module.conv1.weight grad-norm: mean=4.333e+00[A
  param model_0__forward_module.module.conv1.bias grad-norm: mean=9.797e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.330e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=5.156e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.557e+00
  param model_1__forward_module.module.conv1.bias grad-norm: mean=3.454e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.988e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.938e-01Epoch 20/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

  param model_2__forward_module.module.conv1.weight grad-norm: mean=7.038e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.542e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.881e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=7.592e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=8.800e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.900e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.652e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=9.472e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=6.350e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.360e+00
  param model_4__forward_module.module.conv2.weight grad-norm: mean=5.359e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=7.850e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=6.472e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.387e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=5.667e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.118e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=9.061e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.906e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=9.995e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.254e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=7.948e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.664e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.812e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=8.910e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.82it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.82it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.81it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.81it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.96it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]
Training epochs:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 20/32 [07:11<04:18, 21.55s/it]Epoch 20/32 - Train Loss: 49.798657 - Test Loss: 44.951743

Epoch 21/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 20/32 [07:11<04:18, 21.55s/it]
Epoch 21/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 21/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.50s/it][A
Epoch 21/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A

Epoch 21/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][AEpoch 21/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 21/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 21/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 21/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 21/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A

Epoch 21/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][AEpoch 21/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A

Epoch 21/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][AEpoch 21/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A

Epoch 21/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][AEpoch 21/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 21/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 21/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 21/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 21/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 21/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 21/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A

Epoch 21/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.58s/it]Epoch 21/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.58s/it][A[A

Epoch 21/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.56s/it][AEpoch 21/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.56s/it][A
Epoch 21/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.43s/it][AEpoch 21/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

Epoch 21/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.43s/it][AEpoch 21/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=5.5] Epoch 21 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.056e-01
  layer model_7__forward_module.module.conv2 act-std: mean=6.859e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.148e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.620e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.505e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.690e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.623e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.012e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.360e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.390e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.067e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.009e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.239e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.542e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.370e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.088e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=4.331e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=9.790e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.325e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=5.155e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.558e+00
  param model_1__forward_module.module.conv1.bias grad-norm: mean=3.455e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.998e+00

  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.949e-01
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  param model_2__forward_module.module.conv1.weight grad-norm: mean=7.003e+00[A
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.533e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.875e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=7.548e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=8.777e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.895e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.642e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=9.449e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=6.336e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.357e+00
  param model_4__forward_module.module.conv2.weight grad-norm: mean=5.342e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=7.826e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=6.484e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.389e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=5.676e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.120e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=9.018e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.897e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=9.955e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.249e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=7.957e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.666e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.809e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=8.934e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.85it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.84it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.84it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.82it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.83it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.81it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.97it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s]
Training epochs:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 21/32 [07:33<03:57, 21.59s/it]
Epoch 22/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.96it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]
Epoch 21/32 - Train Loss: 49.901845 - Test Loss: 44.951441
Training epochs:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 21/32 [07:33<03:57, 21.59s/it]
Epoch 22/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 22/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 22/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A

Epoch 22/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:17,  1.61s/it][AEpoch 22/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:17,  1.62s/it][A
Epoch 22/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.58s/it][A
Epoch 22/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.57s/it][A

Epoch 22/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.55s/it][AEpoch 22/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.55s/it][A
Epoch 22/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 22/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 22/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 22/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 22/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 22/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 22/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 22/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 22/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 22/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 22/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 22/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A

Epoch 22/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.51s/it][AEpoch 22/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.51s/it][A
Epoch 22/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 22/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A

Epoch 22/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 22/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 22/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]
Epoch 22/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=5.5] Epoch 22 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.055e-01
  layer model_7__forward_module.module.conv2 act-std: mean=6.858e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.148e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.620e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.505e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.686e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.625e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.011e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.360e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.392e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.067e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.010e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.239e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.543e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.370e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.088e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=4.326e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=9.781e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.327e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=5.154e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.556e+00
  param model_1__forward_module.module.conv1.bias grad-norm: mean=3.452e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.989e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.940e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=7.018e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.539e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.865e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=7.583e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=8.816e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.904e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.651e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=9.493e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=6.348e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.360e+00
  param model_4__forward_module.module.conv2.weight grad-norm: mean=5.352e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=7.843e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=6.470e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.387e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=5.661e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.117e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=9.041e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.902e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=9.977e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.252e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=7.955e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.666e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.810e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=8.922e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.82it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.81it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.82it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.82it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.98it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s]
Epoch 22/32 - Train Loss: 49.867528 - Test Loss: 44.951132

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.97it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s]
Training epochs:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 22/32 [07:54<03:35, 21.60s/it]
Epoch 23/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 22/32 [07:54<03:36, 21.60s/it]
Epoch 23/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 23/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][A
Epoch 23/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.50s/it][A
Epoch 23/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.51s/it][A
Epoch 23/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.51s/it][A

Epoch 23/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.51s/it][AEpoch 23/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.51s/it][A

Epoch 23/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.51s/it][AEpoch 23/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.51s/it][A

Epoch 23/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][AEpoch 23/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A

Epoch 23/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][AEpoch 23/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 23/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 23/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 23/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 23/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 23/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.51s/it][A
Epoch 23/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.51s/it][A
Epoch 23/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.51s/it][A
Epoch 23/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.51s/it][A

Epoch 23/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.51s/it][AEpoch 23/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.51s/it][A
Epoch 23/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 23/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 23/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][A
Epoch 23/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]
Epoch 23/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 23/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

[Î²=5.5] Epoch 23 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.055e-01
  layer model_7__forward_module.module.conv2 act-std: mean=6.857e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.148e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.620e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.505e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.687e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.624e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.012e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.360e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.390e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.067e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.008e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.239e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.542e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.370e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.088e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=4.337e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=9.807e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.333e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=5.169e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.559e+00
  param model_1__forward_module.module.conv1.bias grad-norm: mean=3.459e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.002e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.962e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=7.037e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.543e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.874e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=7.602e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=8.822e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.905e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.654e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=9.498e-01

  param model_4__forward_module.module.conv1.weight grad-norm: mean=6.338e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.358e+00Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  param model_4__forward_module.module.conv2.weight grad-norm: mean=5.345e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=7.831e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=6.465e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.386e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=5.658e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.117e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=9.035e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.901e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=9.958e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.250e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=7.972e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.670e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.814e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=8.935e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.84it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.84it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]
Training epochs:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 23/32 [08:16<03:14, 21.56s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Epoch 23/32 - Train Loss: 49.931271 - Test Loss: 44.950801

Epoch 24/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 23/32 [08:16<03:14, 21.56s/it]
Epoch 24/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 24/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][A
Epoch 24/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 24/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 24/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A

Epoch 24/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][AEpoch 24/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 24/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 24/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 24/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 24/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 24/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 24/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 24/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it]
[AEpoch 24/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 24/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 24/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A

Epoch 24/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][AEpoch 24/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 24/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 24/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 24/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 24/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 24/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 24/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 24/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 24/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

Epoch 24/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 24/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

[Î²=5.5] Epoch 24 summary:
  input  std: mean=1.813e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.055e-01
  layer model_7__forward_module.module.conv2 act-std: mean=6.858e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.148e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.619e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.505e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.685e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.624e-01

  layer model_4__forward_module.module.conv2 act-std: mean=2.012e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.359e-01Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  layer model_3__forward_module.module.conv2 act-std: mean=3.389e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.067e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.008e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.239e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.543e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.370e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.089e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=4.328e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=9.786e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.329e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=5.158e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.558e+00
  param model_1__forward_module.module.conv1.bias grad-norm: mean=3.452e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.998e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.947e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=7.030e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.541e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.868e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=7.598e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=8.779e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.897e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.643e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=9.456e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=6.328e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.356e+00
  param model_4__forward_module.module.conv2.weight grad-norm: mean=5.341e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=7.824e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=6.484e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.390e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=5.682e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.121e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=9.041e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.902e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=9.973e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.252e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=7.988e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.673e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.828e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=8.970e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.81it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]
Epoch 24/32 - Train Loss: 49.856371 - Test Loss: 44.950485
Training epochs:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 24/32 [08:37<02:52, 21.55s/it]
Epoch 25/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 24/32 [08:37<02:52, 21.55s/it]
Epoch 25/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 25/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][A
Epoch 25/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 25/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.51s/it][A
Epoch 25/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.51s/it][A

Epoch 25/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][AEpoch 25/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 25/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 25/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A

Epoch 25/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][AEpoch 25/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 25/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 25/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A

Epoch 25/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][AEpoch 25/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 25/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 25/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 25/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 25/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 25/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 25/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A

Epoch 25/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][AEpoch 25/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A

Epoch 25/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][AEpoch 25/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A

Epoch 25/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 25/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 25/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]
Epoch 25/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

[Î²=5.5] Epoch 25 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.055e-01
  layer model_7__forward_module.module.conv2 act-std: mean=6.856e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.148e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.619e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.505e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.685e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.624e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.012e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.361e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.390e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.067e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.009e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.239e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.542e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.370e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.089e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=4.322e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=9.773e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.325e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=5.145e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.554e+00
  param model_1__forward_module.module.conv1.bias grad-norm: mean=3.448e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.991e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.938e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=7.023e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.539e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.869e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=7.577e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=8.804e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.901e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.650e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=9.476e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=6.329e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.356e+00
  param model_4__forward_module.module.conv2.weight grad-norm: mean=5.337e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=7.819e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=6.458e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.384e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=5.657e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.116e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=9.047e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.903e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=9.964e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.251e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=7.948e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.664e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.812e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=8.924e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.81it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.96it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]
Training epochs:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 25/32 [08:59<02:30, 21.54s/it]
Epoch 26/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Epoch 25/32 - Train Loss: 49.835728 - Test Loss: 44.950163
Training epochs:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 25/32 [08:59<02:30, 21.54s/it]
Epoch 26/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 26/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 26/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 26/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 26/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 26/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 26/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 26/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 26/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 26/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 26/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 26/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 26/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 26/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 26/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A

Epoch 26/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][AEpoch 26/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 26/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 26/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A

Epoch 26/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][AEpoch 26/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A

Epoch 26/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][AEpoch 26/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 26/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 26/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 26/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][A
Epoch 26/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

[Î²=5.5] Epoch 26 summary:
  input  std: mean=1.813e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.054e-01
  layer model_7__forward_module.module.conv2 act-std: mean=6.856e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.148e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.619e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.505e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.685e-01
Epoch 26/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it]  layer model_4__forward_module.module.conv1 act-std: mean=9.625e-01[A
  layer model_4__forward_module.module.conv2 act-std: mean=2.011e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.360e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.390e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.067e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.009e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.239e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.542e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.370e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.089e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=4.326e+00
Epoch 26/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]  param model_0__forward_module.module.conv1.bias grad-norm: mean=9.783e-01

  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.325e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=5.154e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.551e+00
  param model_1__forward_module.module.conv1.bias grad-norm: mean=3.440e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.987e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.939e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=7.050e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.545e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.878e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=7.614e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=8.798e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.900e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.652e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=9.476e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=6.328e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.355e+00
  param model_4__forward_module.module.conv2.weight grad-norm: mean=5.336e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=7.819e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=6.492e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.392e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=5.682e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.121e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=9.020e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.898e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=9.948e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.248e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=7.985e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.673e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.823e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=8.952e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.77it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A

Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][AEvaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Epoch 26/32 - Train Loss: 49.797446 - Test Loss: 44.949851
Training epochs:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 26/32 [09:20<02:09, 21.54s/it]Training epochs:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 26/32 [09:20<02:09, 21.54s/it]
Epoch 27/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 27/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 27/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 27/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 27/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 27/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 27/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 27/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A

Epoch 27/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][AEpoch 27/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 27/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 27/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A

Epoch 27/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it]Epoch 27/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A[A
Epoch 27/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 27/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A

Epoch 27/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][AEpoch 27/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A

Epoch 27/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][AEpoch 27/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A

Epoch 27/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][AEpoch 27/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 27/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 27/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 27/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 27/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 27/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 27/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

Epoch 27/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 27/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

[Î²=5.5] Epoch 27 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.056e-01
  layer model_7__forward_module.module.conv2 act-std: mean=6.859e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.148e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.620e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.505e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.688e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.624e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.012e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.362e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.391e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.067e+00

  layer model_2__forward_module.module.conv2 act-std: mean=4.010e-01
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  layer model_1__forward_module.module.conv1 act-std: mean=1.239e+00[A
  layer model_1__forward_module.module.conv2 act-std: mean=1.543e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.370e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.090e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=4.325e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=9.783e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.325e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=5.152e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.554e+00
  param model_1__forward_module.module.conv1.bias grad-norm: mean=3.444e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.993e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.944e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=7.005e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.535e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.869e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=7.559e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=8.769e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.894e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.643e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=9.447e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=6.333e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.357e+00
  param model_4__forward_module.module.conv2.weight grad-norm: mean=5.337e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=7.822e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=6.461e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.385e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=5.654e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.116e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=9.024e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.898e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=9.960e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.250e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=7.962e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.668e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.808e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=8.929e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.82it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.82it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.81it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.82it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.82it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.97it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.97it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s]
Epoch 27/32 - Train Loss: 49.943300 - Test Loss: 44.949573
Training epochs:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 27/32 [09:42<01:47, 21.54s/it]Training epochs:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 27/32 [09:42<01:47, 21.53s/it]

Epoch 28/32:   0%|          | 0/13 [00:00<?, ?it/s][AEpoch 28/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 28/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 28/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 28/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 28/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A

Epoch 28/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][AEpoch 28/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A

Epoch 28/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][AEpoch 28/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 28/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 28/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A

Epoch 28/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][AEpoch 28/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 28/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.51s/it][A
Epoch 28/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.51s/it][A

Epoch 28/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.51s/it][AEpoch 28/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.51s/it][A
Epoch 28/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.51s/it][A
Epoch 28/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A

Epoch 28/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it]Epoch 28/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A[A

Epoch 28/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][AEpoch 28/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 28/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 28/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 28/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 28/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

Epoch 28/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 28/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

[Î²=5.5] Epoch 28 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.054e-01
  layer model_7__forward_module.module.conv2 act-std: mean=6.857e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.148e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.620e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.505e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.684e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.623e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.012e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.360e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.391e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.067e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.009e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.239e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.543e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.370e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.087e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=4.329e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=9.791e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.331e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=5.163e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.553e+00
  param model_1__forward_module.module.conv1.bias grad-norm: mean=3.444e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.996e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.945e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=7.050e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.545e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.869e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=7.614e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=8.794e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.900e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.645e+00

  param model_3__forward_module.module.conv2.bias grad-norm: mean=9.469e-01
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  param model_4__forward_module.module.conv1.weight grad-norm: mean=6.322e+00[A
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.354e+00
  param model_4__forward_module.module.conv2.weight grad-norm: mean=5.335e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=7.816e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=6.473e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.387e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=5.668e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.119e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=9.044e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.903e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=9.972e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.252e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=7.943e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.663e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.803e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=8.905e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.82it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.82it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.81it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.83it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.83it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.98it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.98it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s]
Epoch 28/32 - Train Loss: 49.868259 - Test Loss: 44.949267
Training epochs:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 28/32 [10:03<01:26, 21.50s/it]
Epoch 29/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 28/32 [10:03<01:26, 21.50s/it]
Epoch 29/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 29/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 29/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][A
Epoch 29/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 29/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A

Epoch 29/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][AEpoch 29/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 29/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 29/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A

Epoch 29/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it]Epoch 29/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A[A

Epoch 29/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.51s/it][AEpoch 29/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.51s/it][A

Epoch 29/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.51s/it][AEpoch 29/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.51s/it][A

Epoch 29/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][AEpoch 29/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 29/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 29/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 29/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.51s/it][A
Epoch 29/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.51s/it][A
Epoch 29/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.51s/it][A
Epoch 29/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.51s/it][A

Epoch 29/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.51s/it][AEpoch 29/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.51s/it][A

Epoch 29/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.45s/it][AEpoch 29/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=5.5] Epoch 29 summary:
  input  std: mean=1.814e+00
Epoch 29/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.45s/it]  layer model_7__forward_module.module.conv1 act-std: mean=9.056e-01[A
  layer model_7__forward_module.module.conv2 act-std: mean=6.859e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.148e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.620e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.505e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.689e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.624e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.012e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.360e-01
Epoch 29/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]  layer model_3__forward_module.module.conv2 act-std: mean=3.391e-01

  layer model_2__forward_module.module.conv1 act-std: mean=1.067e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.010e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.239e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.543e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.370e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.091e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=4.318e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=9.763e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.323e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=5.146e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.553e+00
  param model_1__forward_module.module.conv1.bias grad-norm: mean=3.444e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.986e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.923e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=6.997e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.533e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.866e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=7.553e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=8.736e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.887e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.632e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=9.406e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=6.342e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.358e+00
  param model_4__forward_module.module.conv2.weight grad-norm: mean=5.344e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=7.831e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=6.458e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.384e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=5.661e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.116e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=9.026e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.899e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=9.968e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.251e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=7.942e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.663e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.808e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=8.915e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.83it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.82it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.82it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.81it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.97it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s]
Training epochs:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 29/32 [10:25<01:04, 21.54s/it]
Epoch 30/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Epoch 29/32 - Train Loss: 49.909757 - Test Loss: 44.948969
Training epochs:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 29/32 [10:25<01:04, 21.54s/it]
Epoch 30/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 30/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][AEpoch 30/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.57s/it][A
Epoch 30/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 30/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A

Epoch 30/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][AEpoch 30/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.51s/it][A
Epoch 30/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 30/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 30/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 30/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 30/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 30/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 30/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 30/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A

Epoch 30/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][AEpoch 30/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 30/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 30/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A

Epoch 30/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.51s/it][AEpoch 30/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 30/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 30/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A

Epoch 30/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][AEpoch 30/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A

Epoch 30/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 30/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 30/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

[Î²=5.5] Epoch 30 summary:
Epoch 30/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]  input  std: mean=1.814e+00

  layer model_7__forward_module.module.conv1 act-std: mean=9.055e-01
  layer model_7__forward_module.module.conv2 act-std: mean=6.858e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.148e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.620e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.505e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.686e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.625e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.011e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.361e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.391e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.067e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.010e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.239e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.543e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.370e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.087e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=4.324e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=9.777e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.325e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=5.144e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.552e+00
  param model_1__forward_module.module.conv1.bias grad-norm: mean=3.443e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.986e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.925e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=7.002e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.535e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.867e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=7.564e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=8.756e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.891e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.638e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=9.428e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=6.318e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.353e+00
  param model_4__forward_module.module.conv2.weight grad-norm: mean=5.330e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=7.809e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=6.476e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.388e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=5.673e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.118e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=9.020e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.897e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=9.946e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.248e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=7.969e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.669e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.818e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=8.944e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.85it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.84it/s][A

Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][AEvaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.81it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.82it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.82it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.97it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s]
Training epochs:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 30/32 [10:46<00:43, 21.52s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]
Epoch 30/32 - Train Loss: 49.860426 - Test Loss: 44.948678

Epoch 31/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 30/32 [10:46<00:43, 21.52s/it]
Epoch 31/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 31/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 31/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A

Epoch 31/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][AEpoch 31/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 31/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 31/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 31/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 31/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 31/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 31/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 31/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 31/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 31/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 31/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 31/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 31/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 31/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 31/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 31/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 31/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A

Epoch 31/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][AEpoch 31/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 31/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 31/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 31/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][A
Epoch 31/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it]Epoch 31/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it][A
Epoch 31/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

[Î²=5.5] Epoch 31 summary:
  input  std: mean=1.813e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.055e-01
  layer model_7__forward_module.module.conv2 act-std: mean=6.857e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.148e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.620e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.505e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.688e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.625e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.012e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.361e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.392e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.067e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.011e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.239e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.543e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.370e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.089e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=4.316e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=9.761e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.323e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=5.145e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.549e+00
  param model_1__forward_module.module.conv1.bias grad-norm: mean=3.437e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.984e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.924e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=7.037e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.542e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.872e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=7.599e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=8.795e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.900e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.651e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=9.465e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=6.331e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.356e+00
  param model_4__forward_module.module.conv2.weight grad-norm: mean=5.345e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=7.827e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=6.484e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.390e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=5.679e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.120e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=9.002e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.894e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=9.939e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.247e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=7.962e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.668e+00

  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.817e+00
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  param model_7__forward_module.module.conv2.bias grad-norm: mean=8.930e-01[A

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.82it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.81it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]
Training epochs:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 31/32 [11:08<00:21, 21.52s/it]
Epoch 32/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Epoch 31/32 - Train Loss: 49.864601 - Test Loss: 44.948365
Training epochs:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 31/32 [11:08<00:21, 21.53s/it]
Epoch 32/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 32/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][AEpoch 32/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A

Epoch 32/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][AEpoch 32/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A

Epoch 32/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][AEpoch 32/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 32/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 32/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 32/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 32/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 32/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 32/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 32/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 32/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 32/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 32/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 32/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 32/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A

Epoch 32/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][AEpoch 32/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A

Epoch 32/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][AEpoch 32/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 32/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 32/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A

Epoch 32/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 32/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 32/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]
Epoch 32/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

[Î²=5.5] Epoch 32 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.055e-01
  layer model_7__forward_module.module.conv2 act-std: mean=6.858e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.148e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.620e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.505e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.686e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.624e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.012e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.361e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.393e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.067e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.011e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.239e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.543e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.370e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.090e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=4.318e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=9.764e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.323e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=5.141e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.556e+00
  param model_1__forward_module.module.conv1.bias grad-norm: mean=3.453e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.988e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.934e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=7.005e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.535e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.865e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=7.557e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=8.769e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.894e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.639e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=9.438e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=6.318e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.353e+00
  param model_4__forward_module.module.conv2.weight grad-norm: mean=5.329e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=7.809e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=6.459e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.384e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=5.655e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.116e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=9.011e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.895e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=9.940e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.247e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=7.932e+00
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.661e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.801e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=8.895e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.81it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.96it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.96it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]
Epoch 32/32 - Train Loss: 49.839472 - Test Loss: 44.948057
Training epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [11:30<00:00, 21.52s/it]Training epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [11:30<00:00, 21.56s/it]
Training epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [11:30<00:00, 21.52s/it]Training epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [11:30<00:00, 21.56s/it]
Loaded best models from epoch 32 with loss 44.948057

>>> Completed beta = 5.5
>>> Time for this beta: 0:11:30
>>> Total elapsed time: 1:20:46
==================================================
Loaded data shape: torch.Size([4096, 2, 64, 64])
Training data shape: torch.Size([3276, 2, 64, 64])
Testing data shape: torch.Size([820, 2, 64, 64])

>>> Training the model at beta =  6.0
Training epochs:   0%|          | 0/32 [00:00<?, ?it/s]
>>> Training the model at beta = 6.0

Training epochs:   0%|          | 0/32 [00:00<?, ?it/s]
Epoch 1/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 1/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 1/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.50s/it][A
Epoch 1/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.50s/it][A
Epoch 1/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.51s/it][A
Epoch 1/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.51s/it][A
Epoch 1/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.51s/it][A
Epoch 1/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.51s/it][A
Epoch 1/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 1/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 1/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 1/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 1/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 1/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 1/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.51s/it][A
Epoch 1/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 1/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.51s/it][A
Epoch 1/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.51s/it][A
Epoch 1/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.51s/it][A
Epoch 1/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 1/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 1/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A

Epoch 1/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it]Epoch 1/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A[A
Epoch 1/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 1/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 1/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 1/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

Epoch 1/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 1/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

[Î²=6.0] Epoch 1 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=8.965e-01
  layer model_7__forward_module.module.conv2 act-std: mean=6.737e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.146e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.589e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.510e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.506e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.552e-01
  layer model_4__forward_module.module.conv2 act-std: mean=1.994e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.280e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.272e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.068e+00
  layer model_2__forward_module.module.conv2 act-std: mean=3.895e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.238e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.511e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.375e+00
  layer model_0__forward_module.module.conv2 act-std: mean=7.916e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=5.475e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.232e+00
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.923e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=6.549e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.968e+00
  param model_1__forward_module.module.conv1.bias grad-norm: mean=4.324e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.447e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=5.000e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=1.003e+01

  param model_2__forward_module.module.conv1.bias grad-norm: mean=2.173e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.502e+00Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.074e+00
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.187e+01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.549e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=3.463e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.270e+00
  param model_4__forward_module.module.conv1.weight grad-norm: mean=8.182e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.740e+00
  param model_4__forward_module.module.conv2.weight grad-norm: mean=6.808e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.005e+00
  param model_5__forward_module.module.conv1.weight grad-norm: mean=8.228e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.749e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=7.120e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.412e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.152e+01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=2.413e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.285e+01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.608e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.024e+01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.132e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=4.863e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.142e+00

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.84it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.83it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.84it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.82it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.83it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.81it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.98it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s]
Training epochs:   3%|â–Ž         | 1/32 [00:21<11:04, 21.43s/it]
Epoch 2/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]
Epoch 1/32 - Train Loss: 51.596623 - Test Loss: 46.605010
Training epochs:   3%|â–Ž         | 1/32 [00:21<11:04, 21.45s/it]
Epoch 2/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 2/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 2/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.55s/it][A

Epoch 2/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][AEpoch 2/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 2/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 2/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 2/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 2/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 2/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 2/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A

Epoch 2/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][AEpoch 2/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 2/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 2/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 2/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 2/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 2/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 2/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 2/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 2/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 2/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 2/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 2/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 2/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 2/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 2/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

[Î²=6.0] Epoch 2 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=8.964e-01
  layer model_7__forward_module.module.conv2 act-std: mean=6.736e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.146e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.589e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.510e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.504e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.552e-01
  layer model_4__forward_module.module.conv2 act-std: mean=1.994e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.280e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.274e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.068e+00
  layer model_2__forward_module.module.conv2 act-std: mean=3.896e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.238e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.511e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.375e+00
  layer model_0__forward_module.module.conv2 act-std: mean=7.914e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=5.490e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.235e+00
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.927e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=6.569e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.970e+00
  param model_1__forward_module.module.conv1.bias grad-norm: mean=4.330e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.450e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=5.009e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=1.003e+01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=2.173e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.503e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.074e+00

  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.186e+01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.547e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=3.460e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.270e+00
  param model_4__forward_module.module.conv1.weight grad-norm: mean=8.179e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.740e+00
  param model_4__forward_module.module.conv2.weight grad-norm: mean=6.805e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.005e+00
  param model_5__forward_module.module.conv1.weight grad-norm: mean=8.253e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.754e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=7.141e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.416e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.151e+01
Epoch 2/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it]  param model_6__forward_module.module.conv1.bias grad-norm: mean=2.411e+00[A
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.283e+01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.605e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.027e+01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.138e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=4.886e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.146e+00
Epoch 2/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.85it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.83it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.83it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.82it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.81it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Epoch 2/32 - Train Loss: 51.675930 - Test Loss: 46.604472
Training epochs:   6%|â–‹         | 2/32 [00:42<10:44, 21.49s/it]
Epoch 3/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:   6%|â–‹         | 2/32 [00:42<10:44, 21.49s/it]
Epoch 3/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 3/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 3/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 3/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 3/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A

Epoch 3/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][AEpoch 3/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A

Epoch 3/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][AEpoch 3/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 3/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 3/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A

Epoch 3/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][AEpoch 3/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 3/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 3/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A

Epoch 3/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][AEpoch 3/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A

Epoch 3/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][AEpoch 3/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A

Epoch 3/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][AEpoch 3/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 3/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.51s/it][A
Epoch 3/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.51s/it][A
Epoch 3/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.51s/it][A
Epoch 3/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 3/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.45s/it][AEpoch 3/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=6.0] Epoch 3 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=8.964e-01
  layer model_7__forward_module.module.conv2 act-std: mean=6.736e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.146e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.589e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.510e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.505e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.552e-01
  layer model_4__forward_module.module.conv2 act-std: mean=1.994e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.279e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.273e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.068e+00
  layer model_2__forward_module.module.conv2 act-std: mean=3.896e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.238e+00

  layer model_1__forward_module.module.conv2 act-std: mean=1.511e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.375e+00
  layer model_0__forward_module.module.conv2 act-std: mean=7.914e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=5.471e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.231e+00
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.924e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=6.547e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.966e+00
  param model_1__forward_module.module.conv1.bias grad-norm: mean=4.319e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.444e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=4.994e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=1.003e+01
Epoch 3/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.45s/it]  param model_2__forward_module.module.conv1.bias grad-norm: mean=2.173e+00[A
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.505e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.074e+00
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.187e+01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.549e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=3.462e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.270e+00
  param model_4__forward_module.module.conv1.weight grad-norm: mean=8.193e+00Epoch 3/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.743e+00
  param model_4__forward_module.module.conv2.weight grad-norm: mean=6.823e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.007e+00
  param model_5__forward_module.module.conv1.weight grad-norm: mean=8.228e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.748e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=7.120e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.411e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.152e+01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=2.413e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.285e+01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.607e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.026e+01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.136e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=4.877e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.144e+00


Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][AEvaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.85it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.84it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.83it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.82it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.83it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.83it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.99it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.97it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s]
Epoch 3/32 - Train Loss: 51.593744 - Test Loss: 46.603982
Training epochs:   9%|â–‰         | 3/32 [01:04<10:24, 21.55s/it]
Epoch 4/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:   9%|â–‰         | 3/32 [01:04<10:24, 21.55s/it]
Epoch 4/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 4/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][A
Epoch 4/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A

Epoch 4/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.51s/it][AEpoch 4/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.51s/it][A
Epoch 4/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.51s/it][A
Epoch 4/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.51s/it][A
Epoch 4/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.51s/it][A
Epoch 4/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.51s/it][A

Epoch 4/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.51s/it][AEpoch 4/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.51s/it][A
Epoch 4/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.51s/it][A
Epoch 4/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.51s/it][A
Epoch 4/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 4/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 4/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.51s/it][A
Epoch 4/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A

Epoch 4/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.51s/it][AEpoch 4/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.51s/it][A

Epoch 4/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.51s/it][AEpoch 4/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.51s/it][A

Epoch 4/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.51s/it][AEpoch 4/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.51s/it][A
Epoch 4/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.51s/it][A
Epoch 4/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.51s/it][A
Epoch 4/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 4/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.48s/it]

[Î²=6.0] Epoch 4 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=8.964e-01
  layer model_7__forward_module.module.conv2 act-std: mean=6.736e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.146e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.589e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.510e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.507e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.552e-01
  layer model_4__forward_module.module.conv2 act-std: mean=1.993e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.281e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.274e-01

  layer model_2__forward_module.module.conv1 act-std: mean=1.068e+00
  layer model_2__forward_module.module.conv2 act-std: mean=3.897e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.238e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.511e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.375e+00
  layer model_0__forward_module.module.conv2 act-std: mean=7.916e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=5.488e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.235e+00Epoch 4/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it]
[A  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.930e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=6.564e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.971e+00
  param model_1__forward_module.module.conv1.bias grad-norm: mean=4.333e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.451e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=5.007e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=1.002e+01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=2.171e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.500e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.072e+00Epoch 4/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.48s/it]

  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.184e+01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.543e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=3.454e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.267e+00
  param model_4__forward_module.module.conv1.weight grad-norm: mean=8.187e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.742e+00
  param model_4__forward_module.module.conv2.weight grad-norm: mean=6.817e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.006e+00
  param model_5__forward_module.module.conv1.weight grad-norm: mean=8.252e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.754e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=7.131e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.414e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.152e+01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=2.413e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.285e+01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.607e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.027e+01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.137e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=4.876e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.145e+00

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.81it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.83it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.82it/s][A

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.97it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]
Epoch 4/32 - Train Loss: 51.684889 - Test Loss: 46.603469
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.96it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]
Training epochs:  12%|â–ˆâ–Ž        | 4/32 [01:25<10:01, 21.48s/it]Training epochs:  12%|â–ˆâ–Ž        | 4/32 [01:25<10:01, 21.49s/it]
Epoch 5/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 5/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 5/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][AEpoch 5/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][A
Epoch 5/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.51s/it][A
Epoch 5/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.51s/it][A
Epoch 5/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.51s/it][A
Epoch 5/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.51s/it][A
Epoch 5/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.51s/it][A
Epoch 5/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.51s/it][A
Epoch 5/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.51s/it][A
Epoch 5/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.51s/it][A
Epoch 5/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.51s/it][A
Epoch 5/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.51s/it][A
Epoch 5/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.57s/it][A
Epoch 5/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.57s/it][A

Epoch 5/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.55s/it][AEpoch 5/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.55s/it][A
Epoch 5/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 5/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 5/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 5/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 5/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 5/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A

Epoch 5/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][AEpoch 5/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 5/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 5/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

Epoch 5/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 5/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=6.0] Epoch 5 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=8.965e-01
  layer model_7__forward_module.module.conv2 act-std: mean=6.737e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.146e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.589e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.510e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.507e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.552e-01
  layer model_4__forward_module.module.conv2 act-std: mean=1.994e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.281e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.273e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.068e+00
  layer model_2__forward_module.module.conv2 act-std: mean=3.896e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.238e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.511e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.375e+00
  layer model_0__forward_module.module.conv2 act-std: mean=7.917e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=5.475e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.232e+00
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.921e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=6.547e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.970e+00
  param model_1__forward_module.module.conv1.bias grad-norm: mean=4.328e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.446e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=5.000e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=1.001e+01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=2.170e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.500e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.072e+00
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.184e+01

  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.544e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=3.457e+00Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.267e+00
  param model_4__forward_module.module.conv1.weight grad-norm: mean=8.182e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.741e+00
  param model_4__forward_module.module.conv2.weight grad-norm: mean=6.810e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.006e+00
  param model_5__forward_module.module.conv1.weight grad-norm: mean=8.228e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.748e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=7.113e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.411e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.151e+01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=2.410e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.283e+01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.606e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.026e+01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.135e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=4.872e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.144e+00

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.83it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.83it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.82it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.82it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.97it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.96it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s]
Epoch 5/32 - Train Loss: 51.648318 - Test Loss: 46.603015
Training epochs:  16%|â–ˆâ–Œ        | 5/32 [01:47<09:41, 21.52s/it]
Epoch 6/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  16%|â–ˆâ–Œ        | 5/32 [01:47<09:41, 21.52s/it]
Epoch 6/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 6/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][A
Epoch 6/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A

Epoch 6/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.51s/it][AEpoch 6/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.51s/it][A
Epoch 6/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.51s/it][A
Epoch 6/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.51s/it][A

Epoch 6/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.51s/it][AEpoch 6/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.51s/it][A
Epoch 6/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.51s/it][A
Epoch 6/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.51s/it][A
Epoch 6/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.51s/it][A
Epoch 6/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 6/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.51s/it][A
Epoch 6/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.51s/it][A
Epoch 6/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.51s/it][A
Epoch 6/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.51s/it][A
Epoch 6/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.51s/it][A
Epoch 6/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.51s/it][A
Epoch 6/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.51s/it][A
Epoch 6/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.51s/it][A
Epoch 6/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 6/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A

Epoch 6/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][AEpoch 6/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A

Epoch 6/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 6/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 6/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]
Epoch 6/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.48s/it]

[Î²=6.0] Epoch 6 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=8.965e-01
  layer model_7__forward_module.module.conv2 act-std: mean=6.737e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.146e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.589e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.510e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.506e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.552e-01
  layer model_4__forward_module.module.conv2 act-std: mean=1.993e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.280e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.274e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.068e+00
  layer model_2__forward_module.module.conv2 act-std: mean=3.898e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.238e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.511e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.375e+00
  layer model_0__forward_module.module.conv2 act-std: mean=7.915e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=5.462e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.229e+00
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.921e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=6.538e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.967e+00
  param model_1__forward_module.module.conv1.bias grad-norm: mean=4.321e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.447e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=4.996e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=1.002e+01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=2.170e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.503e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.072e+00
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.186e+01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.547e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=3.465e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.269e+00
  param model_4__forward_module.module.conv1.weight grad-norm: mean=8.178e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.739e+00
  param model_4__forward_module.module.conv2.weight grad-norm: mean=6.807e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.005e+00
  param model_5__forward_module.module.conv1.weight grad-norm: mean=8.234e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.749e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=7.126e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.412e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.151e+01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=2.410e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.282e+01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.604e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.029e+01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.142e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=4.891e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.147e+00

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A

Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][AEvaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.81it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.81it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.96it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]
Training epochs:  19%|â–ˆâ–‰        | 6/32 [02:08<09:18, 21.49s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]
Epoch 6/32 - Train Loss: 51.667132 - Test Loss: 46.602540

Epoch 7/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  19%|â–ˆâ–‰        | 6/32 [02:08<09:18, 21.49s/it]
Epoch 7/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 7/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it]Epoch 7/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A[A
Epoch 7/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 7/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 7/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 7/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A

Epoch 7/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][AEpoch 7/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A

Epoch 7/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][AEpoch 7/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 7/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 7/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 7/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 7/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 7/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 7/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A

Epoch 7/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][AEpoch 7/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 7/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 7/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 7/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 7/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 7/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 7/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A

Epoch 7/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 7/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 7/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

[Î²=6.0] Epoch 7 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=8.964e-01Epoch 7/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

  layer model_7__forward_module.module.conv2 act-std: mean=6.736e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.146e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.589e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.510e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.504e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.553e-01
  layer model_4__forward_module.module.conv2 act-std: mean=1.994e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.281e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.275e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.068e+00
  layer model_2__forward_module.module.conv2 act-std: mean=3.897e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.238e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.511e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.375e+00
  layer model_0__forward_module.module.conv2 act-std: mean=7.915e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=5.462e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.229e+00
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.915e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=6.530e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.965e+00
  param model_1__forward_module.module.conv1.bias grad-norm: mean=4.319e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.440e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=4.977e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=9.995e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=2.166e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.497e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.070e+00
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.182e+01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.540e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=3.456e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.265e+00
  param model_4__forward_module.module.conv1.weight grad-norm: mean=8.184e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.741e+00
  param model_4__forward_module.module.conv2.weight grad-norm: mean=6.813e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.006e+00
  param model_5__forward_module.module.conv1.weight grad-norm: mean=8.242e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.751e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=7.129e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.413e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.151e+01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=2.410e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.284e+01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.606e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.027e+01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.137e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=4.883e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.145e+00

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A

Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.83it/s][AEvaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.84it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.82it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.81it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.81it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.96it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]
Epoch 7/32 - Train Loss: 51.669878 - Test Loss: 46.602085
Training epochs:  22%|â–ˆâ–ˆâ–       | 7/32 [02:30<08:57, 21.49s/it]
Epoch 8/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  22%|â–ˆâ–ˆâ–       | 7/32 [02:30<08:57, 21.49s/it]
Epoch 8/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 8/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.50s/it][AEpoch 8/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][A
Epoch 8/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.51s/it][A
Epoch 8/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.51s/it][A

Epoch 8/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.51s/it][AEpoch 8/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 8/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 8/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A

Epoch 8/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][AEpoch 8/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 8/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 8/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 8/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 8/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A

Epoch 8/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][AEpoch 8/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 8/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.51s/it][A
Epoch 8/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.51s/it][A

Epoch 8/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.51s/it][AEpoch 8/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.51s/it][A
Epoch 8/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.51s/it]
[AEpoch 8/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.51s/it][A
Epoch 8/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.51s/it][A
Epoch 8/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.51s/it][A
Epoch 8/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 8/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

[Î²=6.0] Epoch 8 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=8.963e-01
  layer model_7__forward_module.module.conv2 act-std: mean=6.736e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.146e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.589e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.510e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.505e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.551e-01
  layer model_4__forward_module.module.conv2 act-std: mean=1.994e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.279e-01

  layer model_3__forward_module.module.conv2 act-std: mean=3.272e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.068e+00
  layer model_2__forward_module.module.conv2 act-std: mean=3.896e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.238e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.510e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.375e+00
  layer model_0__forward_module.module.conv2 act-std: mean=7.913e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=5.462e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.229e+00
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.915e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=6.533e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.966e+00
Epoch 8/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it]  param model_1__forward_module.module.conv1.bias grad-norm: mean=4.320e-01[A
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.443e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=4.990e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=1.001e+01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=2.168e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.499e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.071e+00
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.185e+01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.545e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=3.461e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.268e+00
  param model_4__forward_module.module.conv1.weight grad-norm: mean=8.171e+00
Epoch 8/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.738e+00

  param model_4__forward_module.module.conv2.weight grad-norm: mean=6.801e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.004e+00
  param model_5__forward_module.module.conv1.weight grad-norm: mean=8.228e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.749e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=7.116e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.411e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.152e+01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=2.412e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.284e+01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.606e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.026e+01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.134e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=4.870e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.143e+00

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.83it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.82it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.82it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.82it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.97it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s]
Epoch 8/32 - Train Loss: 51.640344 - Test Loss: 46.601629
Training epochs:  25%|â–ˆâ–ˆâ–Œ       | 8/32 [02:51<08:35, 21.47s/it]
Epoch 9/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]
Training epochs:  25%|â–ˆâ–ˆâ–Œ       | 8/32 [02:51<08:35, 21.48s/it]
Epoch 9/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 9/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it]
[AEpoch 9/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.50s/it][A
Epoch 9/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 9/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.51s/it][A
Epoch 9/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.51s/it][A
Epoch 9/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A

Epoch 9/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.51s/it][AEpoch 9/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A

Epoch 9/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.51s/it][AEpoch 9/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.51s/it][A

Epoch 9/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.51s/it][AEpoch 9/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.51s/it][A
Epoch 9/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.51s/it][A
Epoch 9/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A

Epoch 9/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.51s/it][AEpoch 9/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.51s/it][A
Epoch 9/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 9/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 9/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 9/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A

Epoch 9/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.51s/it][AEpoch 9/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.51s/it][A
Epoch 9/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.51s/it][A
Epoch 9/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.51s/it][A
Epoch 9/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.39s/it][A
Epoch 9/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.39s/it][AEpoch 9/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.48s/it]

[Î²=6.0] Epoch 9 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=8.964e-01
Epoch 9/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.48s/it]  layer model_7__forward_module.module.conv2 act-std: mean=6.737e-01

  layer model_6__forward_module.module.conv1 act-std: mean=1.146e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.589e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.510e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.505e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.551e-01
  layer model_4__forward_module.module.conv2 act-std: mean=1.994e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.280e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.274e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.068e+00
  layer model_2__forward_module.module.conv2 act-std: mean=3.897e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.238e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.511e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.376e+00
  layer model_0__forward_module.module.conv2 act-std: mean=7.916e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=5.480e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.233e+00
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.924e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=6.554e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.971e+00
  param model_1__forward_module.module.conv1.bias grad-norm: mean=4.332e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.448e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=5.002e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=1.000e+01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=2.168e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.500e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.071e+00
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.183e+01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.541e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=3.455e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.266e+00
  param model_4__forward_module.module.conv1.weight grad-norm: mean=8.169e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.738e+00
  param model_4__forward_module.module.conv2.weight grad-norm: mean=6.800e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.004e+00
  param model_5__forward_module.module.conv1.weight grad-norm: mean=8.242e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.752e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=7.126e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.413e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.151e+01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=2.410e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.282e+01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.603e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.025e+01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.133e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=4.864e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.144e+00

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.82it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Epoch 9/32 - Train Loss: 51.663113 - Test Loss: 46.601145
Training epochs:  28%|â–ˆâ–ˆâ–Š       | 9/32 [03:13<08:13, 21.46s/it]
Epoch 10/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  28%|â–ˆâ–ˆâ–Š       | 9/32 [03:13<08:13, 21.46s/it]
Epoch 10/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 10/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][A
Epoch 10/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][A

Epoch 10/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.51s/it][AEpoch 10/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.51s/it][A

Epoch 10/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.51s/it][AEpoch 10/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.51s/it][A
Epoch 10/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.51s/it][A
Epoch 10/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.51s/it][A
Epoch 10/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.51s/it][A
Epoch 10/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.51s/it][A

Epoch 10/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][AEpoch 10/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 10/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 10/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A

Epoch 10/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][AEpoch 10/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 10/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 10/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A

Epoch 10/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][AEpoch 10/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 10/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 10/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 10/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 10/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 10/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 10/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

[Î²=6.0] Epoch 10 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=8.965e-01
  layer model_7__forward_module.module.conv2 act-std: mean=6.738e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.146e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.589e-01

  layer model_5__forward_module.module.conv1 act-std: mean=1.510e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.506e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.551e-01
  layer model_4__forward_module.module.conv2 act-std: mean=1.994e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.279e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.273e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.068e+00
  layer model_2__forward_module.module.conv2 act-std: mean=3.897e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.238e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.511e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.375e+00
  layer model_0__forward_module.module.conv2 act-std: mean=7.916e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=5.497e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.237e+00
Epoch 10/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it]  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.934e+00[A
  param model_0__forward_module.module.conv2.bias grad-norm: mean=6.583e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.966e+00
  param model_1__forward_module.module.conv1.bias grad-norm: mean=4.320e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.450e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=5.012e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=1.003e+01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=2.175e+00
Epoch 10/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.506e+00

  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.075e+00
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.186e+01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.547e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=3.463e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.270e+00
  param model_4__forward_module.module.conv1.weight grad-norm: mean=8.164e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.737e+00
  param model_4__forward_module.module.conv2.weight grad-norm: mean=6.791e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.003e+00
  param model_5__forward_module.module.conv1.weight grad-norm: mean=8.243e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.752e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=7.136e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.414e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.149e+01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=2.407e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.280e+01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.601e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.024e+01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.131e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=4.861e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.142e+00

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.76it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.81it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.82it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.81it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.96it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.96it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]
Epoch 10/32 - Train Loss: 51.636210 - Test Loss: 46.600718
Training epochs:  31%|â–ˆâ–ˆâ–ˆâ–      | 10/32 [03:34<07:52, 21.46s/it]
Epoch 11/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  31%|â–ˆâ–ˆâ–ˆâ–      | 10/32 [03:34<07:52, 21.46s/it]
Epoch 11/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 11/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.50s/it][AEpoch 11/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][A
Epoch 11/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.51s/it][A
Epoch 11/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.51s/it][A

Epoch 11/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.51s/it][AEpoch 11/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.51s/it][A

Epoch 11/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][AEpoch 11/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 11/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.51s/it]
[AEpoch 11/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.51s/it][A
Epoch 11/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 11/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A

Epoch 11/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.51s/it][AEpoch 11/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.51s/it][A

Epoch 11/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.51s/it][AEpoch 11/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.51s/it][A
Epoch 11/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.51s/it][A
Epoch 11/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.51s/it][A
Epoch 11/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.51s/it][A
Epoch 11/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.51s/it][A

Epoch 11/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.51s/it][AEpoch 11/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.51s/it][A

Epoch 11/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.51s/it][AEpoch 11/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.51s/it][A

Epoch 11/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.39s/it][AEpoch 11/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.48s/it]

[Î²=6.0] Epoch 11 summary:
  input  std: mean=1.814e+00
Epoch 11/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.39s/it]  layer model_7__forward_module.module.conv1 act-std: mean=8.964e-01[A
  layer model_7__forward_module.module.conv2 act-std: mean=6.737e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.146e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.589e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.510e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.506e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.551e-01
  layer model_4__forward_module.module.conv2 act-std: mean=1.994e+00Epoch 11/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.48s/it]

  layer model_3__forward_module.module.conv1 act-std: mean=6.280e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.274e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.068e+00
  layer model_2__forward_module.module.conv2 act-std: mean=3.897e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.238e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.511e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.375e+00
  layer model_0__forward_module.module.conv2 act-std: mean=7.914e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=5.475e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.232e+00
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.921e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=6.551e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.965e+00
  param model_1__forward_module.module.conv1.bias grad-norm: mean=4.318e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.448e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=5.000e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=1.003e+01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=2.173e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.505e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.074e+00
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.186e+01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.549e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=3.466e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.270e+00
  param model_4__forward_module.module.conv1.weight grad-norm: mean=8.178e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.740e+00
  param model_4__forward_module.module.conv2.weight grad-norm: mean=6.805e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.005e+00
  param model_5__forward_module.module.conv1.weight grad-norm: mean=8.234e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.750e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=7.123e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.412e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.151e+01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=2.410e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.282e+01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.603e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.028e+01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.138e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=4.883e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.146e+00

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.82it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.81it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.98it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.97it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s]
Epoch 11/32 - Train Loss: 51.668120 - Test Loss: 46.600241
Training epochs:  34%|â–ˆâ–ˆâ–ˆâ–      | 11/32 [03:56<07:30, 21.43s/it]
Epoch 12/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  34%|â–ˆâ–ˆâ–ˆâ–      | 11/32 [03:56<07:30, 21.44s/it]
Epoch 12/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 12/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.50s/it][AEpoch 12/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][A

Epoch 12/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.51s/it][AEpoch 12/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.51s/it][A
Epoch 12/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 12/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.51s/it][A
Epoch 12/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 12/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 12/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 12/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 12/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 12/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A

Epoch 12/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][AEpoch 12/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 12/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 12/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A

Epoch 12/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][AEpoch 12/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 12/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 12/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 12/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 12/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A

Epoch 12/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.51s/it][AEpoch 12/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.51s/it][A
Epoch 12/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 12/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

Epoch 12/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 12/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

[Î²=6.0] Epoch 12 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=8.966e-01
  layer model_7__forward_module.module.conv2 act-std: mean=6.740e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.146e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.590e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.510e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.511e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.552e-01
  layer model_4__forward_module.module.conv2 act-std: mean=1.994e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.281e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.276e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.068e+00

  layer model_2__forward_module.module.conv2 act-std: mean=3.899e-01
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  layer model_1__forward_module.module.conv1 act-std: mean=1.238e+00[A
  layer model_1__forward_module.module.conv2 act-std: mean=1.511e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.375e+00
  layer model_0__forward_module.module.conv2 act-std: mean=7.918e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=5.499e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.237e+00
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.931e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=6.580e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.968e+00
  param model_1__forward_module.module.conv1.bias grad-norm: mean=4.328e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.446e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=4.997e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=1.001e+01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=2.169e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.498e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.072e+00
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.182e+01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.539e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=3.450e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.265e+00
  param model_4__forward_module.module.conv1.weight grad-norm: mean=8.164e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.737e+00
  param model_4__forward_module.module.conv2.weight grad-norm: mean=6.797e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.004e+00
  param model_5__forward_module.module.conv1.weight grad-norm: mean=8.245e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.753e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=7.135e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.414e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.151e+01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=2.411e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.282e+01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.604e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.025e+01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.133e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=4.875e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.144e+00

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]
Training epochs:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 12/32 [04:17<07:08, 21.44s/it]
Epoch 13/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Epoch 12/32 - Train Loss: 51.639543 - Test Loss: 46.599794
Training epochs:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 12/32 [04:17<07:08, 21.45s/it]
Epoch 13/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 13/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 13/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 13/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.51s/it][A
Epoch 13/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 13/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.51s/it][A
Epoch 13/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 13/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 13/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 13/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 13/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A

Epoch 13/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][AEpoch 13/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 13/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 13/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 13/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 13/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 13/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 13/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 13/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 13/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 13/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 13/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 13/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.57s/it][A
Epoch 13/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.57s/it][A
Epoch 13/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.44s/it][AEpoch 13/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

Epoch 13/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.44s/it][AEpoch 13/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=6.0] Epoch 13 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=8.965e-01
  layer model_7__forward_module.module.conv2 act-std: mean=6.738e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.146e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.589e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.510e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.508e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.553e-01
  layer model_4__forward_module.module.conv2 act-std: mean=1.994e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.280e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.274e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.068e+00
  layer model_2__forward_module.module.conv2 act-std: mean=3.898e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.238e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.511e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.375e+00
  layer model_0__forward_module.module.conv2 act-std: mean=7.916e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=5.473e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.232e+00
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.920e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=6.547e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.964e+00
  param model_1__forward_module.module.conv1.bias grad-norm: mean=4.317e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.447e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=4.996e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=9.992e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=2.165e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.495e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.070e+00
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.183e+01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.541e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=3.457e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.266e+00
  param model_4__forward_module.module.conv1.weight grad-norm: mean=8.160e+00

  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.736e+00
  param model_4__forward_module.module.conv2.weight grad-norm: mean=6.789e+00Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.003e+00
  param model_5__forward_module.module.conv1.weight grad-norm: mean=8.243e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.752e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=7.128e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.413e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.150e+01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=2.408e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.282e+01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.603e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.027e+01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.137e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=4.879e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.145e+00

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.82it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.82it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.83it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.81it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.98it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s]
Training epochs:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 13/32 [04:39<06:48, 21.51s/it]
Epoch 14/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.96it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]
Epoch 13/32 - Train Loss: 51.673620 - Test Loss: 46.599332
Training epochs:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 13/32 [04:39<06:48, 21.51s/it]
Epoch 14/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 14/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 14/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 14/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.51s/it][A
Epoch 14/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.51s/it][A
Epoch 14/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.50s/it][A
Epoch 14/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.51s/it][A

Epoch 14/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.51s/it][AEpoch 14/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.51s/it][A
Epoch 14/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.51s/it][A
Epoch 14/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.51s/it][A
Epoch 14/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.51s/it][A
Epoch 14/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.51s/it][A

Epoch 14/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.51s/it][AEpoch 14/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.51s/it][A
Epoch 14/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.51s/it][A
Epoch 14/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.51s/it][A

Epoch 14/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.51s/it][AEpoch 14/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.51s/it][A

Epoch 14/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.51s/it][AEpoch 14/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.51s/it][A
Epoch 14/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.51s/it][A
Epoch 14/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.51s/it][A
Epoch 14/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.51s/it][A
Epoch 14/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.51s/it][A
Epoch 14/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 14/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.48s/it]

[Î²=6.0] Epoch 14 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=8.964e-01
  layer model_7__forward_module.module.conv2 act-std: mean=6.737e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.146e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.590e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.510e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.505e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.553e-01
  layer model_4__forward_module.module.conv2 act-std: mean=1.994e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.279e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.274e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.068e+00
  layer model_2__forward_module.module.conv2 act-std: mean=3.897e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.238e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.511e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.376e+00

  layer model_0__forward_module.module.conv2 act-std: mean=7.916e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=5.462e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.229e+00
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.913e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=6.530e-01Epoch 14/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it]
[A  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.961e+00
  param model_1__forward_module.module.conv1.bias grad-norm: mean=4.312e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.435e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=4.977e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=9.992e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=2.165e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.494e+00
Epoch 14/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.48s/it]  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.070e+00

  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.182e+01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.540e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=3.453e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.265e+00
  param model_4__forward_module.module.conv1.weight grad-norm: mean=8.183e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.741e+00
  param model_4__forward_module.module.conv2.weight grad-norm: mean=6.811e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.006e+00
  param model_5__forward_module.module.conv1.weight grad-norm: mean=8.226e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.749e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=7.117e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.411e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.150e+01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=2.407e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.282e+01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.603e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.025e+01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.132e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=4.864e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.142e+00

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.84it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.82it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.82it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.82it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.81it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.96it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]
Epoch 14/32 - Train Loss: 51.586408 - Test Loss: 46.598886
Training epochs:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 14/32 [05:00<06:26, 21.47s/it]
Epoch 15/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 14/32 [05:00<06:26, 21.47s/it]
Epoch 15/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 15/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 15/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 15/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 15/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 15/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 15/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 15/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 15/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 15/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 15/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 15/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 15/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A

Epoch 15/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][AEpoch 15/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 15/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 15/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A

Epoch 15/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][AEpoch 15/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A

Epoch 15/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][AEpoch 15/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 15/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 15/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 15/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 15/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A

Epoch 15/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 15/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 15/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

[Î²=6.0] Epoch 15 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=8.964e-01
Epoch 15/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]  layer model_7__forward_module.module.conv2 act-std: mean=6.736e-01

  layer model_6__forward_module.module.conv1 act-std: mean=1.146e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.589e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.510e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.507e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.551e-01
  layer model_4__forward_module.module.conv2 act-std: mean=1.994e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.280e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.273e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.068e+00
  layer model_2__forward_module.module.conv2 act-std: mean=3.897e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.238e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.511e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.376e+00
  layer model_0__forward_module.module.conv2 act-std: mean=7.915e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=5.458e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.228e+00
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.915e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=6.530e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.963e+00
  param model_1__forward_module.module.conv1.bias grad-norm: mean=4.315e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.441e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=4.988e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=9.995e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=2.166e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.496e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.070e+00
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.183e+01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.541e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=3.454e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.266e+00
  param model_4__forward_module.module.conv1.weight grad-norm: mean=8.158e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.735e+00
  param model_4__forward_module.module.conv2.weight grad-norm: mean=6.786e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.002e+00
  param model_5__forward_module.module.conv1.weight grad-norm: mean=8.226e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.748e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=7.114e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.411e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.149e+01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=2.406e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.280e+01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.601e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.025e+01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.132e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=4.864e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.142e+00

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.96it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]
Training epochs:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 15/32 [05:22<06:05, 21.49s/it]
Epoch 16/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Epoch 15/32 - Train Loss: 51.598632 - Test Loss: 46.598454
Training epochs:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 15/32 [05:22<06:05, 21.49s/it]
Epoch 16/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 16/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][A
Epoch 16/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A

Epoch 16/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][AEpoch 16/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A

Epoch 16/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][AEpoch 16/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A

Epoch 16/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][AEpoch 16/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 16/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 16/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 16/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 16/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 16/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 16/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A

Epoch 16/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][AEpoch 16/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A

Epoch 16/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][AEpoch 16/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 16/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 16/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 16/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 16/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A

Epoch 16/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][AEpoch 16/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 16/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 16/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

Epoch 16/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 16/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

[Î²=6.0] Epoch 16 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=8.964e-01
  layer model_7__forward_module.module.conv2 act-std: mean=6.737e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.146e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.589e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.510e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.506e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.552e-01
  layer model_4__forward_module.module.conv2 act-std: mean=1.994e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.279e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.274e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.068e+00
  layer model_2__forward_module.module.conv2 act-std: mean=3.898e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.238e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.511e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.375e+00
  layer model_0__forward_module.module.conv2 act-std: mean=7.916e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=5.453e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.227e+00
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.911e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=6.528e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.962e+00
  param model_1__forward_module.module.conv1.bias grad-norm: mean=4.311e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.435e+00

  param model_1__forward_module.module.conv2.bias grad-norm: mean=4.969e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=9.972e+00Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  param model_2__forward_module.module.conv1.bias grad-norm: mean=2.161e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.492e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.067e+00
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.179e+01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.533e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=3.450e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.262e+00
  param model_4__forward_module.module.conv1.weight grad-norm: mean=8.172e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.738e+00
  param model_4__forward_module.module.conv2.weight grad-norm: mean=6.801e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.004e+00
  param model_5__forward_module.module.conv1.weight grad-norm: mean=8.232e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.750e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=7.115e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.411e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.149e+01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=2.406e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.282e+01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.603e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.024e+01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.131e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=4.866e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.142e+00

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A

Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.82it/s][AEvaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.82it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.83it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.81it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.81it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.96it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.96it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]
Epoch 16/32 - Train Loss: 51.580022 - Test Loss: 46.598029
Training epochs:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 16/32 [05:43<05:43, 21.49s/it]Training epochs:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 16/32 [05:43<05:43, 21.50s/it]
Epoch 17/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 17/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 17/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][A
Epoch 17/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][A
Epoch 17/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.51s/it][A
Epoch 17/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.51s/it][A

Epoch 17/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.51s/it][AEpoch 17/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.51s/it][A
Epoch 17/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.51s/it][A
Epoch 17/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.51s/it][A
Epoch 17/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.51s/it][A
Epoch 17/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.51s/it][A

Epoch 17/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.51s/it][AEpoch 17/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.51s/it][A
Epoch 17/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.51s/it][A
Epoch 17/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.51s/it][A

Epoch 17/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.51s/it][AEpoch 17/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.51s/it][A

Epoch 17/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.51s/it]Epoch 17/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.51s/it][A[A

Epoch 17/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][AEpoch 17/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 17/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 17/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 17/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 17/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 17/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 17/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

[Î²=6.0] Epoch 17 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=8.965e-01
  layer model_7__forward_module.module.conv2 act-std: mean=6.739e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.146e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.590e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.510e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.510e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.552e-01
  layer model_4__forward_module.module.conv2 act-std: mean=1.994e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.280e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.274e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.068e+00
  layer model_2__forward_module.module.conv2 act-std: mean=3.898e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.238e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.511e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.375e+00
  layer model_0__forward_module.module.conv2 act-std: mean=7.919e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=5.467e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.230e+00
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.917e+00

  param model_0__forward_module.module.conv2.bias grad-norm: mean=6.540e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.966e+00
  param model_1__forward_module.module.conv1.bias grad-norm: mean=4.323e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.442e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=4.990e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=9.975e+00
Epoch 17/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it]  param model_2__forward_module.module.conv1.bias grad-norm: mean=2.162e+00[A
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.494e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.068e+00
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.180e+01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.535e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=3.451e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.263e+00
  param model_4__forward_module.module.conv1.weight grad-norm: mean=8.155e+00
Epoch 17/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.735e+00

  param model_4__forward_module.module.conv2.weight grad-norm: mean=6.788e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.002e+00
  param model_5__forward_module.module.conv1.weight grad-norm: mean=8.229e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.749e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=7.113e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.410e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.149e+01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=2.406e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.281e+01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.602e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.025e+01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.134e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=4.866e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.143e+00


Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A[A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.84it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.82it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.82it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.82it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]
Epoch 17/32 - Train Loss: 51.689216 - Test Loss: 46.597608

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]
Training epochs:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 17/32 [06:05<05:22, 21.48s/it]
Epoch 18/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 17/32 [06:05<05:22, 21.48s/it]
Epoch 18/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 18/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][A
Epoch 18/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.50s/it][A
Epoch 18/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.51s/it][A
Epoch 18/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.51s/it][A
Epoch 18/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.51s/it][A
Epoch 18/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.51s/it][A
Epoch 18/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 18/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 18/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.51s/it][A
Epoch 18/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.51s/it][A
Epoch 18/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.51s/it][A
Epoch 18/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.51s/it][A

Epoch 18/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.57s/it][AEpoch 18/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.57s/it][A

Epoch 18/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.56s/it][AEpoch 18/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.56s/it][A
Epoch 18/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.55s/it][A
Epoch 18/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.55s/it][A
Epoch 18/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 18/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 18/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 18/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 18/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 18/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 18/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 18/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

Epoch 18/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 18/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=6.0] Epoch 18 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=8.965e-01
  layer model_7__forward_module.module.conv2 act-std: mean=6.737e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.146e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.589e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.510e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.507e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.552e-01
  layer model_4__forward_module.module.conv2 act-std: mean=1.994e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.280e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.275e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.068e+00
  layer model_2__forward_module.module.conv2 act-std: mean=3.898e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.238e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.511e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.375e+00
  layer model_0__forward_module.module.conv2 act-std: mean=7.917e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=5.464e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.230e+00

  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.915e+00
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  param model_0__forward_module.module.conv2.bias grad-norm: mean=6.537e-01[A
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.963e+00
  param model_1__forward_module.module.conv1.bias grad-norm: mean=4.316e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.438e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=4.983e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=9.995e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=2.166e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.497e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.071e+00
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.182e+01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.540e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=3.454e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.265e+00
  param model_4__forward_module.module.conv1.weight grad-norm: mean=8.169e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.738e+00
  param model_4__forward_module.module.conv2.weight grad-norm: mean=6.801e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.004e+00
  param model_5__forward_module.module.conv1.weight grad-norm: mean=8.233e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.750e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=7.117e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.411e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.148e+01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=2.404e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.280e+01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.601e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.025e+01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.133e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=4.870e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.143e+00

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A

Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][AEvaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.81it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.81it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.97it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s]
Training epochs:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 18/32 [06:26<05:01, 21.52s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.96it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]
Epoch 18/32 - Train Loss: 51.652031 - Test Loss: 46.597198

Epoch 19/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 18/32 [06:26<05:01, 21.52s/it]
Epoch 19/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 19/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 19/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A

Epoch 19/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][AEpoch 19/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A

Epoch 19/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][AEpoch 19/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A

Epoch 19/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][AEpoch 19/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A

Epoch 19/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][AEpoch 19/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 19/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 19/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 19/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 19/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 19/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 19/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 19/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.51s/it][A
Epoch 19/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 19/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.51s/it][A
Epoch 19/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.51s/it][A
Epoch 19/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.51s/it][A
Epoch 19/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A

Epoch 19/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.51s/it][AEpoch 19/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.51s/it][A
Epoch 19/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 19/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

Epoch 19/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 19/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

[Î²=6.0] Epoch 19 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=8.964e-01
  layer model_7__forward_module.module.conv2 act-std: mean=6.738e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.146e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.590e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.510e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.507e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.552e-01
  layer model_4__forward_module.module.conv2 act-std: mean=1.994e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.280e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.275e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.068e+00
  layer model_2__forward_module.module.conv2 act-std: mean=3.898e-01

  layer model_1__forward_module.module.conv1 act-std: mean=1.238e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.511e+00Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  layer model_0__forward_module.module.conv1 act-std: mean=1.375e+00
  layer model_0__forward_module.module.conv2 act-std: mean=7.920e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=5.455e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.227e+00
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.911e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=6.524e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.961e+00
  param model_1__forward_module.module.conv1.bias grad-norm: mean=4.310e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.435e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=4.974e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=9.979e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=2.162e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.493e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.069e+00
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.181e+01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.537e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=3.450e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.264e+00
  param model_4__forward_module.module.conv1.weight grad-norm: mean=8.151e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.734e+00
  param model_4__forward_module.module.conv2.weight grad-norm: mean=6.782e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.001e+00
  param model_5__forward_module.module.conv1.weight grad-norm: mean=8.210e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.745e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=7.100e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.408e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.148e+01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=2.403e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.278e+01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.599e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.023e+01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.129e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=4.853e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.140e+00

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.83it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.83it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.83it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.83it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.83it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.81it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]
Training epochs:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 19/32 [06:48<04:39, 21.51s/it]
Epoch 20/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Epoch 19/32 - Train Loss: 51.677389 - Test Loss: 46.596792
Training epochs:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 19/32 [06:48<04:39, 21.51s/it]
Epoch 20/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 20/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][AEpoch 20/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 20/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 20/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 20/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.51s/it]
[AEpoch 20/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 20/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 20/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 20/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 20/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 20/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 20/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 20/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 20/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A

Epoch 20/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][AEpoch 20/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 20/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 20/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A

Epoch 20/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][AEpoch 20/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 20/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 20/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A

Epoch 20/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][AEpoch 20/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A

Epoch 20/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 20/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

[Î²=6.0] Epoch 20 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=8.964e-01
  layer model_7__forward_module.module.conv2 act-std: mean=6.737e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.146e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.590e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.510e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.506e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.552e-01
  layer model_4__forward_module.module.conv2 act-std: mean=1.994e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.281e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.275e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.068e+00
  layer model_2__forward_module.module.conv2 act-std: mean=3.898e-01Epoch 20/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it]
[A  layer model_1__forward_module.module.conv1 act-std: mean=1.238e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.511e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.375e+00
  layer model_0__forward_module.module.conv2 act-std: mean=7.918e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=5.451e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.227e+00
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.909e+00Epoch 20/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

  param model_0__forward_module.module.conv2.bias grad-norm: mean=6.520e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.958e+00
  param model_1__forward_module.module.conv1.bias grad-norm: mean=4.305e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.433e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=4.970e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=9.985e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=2.164e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.493e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.069e+00
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.182e+01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.539e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=3.451e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.265e+00
  param model_4__forward_module.module.conv1.weight grad-norm: mean=8.144e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.733e+00
  param model_4__forward_module.module.conv2.weight grad-norm: mean=6.778e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.001e+00
  param model_5__forward_module.module.conv1.weight grad-norm: mean=8.220e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.747e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=7.109e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.409e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.148e+01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=2.404e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.279e+01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.600e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.025e+01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.132e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=4.863e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.142e+00

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A

Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][AEvaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.83it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.82it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.83it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.82it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.97it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.98it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s]
Epoch 20/32 - Train Loss: 51.638256 - Test Loss: 46.596380
Training epochs:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 20/32 [07:09<04:18, 21.51s/it]
Epoch 21/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 20/32 [07:09<04:18, 21.50s/it]
Epoch 21/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 21/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][AEpoch 21/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 21/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 21/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 21/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.51s/it][A
Epoch 21/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.51s/it][A
Epoch 21/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 21/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A

Epoch 21/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.51s/it][AEpoch 21/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.51s/it][A
Epoch 21/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.51s/it][A
Epoch 21/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.51s/it][A
Epoch 21/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.51s/it][A
Epoch 21/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.51s/it][A
Epoch 21/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.51s/it][A
Epoch 21/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.51s/it][A

Epoch 21/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.51s/it][AEpoch 21/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.51s/it][A
Epoch 21/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 21/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 21/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 21/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 21/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 21/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 21/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 21/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.48s/it]

[Î²=6.0] Epoch 21 summary:
  input  std: mean=1.813e+00
  layer model_7__forward_module.module.conv1 act-std: mean=8.964e-01
  layer model_7__forward_module.module.conv2 act-std: mean=6.737e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.146e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.589e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.510e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.507e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.552e-01
  layer model_4__forward_module.module.conv2 act-std: mean=1.994e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.280e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.275e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.068e+00
  layer model_2__forward_module.module.conv2 act-std: mean=3.898e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.238e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.511e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.376e+00
  layer model_0__forward_module.module.conv2 act-std: mean=7.915e-01

  param model_0__forward_module.module.conv1.weight grad-norm: mean=5.446e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.226e+00
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.910e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=6.518e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.962e+00
  param model_1__forward_module.module.conv1.bias grad-norm: mean=4.313e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.442e+00Epoch 21/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it]
[A  param model_1__forward_module.module.conv2.bias grad-norm: mean=4.988e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=9.968e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=2.160e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.489e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.067e+00
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.181e+01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.537e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=3.449e+00Epoch 21/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.264e+00
  param model_4__forward_module.module.conv1.weight grad-norm: mean=8.150e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.734e+00
  param model_4__forward_module.module.conv2.weight grad-norm: mean=6.784e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.001e+00
  param model_5__forward_module.module.conv1.weight grad-norm: mean=8.222e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.747e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=7.110e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.410e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.148e+01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=2.404e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.279e+01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.601e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.026e+01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.135e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=4.871e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.144e+00


Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][AEvaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:02,  1.35it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.60it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.81it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.67it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]
Training epochs:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 21/32 [07:31<03:56, 21.48s/it]
Epoch 22/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.74it/s]
Epoch 21/32 - Train Loss: 51.644668 - Test Loss: 46.595967
Training epochs:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 21/32 [07:31<03:56, 21.54s/it]
Epoch 22/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 22/32:   8%|â–Š         | 1/13 [00:01<00:20,  1.69s/it][A
Epoch 22/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.50s/it][A
Epoch 22/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.50s/it][A
Epoch 22/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:17,  1.58s/it][A
Epoch 22/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.50s/it][A
Epoch 22/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.55s/it][A
Epoch 22/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 22/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.51s/it][A
Epoch 22/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.51s/it][A
Epoch 22/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A

Epoch 22/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.51s/it][AEpoch 22/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A

Epoch 22/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.51s/it][AEpoch 22/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A

Epoch 22/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][AEpoch 22/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 22/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 22/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.51s/it][A

Epoch 22/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][AEpoch 22/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A

Epoch 22/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][AEpoch 22/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 22/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 22/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 22/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 22/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

Epoch 22/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 22/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

[Î²=6.0] Epoch 22 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=8.965e-01
  layer model_7__forward_module.module.conv2 act-std: mean=6.738e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.146e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.590e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.510e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.509e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.552e-01
  layer model_4__forward_module.module.conv2 act-std: mean=1.994e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.281e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.276e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.068e+00
  layer model_2__forward_module.module.conv2 act-std: mean=3.900e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.238e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.512e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.375e+00
  layer model_0__forward_module.module.conv2 act-std: mean=7.919e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=5.454e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.227e+00
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.914e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=6.529e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.963e+00
  param model_1__forward_module.module.conv1.bias grad-norm: mean=4.315e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.442e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=4.984e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=9.967e+00

  param model_2__forward_module.module.conv1.bias grad-norm: mean=2.160e+00
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.492e+00[A
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.067e+00
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.180e+01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.535e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=3.446e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.263e+00
  param model_4__forward_module.module.conv1.weight grad-norm: mean=8.149e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.734e+00
  param model_4__forward_module.module.conv2.weight grad-norm: mean=6.781e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.001e+00
  param model_5__forward_module.module.conv1.weight grad-norm: mean=8.225e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.748e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=7.116e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.410e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.147e+01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=2.402e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.278e+01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.599e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.024e+01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.131e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=4.865e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.142e+00

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]
Training epochs:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 22/32 [07:52<03:35, 21.53s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][A
Epoch 23/32:   0%|          | 0/13 [00:00<?, ?it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Epoch 22/32 - Train Loss: 51.681077 - Test Loss: 46.595559
Training epochs:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 22/32 [07:52<03:35, 21.52s/it]
Epoch 23/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 23/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][AEpoch 23/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 23/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 23/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A

Epoch 23/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][AEpoch 23/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A

Epoch 23/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][AEpoch 23/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 23/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 23/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 23/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 23/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 23/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 23/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A

Epoch 23/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][AEpoch 23/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A

Epoch 23/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][AEpoch 23/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A

Epoch 23/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][AEpoch 23/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A

Epoch 23/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][AEpoch 23/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A

Epoch 23/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][AEpoch 23/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 23/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][A
Epoch 23/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]
Epoch 23/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 23/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

[Î²=6.0] Epoch 23 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=8.966e-01
  layer model_7__forward_module.module.conv2 act-std: mean=6.739e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.146e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.590e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.510e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.511e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.553e-01
  layer model_4__forward_module.module.conv2 act-std: mean=1.995e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.281e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.277e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.068e+00
  layer model_2__forward_module.module.conv2 act-std: mean=3.900e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.238e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.512e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.375e+00
  layer model_0__forward_module.module.conv2 act-std: mean=7.919e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=5.450e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.226e+00
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.909e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=6.517e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.961e+00
  param model_1__forward_module.module.conv1.bias grad-norm: mean=4.308e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.435e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=4.971e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=9.960e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=2.158e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.489e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.066e+00
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.179e+01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.534e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=3.451e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.262e+00
  param model_4__forward_module.module.conv1.weight grad-norm: mean=8.149e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.734e+00
  param model_4__forward_module.module.conv2.weight grad-norm: mean=6.785e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.002e+00
  param model_5__forward_module.module.conv1.weight grad-norm: mean=8.218e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.747e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=7.108e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.409e+00

  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.147e+01
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  param model_6__forward_module.module.conv1.bias grad-norm: mean=2.402e+00[A
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.278e+01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.600e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.025e+01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.132e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=4.867e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.142e+00

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.77it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.82it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.98it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s]
Training epochs:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 23/32 [08:14<03:13, 21.53s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.96it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]
Epoch 23/32 - Train Loss: 51.647265 - Test Loss: 46.595245

Epoch 24/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 23/32 [08:14<03:13, 21.52s/it]
Epoch 24/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 24/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][A
Epoch 24/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 24/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.51s/it][A
Epoch 24/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 24/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 24/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.51s/it][A
Epoch 24/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 24/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A

Epoch 24/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.51s/it][AEpoch 24/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.51s/it][A

Epoch 24/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.51s/it][AEpoch 24/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.51s/it][A
Epoch 24/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.51s/it][A
Epoch 24/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.51s/it][A

Epoch 24/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.51s/it][AEpoch 24/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.51s/it][A

Epoch 24/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][AEpoch 24/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A

Epoch 24/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][AEpoch 24/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 24/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 24/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 24/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it]
[AEpoch 24/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 24/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][A
Epoch 24/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]
Epoch 24/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 24/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

[Î²=6.0] Epoch 24 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=8.964e-01
  layer model_7__forward_module.module.conv2 act-std: mean=6.737e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.146e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.590e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.510e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.508e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.552e-01
  layer model_4__forward_module.module.conv2 act-std: mean=1.994e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.281e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.276e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.068e+00
  layer model_2__forward_module.module.conv2 act-std: mean=3.900e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.238e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.512e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.375e+00
  layer model_0__forward_module.module.conv2 act-std: mean=7.917e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=5.444e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.225e+00
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.906e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=6.513e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.959e+00
  param model_1__forward_module.module.conv1.bias grad-norm: mean=4.306e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.432e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=4.966e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=9.957e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=2.158e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.488e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.066e+00
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.179e+01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.533e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=3.443e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.261e+00
  param model_4__forward_module.module.conv1.weight grad-norm: mean=8.139e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.732e+00
  param model_4__forward_module.module.conv2.weight grad-norm: mean=6.772e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.000e+00
  param model_5__forward_module.module.conv1.weight grad-norm: mean=8.215e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.746e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=7.102e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.408e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.146e+01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=2.399e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.277e+01

  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.598e+00
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.024e+01[A
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.130e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=4.862e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.141e+00

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A

Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][AEvaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.77it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.82it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.82it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.83it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.83it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.98it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s]
Epoch 24/32 - Train Loss: 51.621376 - Test Loss: 46.594839

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.97it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s]
Training epochs:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 24/32 [08:35<02:51, 21.50s/it]
Epoch 25/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 24/32 [08:35<02:52, 21.51s/it]
Epoch 25/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 25/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][A
Epoch 25/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][A

Epoch 25/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][AEpoch 25/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 25/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.51s/it][A
Epoch 25/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 25/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 25/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 25/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 25/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 25/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.51s/it][A
Epoch 25/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.51s/it][A
Epoch 25/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.51s/it][A
Epoch 25/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.51s/it][A
Epoch 25/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.51s/it][A
Epoch 25/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.51s/it][A

Epoch 25/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.51s/it][AEpoch 25/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.51s/it][A

Epoch 25/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][AEpoch 25/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 25/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 25/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 25/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.51s/it][A
Epoch 25/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.51s/it][A
Epoch 25/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 25/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.48s/it]

[Î²=6.0] Epoch 25 summary:
  input  std: mean=1.814e+00

  layer model_7__forward_module.module.conv1 act-std: mean=8.965e-01
  layer model_7__forward_module.module.conv2 act-std: mean=6.739e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.146e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.590e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.510e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.511e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.552e-01
  layer model_4__forward_module.module.conv2 act-std: mean=1.994e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.283e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.277e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.068e+00
  layer model_2__forward_module.module.conv2 act-std: mean=3.901e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.238e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.512e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.375e+00
  layer model_0__forward_module.module.conv2 act-std: mean=7.919e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=5.449e+00Epoch 25/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it]
[A  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.226e+00
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.911e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=6.522e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.961e+00
  param model_1__forward_module.module.conv1.bias grad-norm: mean=4.310e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.442e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=4.986e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=9.971e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=2.161e+00
Epoch 25/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.48s/it]  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.490e+00

  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.067e+00
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.181e+01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.537e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=3.450e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.264e+00
  param model_4__forward_module.module.conv1.weight grad-norm: mean=8.151e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.734e+00
  param model_4__forward_module.module.conv2.weight grad-norm: mean=6.783e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.002e+00
  param model_5__forward_module.module.conv1.weight grad-norm: mean=8.206e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.744e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=7.097e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.407e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.149e+01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=2.407e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.280e+01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.601e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.023e+01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.130e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=4.862e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.141e+00

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.82it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A

Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][AEvaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]
Epoch 25/32 - Train Loss: 51.686541 - Test Loss: 46.594420
Training epochs:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 25/32 [08:57<02:30, 21.49s/it]Training epochs:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 25/32 [08:57<02:30, 21.48s/it]

Epoch 26/32:   0%|          | 0/13 [00:00<?, ?it/s][AEpoch 26/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 26/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][A
Epoch 26/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 26/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 26/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 26/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 26/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 26/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 26/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A

Epoch 26/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.51s/it][AEpoch 26/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.51s/it][A
Epoch 26/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 26/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 26/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.51s/it][A
Epoch 26/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.51s/it][A

Epoch 26/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.51s/it][AEpoch 26/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.51s/it][A
Epoch 26/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.51s/it][A
Epoch 26/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.51s/it][A

Epoch 26/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.51s/it][AEpoch 26/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.51s/it][A

Epoch 26/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.51s/it][AEpoch 26/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.51s/it][A
Epoch 26/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.51s/it][A
Epoch 26/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.51s/it][A

Epoch 26/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 26/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 26/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.48s/it]
Epoch 26/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.48s/it]

[Î²=6.0] Epoch 26 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=8.964e-01
  layer model_7__forward_module.module.conv2 act-std: mean=6.738e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.146e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.589e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.510e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.508e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.552e-01
  layer model_4__forward_module.module.conv2 act-std: mean=1.994e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.281e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.277e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.068e+00
  layer model_2__forward_module.module.conv2 act-std: mean=3.899e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.238e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.512e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.375e+00
  layer model_0__forward_module.module.conv2 act-std: mean=7.918e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=5.452e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.227e+00
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.911e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=6.527e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.955e+00
  param model_1__forward_module.module.conv1.bias grad-norm: mean=4.299e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.433e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=4.969e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=9.987e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=2.164e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.494e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.069e+00
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.180e+01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.536e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=3.452e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.264e+00
  param model_4__forward_module.module.conv1.weight grad-norm: mean=8.158e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.735e+00
  param model_4__forward_module.module.conv2.weight grad-norm: mean=6.794e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.003e+00
  param model_5__forward_module.module.conv1.weight grad-norm: mean=8.223e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.748e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=7.113e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.410e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.148e+01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=2.405e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.279e+01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.600e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.023e+01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.129e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=4.856e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.140e+00

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.82it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.81it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.97it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s]
Training epochs:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 26/32 [09:18<02:08, 21.47s/it]
Epoch 27/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]
Epoch 26/32 - Train Loss: 51.585509 - Test Loss: 46.594012
Training epochs:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 26/32 [09:18<02:08, 21.47s/it]
Epoch 27/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 27/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][AEpoch 27/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 27/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 27/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A

Epoch 27/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][AEpoch 27/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 27/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 27/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 27/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 27/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 27/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it]
[AEpoch 27/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A

Epoch 27/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][AEpoch 27/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A

Epoch 27/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][AEpoch 27/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A

Epoch 27/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][AEpoch 27/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 27/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 27/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A

Epoch 27/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][AEpoch 27/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 27/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 27/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A

Epoch 27/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 27/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 27/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

[Î²=6.0] Epoch 27 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=8.966e-01
  layer model_7__forward_module.module.conv2 act-std: mean=6.740e-01
Epoch 27/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]  layer model_6__forward_module.module.conv1 act-std: mean=1.146e+00

  layer model_6__forward_module.module.conv2 act-std: mean=2.589e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.510e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.511e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.552e-01
  layer model_4__forward_module.module.conv2 act-std: mean=1.994e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.281e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.276e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.068e+00
  layer model_2__forward_module.module.conv2 act-std: mean=3.900e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.238e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.512e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.375e+00
  layer model_0__forward_module.module.conv2 act-std: mean=7.918e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=5.443e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.225e+00
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.907e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=6.516e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.955e+00
  param model_1__forward_module.module.conv1.bias grad-norm: mean=4.298e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.433e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=4.971e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=9.957e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=2.158e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.488e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.067e+00
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.179e+01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.533e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=3.446e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.262e+00
  param model_4__forward_module.module.conv1.weight grad-norm: mean=8.124e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.729e+00
  param model_4__forward_module.module.conv2.weight grad-norm: mean=6.767e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=9.988e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=8.228e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.749e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=7.123e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.412e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.145e+01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=2.398e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.276e+01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.596e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.024e+01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.132e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=4.862e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.142e+00

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.82it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]
Epoch 27/32 - Train Loss: 51.638228 - Test Loss: 46.593605
Training epochs:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 27/32 [09:40<01:47, 21.48s/it]
Epoch 28/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 27/32 [09:40<01:47, 21.48s/it]
Epoch 28/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 28/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 28/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][A
Epoch 28/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 28/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A

Epoch 28/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.51s/it][AEpoch 28/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.51s/it][A
Epoch 28/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.51s/it][A
Epoch 28/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.51s/it][A
Epoch 28/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 28/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 28/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 28/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 28/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 28/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 28/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it]
[AEpoch 28/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 28/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 28/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A

Epoch 28/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][AEpoch 28/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 28/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 28/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 28/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 28/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 28/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 28/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

[Î²=6.0] Epoch 28 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=8.965e-01
  layer model_7__forward_module.module.conv2 act-std: mean=6.739e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.146e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.590e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.510e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.509e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.553e-01
  layer model_4__forward_module.module.conv2 act-std: mean=1.994e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.281e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.277e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.068e+00
  layer model_2__forward_module.module.conv2 act-std: mean=3.900e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.238e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.512e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.375e+00
  layer model_0__forward_module.module.conv2 act-std: mean=7.918e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=5.450e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.226e+00
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.912e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=6.525e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.958e+00
  param model_1__forward_module.module.conv1.bias grad-norm: mean=4.303e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.436e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=4.971e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=9.956e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=2.158e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.488e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.066e+00
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.177e+01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.530e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=3.444e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.260e+00
  param model_4__forward_module.module.conv1.weight grad-norm: mean=8.143e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.733e+00
  param model_4__forward_module.module.conv2.weight grad-norm: mean=6.782e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.001e+00
  param model_5__forward_module.module.conv1.weight grad-norm: mean=8.221e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.747e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=7.107e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.409e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.146e+01

  param model_6__forward_module.module.conv1.bias grad-norm: mean=2.400e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.276e+01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.597e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.022e+01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.128e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=4.853e+00
Epoch 28/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it]  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.139e+00[A
Epoch 28/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.83it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.83it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]
Training epochs:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 28/32 [10:01<01:25, 21.49s/it]
Epoch 29/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Epoch 28/32 - Train Loss: 51.663959 - Test Loss: 46.593212
Training epochs:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 28/32 [10:01<01:25, 21.49s/it]
Epoch 29/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 29/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 29/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][A

Epoch 29/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][AEpoch 29/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A

Epoch 29/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][AEpoch 29/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 29/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 29/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A

Epoch 29/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][AEpoch 29/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A

Epoch 29/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][AEpoch 29/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 29/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 29/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A

Epoch 29/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.51s/it][AEpoch 29/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 29/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 29/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 29/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.51s/it][A
Epoch 29/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 29/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 29/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A

Epoch 29/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][AEpoch 29/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 29/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.45s/it][AEpoch 29/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=6.0] Epoch 29 summary:
  input  std: mean=1.813e+00
  layer model_7__forward_module.module.conv1 act-std: mean=8.966e-01
  layer model_7__forward_module.module.conv2 act-std: mean=6.739e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.146e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.590e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.510e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.511e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.553e-01
  layer model_4__forward_module.module.conv2 act-std: mean=1.994e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.282e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.277e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.068e+00
  layer model_2__forward_module.module.conv2 act-std: mean=3.901e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.238e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.512e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.375e+00
  layer model_0__forward_module.module.conv2 act-std: mean=7.921e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=5.434e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.223e+00
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.903e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=6.502e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.954e+00

  param model_1__forward_module.module.conv1.bias grad-norm: mean=4.295e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.431e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=4.962e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=9.965e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=2.159e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.489e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.067e+00Epoch 29/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.45s/it]
[A  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.179e+01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.534e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=3.444e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.262e+00
  param model_4__forward_module.module.conv1.weight grad-norm: mean=8.135e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.731e+00
  param model_4__forward_module.module.conv2.weight grad-norm: mean=6.773e+00
Epoch 29/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.000e+00

  param model_5__forward_module.module.conv1.weight grad-norm: mean=8.206e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.744e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=7.095e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.407e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.145e+01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=2.397e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.275e+01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.595e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.024e+01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.131e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=4.863e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.141e+00

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.77it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.76it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Training epochs:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 29/32 [10:23<01:04, 21.54s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Epoch 29/32 - Train Loss: 51.663916 - Test Loss: 46.592832

Epoch 30/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 29/32 [10:23<01:04, 21.54s/it]
Epoch 30/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 30/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 30/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 30/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 30/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 30/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 30/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A

Epoch 30/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][AEpoch 30/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A

Epoch 30/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][AEpoch 30/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A

Epoch 30/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][AEpoch 30/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A

Epoch 30/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][AEpoch 30/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A

Epoch 30/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][AEpoch 30/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A

Epoch 30/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][AEpoch 30/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A

Epoch 30/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][AEpoch 30/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A

Epoch 30/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][AEpoch 30/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A

Epoch 30/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][AEpoch 30/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A

Epoch 30/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 30/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 30/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]
Epoch 30/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

[Î²=6.0] Epoch 30 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=8.965e-01
  layer model_7__forward_module.module.conv2 act-std: mean=6.738e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.146e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.590e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.510e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.508e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.553e-01
  layer model_4__forward_module.module.conv2 act-std: mean=1.994e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.282e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.277e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.068e+00
  layer model_2__forward_module.module.conv2 act-std: mean=3.901e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.238e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.512e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.375e+00
  layer model_0__forward_module.module.conv2 act-std: mean=7.919e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=5.440e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.224e+00
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.905e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=6.509e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.961e+00
  param model_1__forward_module.module.conv1.bias grad-norm: mean=4.311e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.439e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=4.981e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=9.955e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=2.158e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.488e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.066e+00
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.180e+01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.534e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=3.448e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.263e+00
  param model_4__forward_module.module.conv1.weight grad-norm: mean=8.133e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.730e+00
  param model_4__forward_module.module.conv2.weight grad-norm: mean=6.767e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=9.993e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=8.220e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.747e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=7.108e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.409e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.145e+01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=2.397e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.276e+01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.596e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.023e+01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.130e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=4.858e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.140e+00

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.81it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.97it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]
Training epochs:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 30/32 [10:44<00:43, 21.53s/it]
Epoch 31/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Epoch 30/32 - Train Loss: 51.626450 - Test Loss: 46.592476
Training epochs:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 30/32 [10:44<00:43, 21.53s/it]
Epoch 31/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 31/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 31/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 31/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 31/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A

Epoch 31/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][AEpoch 31/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 31/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 31/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 31/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.51s/it][A
Epoch 31/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 31/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 31/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 31/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 31/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 31/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.51s/it][A
Epoch 31/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.51s/it][A
Epoch 31/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.51s/it][A
Epoch 31/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.51s/it][A

Epoch 31/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.51s/it][AEpoch 31/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.51s/it][A

Epoch 31/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.51s/it][AEpoch 31/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.51s/it][A
Epoch 31/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.51s/it][A
Epoch 31/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.51s/it][A
Epoch 31/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 31/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.48s/it]

[Î²=6.0] Epoch 31 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=8.965e-01
  layer model_7__forward_module.module.conv2 act-std: mean=6.738e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.146e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.589e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.510e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.508e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.552e-01
  layer model_4__forward_module.module.conv2 act-std: mean=1.994e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.281e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.276e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.068e+00
  layer model_2__forward_module.module.conv2 act-std: mean=3.900e-01

  layer model_1__forward_module.module.conv1 act-std: mean=1.238e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.511e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.375e+00
  layer model_0__forward_module.module.conv2 act-std: mean=7.918e-01
Epoch 31/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it]  param model_0__forward_module.module.conv1.weight grad-norm: mean=5.445e+00[A
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.225e+00
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.907e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=6.515e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.960e+00
  param model_1__forward_module.module.conv1.bias grad-norm: mean=4.310e-01
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.435e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=4.966e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=9.955e+00Epoch 31/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

  param model_2__forward_module.module.conv1.bias grad-norm: mean=2.158e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.492e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.066e+00
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.179e+01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.533e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=3.449e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.262e+00
  param model_4__forward_module.module.conv1.weight grad-norm: mean=8.134e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.731e+00
  param model_4__forward_module.module.conv2.weight grad-norm: mean=6.772e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=9.999e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=8.228e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.749e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=7.113e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.410e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.146e+01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=2.401e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.277e+01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.598e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.025e+01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.133e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=4.863e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.142e+00

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Epoch 31/32 - Train Loss: 51.665806 - Test Loss: 46.592093
Training epochs:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 31/32 [11:06<00:21, 21.51s/it]
Epoch 32/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 31/32 [11:06<00:21, 21.50s/it]
Epoch 32/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 32/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 32/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 32/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 32/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 32/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 32/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 32/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 32/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A

Epoch 32/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][AEpoch 32/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A

Epoch 32/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][AEpoch 32/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 32/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 32/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A

Epoch 32/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][AEpoch 32/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 32/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.51s/it][A
Epoch 32/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.51s/it][A

Epoch 32/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.51s/it][AEpoch 32/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.51s/it][A
Epoch 32/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 32/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 32/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.51s/it][A
Epoch 32/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 32/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 32/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

[Î²=6.0] Epoch 32 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=8.964e-01
  layer model_7__forward_module.module.conv2 act-std: mean=6.738e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.146e+00
  layer model_6__forward_module.module.conv2 act-std: mean=2.589e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.510e+00
  layer model_5__forward_module.module.conv2 act-std: mean=8.507e-01
  layer model_4__forward_module.module.conv1 act-std: mean=9.552e-01
  layer model_4__forward_module.module.conv2 act-std: mean=1.994e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.281e-01

  layer model_3__forward_module.module.conv2 act-std: mean=3.278e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.068e+00
  layer model_2__forward_module.module.conv2 act-std: mean=3.900e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.238e+00
Epoch 32/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it]  layer model_1__forward_module.module.conv2 act-std: mean=1.512e+00[A
  layer model_0__forward_module.module.conv1 act-std: mean=1.375e+00
  layer model_0__forward_module.module.conv2 act-std: mean=7.918e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=5.454e+00
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.227e+00
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.913e+00
  param model_0__forward_module.module.conv2.bias grad-norm: mean=6.529e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.957e+00
Epoch 32/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]  param model_1__forward_module.module.conv1.bias grad-norm: mean=4.303e-01

  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.437e+00
  param model_1__forward_module.module.conv2.bias grad-norm: mean=4.975e-01
  param model_2__forward_module.module.conv1.weight grad-norm: mean=9.958e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=2.158e+00
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.487e+00
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.066e+00
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.177e+01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.529e+00
  param model_3__forward_module.module.conv2.weight grad-norm: mean=3.441e+00
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.260e+00
  param model_4__forward_module.module.conv1.weight grad-norm: mean=8.131e+00
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.730e+00
  param model_4__forward_module.module.conv2.weight grad-norm: mean=6.773e+00
  param model_4__forward_module.module.conv2.bias grad-norm: mean=9.997e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=8.228e+00
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.749e+00
  param model_5__forward_module.module.conv2.weight grad-norm: mean=7.118e+00
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.411e+00
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.146e+01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=2.401e+00
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.277e+01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.598e+00
  param model_7__forward_module.module.conv1.weight grad-norm: mean=1.024e+01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.131e+00
  param model_7__forward_module.module.conv2.weight grad-norm: mean=4.863e+00
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.141e+00

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.84it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.83it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.85it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.54it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.82it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.62it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]
Epoch 32/32 - Train Loss: 51.597717 - Test Loss: 46.591705
Training epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [11:27<00:00, 21.49s/it]Training epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [11:27<00:00, 21.49s/it]
Loaded best models from epoch 32 with loss 46.591705

>>> Completed beta = 6.0
>>> Time for this beta: 0:11:28
>>> Total elapsed time: 1:32:14
==================================================

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.80it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.73it/s]
Training epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [11:28<00:00, 21.56s/it]Training epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [11:28<00:00, 21.50s/it]
End time: 2025-07-22 04:16:29
Total time: 1h 43m 3s
