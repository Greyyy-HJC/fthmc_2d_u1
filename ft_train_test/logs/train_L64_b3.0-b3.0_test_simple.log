 
>>> PBS_NODEFILE content:
sophia-gpu-12.lab.alcf.anl.gov
1n*1t
Tue Jul 22 03:19:24 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.127.05             Driver Version: 550.127.05     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:87:00.0 Off |                    0 |
| N/A   33C    P0             52W /  400W |       1MiB /  40960MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA A100-SXM4-40GB          Off |   00000000:90:00.0 Off |                    0 |
| N/A   32C    P0             55W /  400W |       1MiB /  40960MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2024 NVIDIA Corporation
Built on Thu_Mar_28_02:18:24_PDT_2024
Cuda compilation tools, release 12.4, V12.4.131
Build cuda_12.4.r12.4/compiler.34097967_0
Start time: 2025-07-22 03:19:25
Python 3.9.18
Python path: /lus/eagle/projects/fthmc/software/ml/bin/python
PYTHONPATH: /eagle/fthmc/run
You are using a CUDA device ('NVIDIA A100-SXM4-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 2 processes
----------------------------------------------------------------------------------------------------

============================================================
>>> CUDA device count: 2
PyTorch version: 2.5.0+cu124
CUDA available: True
>>> Arguments:
Lattice size: 64x64
Minimum beta: 3.0
Maximum beta: 3.0
Beta gap: 0.5
Number of epochs: 32
Batch size: 128
Number of subsets: 8
Number of workers: 0
Model tag: simple
Save tag: test_simple
Random seed: 2008
Identity initialization: True
Check Jacobian: False
Continue training: True
============================================================
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2
Trying to use torch.compile for optimized computation...
Successfully initialized torch.compile
Loaded best models from epoch 32 with loss 31.256616
>>> Loaded the best model at beta = 2.5 to continue training
Loaded data shape: torch.Size([4096, 2, 64, 64])
Training data shape: torch.Size([3276, 2, 64, 64])
Testing data shape: torch.Size([820, 2, 64, 64])

>>> Training the model at beta =  Training epochs:   0%|          | 0/32 [00:00<?, ?it/s]
Epoch 1/32:   0%|          | 0/13 [00:00<?, ?it/s][A3.0

>>> Training the model at beta = 3.0

Training epochs:   0%|          | 0/32 [00:00<?, ?it/s]
Epoch 1/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 1/32:   8%|â–Š         | 1/13 [00:17<03:33, 17.79s/it][A
Epoch 1/32:   8%|â–Š         | 1/13 [00:17<03:33, 17.77s/it][A

Epoch 1/32:  15%|â–ˆâ–Œ        | 2/13 [00:19<01:30,  8.26s/it][AEpoch 1/32:  15%|â–ˆâ–Œ        | 2/13 [00:19<01:30,  8.25s/it][A
Epoch 1/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:20<00:51,  5.19s/it][A
Epoch 1/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:20<00:51,  5.20s/it][A
Epoch 1/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:22<00:33,  3.74s/it][A
Epoch 1/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:22<00:33,  3.74s/it][A

Epoch 1/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:23<00:23,  2.94s/it][AEpoch 1/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:23<00:23,  2.94s/it][A
Epoch 1/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:25<00:17,  2.45s/it]
[AEpoch 1/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:25<00:17,  2.45s/it][A
Epoch 1/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:26<00:12,  2.14s/it][A
Epoch 1/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:26<00:12,  2.14s/it][A
Epoch 1/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:28<00:09,  1.95s/it][A
Epoch 1/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:28<00:09,  1.95s/it][A

Epoch 1/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:30<00:07,  1.82s/it][AEpoch 1/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:30<00:07,  1.82s/it][A

Epoch 1/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:31<00:05,  1.74s/it][AEpoch 1/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:31<00:05,  1.74s/it][A
Epoch 1/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:33<00:03,  1.68s/it][A
Epoch 1/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:33<00:03,  1.68s/it][A

Epoch 1/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:34<00:01,  1.63s/it][AEpoch 1/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:34<00:01,  1.64s/it][A
Epoch 1/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:35<00:00,  1.49s/it][A
Epoch 1/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:35<00:00,  2.75s/it]
Epoch 1/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:35<00:00,  1.49s/it][AEpoch 1/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:35<00:00,  2.76s/it]

[Î²=3.0] Epoch 1 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.726e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.604e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.116e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.090e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.418e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.817e-01
  layer model_4__forward_module.module.conv1 act-std: mean=1.012e+00
  layer model_4__forward_module.module.conv2 act-std: mean=1.660e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.388e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.014e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.003e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.738e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.135e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.482e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.245e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.849e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=6.614e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=1.528e-01
  param model_0__forward_module.module.conv2.weight grad-norm: mean=5.049e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=1.003e-01
  param model_1__forward_module.module.conv1.weight grad-norm: mean=2.621e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=5.533e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=4.514e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=8.473e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=1.473e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=3.278e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=4.843e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.777e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.505e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=3.314e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=5.938e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.988e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=9.036e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.962e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=8.477e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=1.240e-01
  param model_5__forward_module.module.conv1.weight grad-norm: mean=8.226e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.799e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=8.535e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=1.588e-01
  param model_6__forward_module.module.conv1.weight grad-norm: mean=1.352e+00
  param model_6__forward_module.module.conv1.bias grad-norm: mean=2.906e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=1.504e+00
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.953e-01

  param model_7__forward_module.module.conv1.weight grad-norm: mean=9.819e-01
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  param model_7__forward_module.module.conv1.bias grad-norm: mean=2.051e-01[A
  param model_7__forward_module.module.conv2.weight grad-norm: mean=6.607e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=1.369e-01

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.88it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.87it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.86it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.86it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.84it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.82it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s]
Epoch 1/32 - Train Loss: 38.605439 - Test Loss: 34.870425

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][ATraining epochs:   3%|â–Ž         | 1/32 [00:37<19:35, 37.91s/it]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]

Epoch 2/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:   3%|â–Ž         | 1/32 [00:37<19:36, 37.95s/it]
Epoch 2/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 2/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.49s/it][A
Epoch 2/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][A
Epoch 2/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.51s/it][A
Epoch 2/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.51s/it][A
Epoch 2/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.50s/it][A
Epoch 2/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.50s/it][A
Epoch 2/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.50s/it][A
Epoch 2/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:13,  1.50s/it][A
Epoch 2/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.50s/it][A
Epoch 2/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.50s/it][A
Epoch 2/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.51s/it][A
Epoch 2/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.51s/it][A
Epoch 2/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.51s/it][A
Epoch 2/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.51s/it][A
Epoch 2/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.51s/it][A
Epoch 2/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.51s/it][A
Epoch 2/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.51s/it][A
Epoch 2/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.51s/it][A

Epoch 2/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.51s/it][AEpoch 2/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.51s/it][A
Epoch 2/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.51s/it][A
Epoch 2/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.51s/it][A
Epoch 2/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.51s/it][A
Epoch 2/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.51s/it][A

Epoch 2/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.39s/it][AEpoch 2/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.39s/it][AEpoch 2/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.48s/it]
Epoch 2/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.48s/it]

[Î²=3.0] Epoch 2 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.754e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.625e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.118e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.093e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.414e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.959e-01
  layer model_4__forward_module.module.conv1 act-std: mean=1.011e+00
  layer model_4__forward_module.module.conv2 act-std: mean=1.725e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.391e-01
  layer model_3__forward_module.module.conv2 act-std: mean=3.988e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.007e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.701e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.144e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.492e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.247e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.742e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=3.556e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=8.097e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=3.331e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=6.248e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.879e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=3.790e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=3.523e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=6.673e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=1.046e+00
  param model_2__forward_module.module.conv1.bias grad-norm: mean=2.331e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=3.556e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=1.275e-01
  param model_3__forward_module.module.conv1.weight grad-norm: mean=1.102e+00
  param model_3__forward_module.module.conv1.bias grad-norm: mean=2.440e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=4.606e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=1.474e-01
  param model_4__forward_module.module.conv1.weight grad-norm: mean=5.272e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.163e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=5.275e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=7.176e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.808e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=5.682e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=3.388e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=5.709e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=8.435e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.822e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=9.259e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.210e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=4.306e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=8.543e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.513e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=5.701e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.84it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.84it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.85it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.84it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.85it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.85it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  2.01it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s]
Epoch 2/32 - Train Loss: 38.572531 - Test Loss: 34.840862
Training epochs:   6%|â–‹         | 2/32 [00:59<14:04, 28.14s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.99it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s]

Epoch 3/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:   6%|â–‹         | 2/32 [00:59<14:04, 28.16s/it]
Epoch 3/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 3/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 3/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][A

Epoch 3/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.50s/it][AEpoch 3/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.51s/it][A

Epoch 3/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.51s/it][AEpoch 3/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.51s/it][A
Epoch 3/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.51s/it][A
Epoch 3/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.51s/it][A

Epoch 3/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.51s/it][AEpoch 3/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.51s/it][A
Epoch 3/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.51s/it][A
Epoch 3/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.51s/it][A
Epoch 3/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.51s/it][A
Epoch 3/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.51s/it][A

Epoch 3/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.51s/it][AEpoch 3/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.51s/it][A

Epoch 3/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.51s/it][AEpoch 3/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.51s/it][A
Epoch 3/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.51s/it][A
Epoch 3/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.51s/it][A
Epoch 3/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.51s/it][A
Epoch 3/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.51s/it][A
Epoch 3/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.51s/it][A
Epoch 3/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.51s/it][A
Epoch 3/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 3/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.48s/it]

[Î²=3.0] Epoch 3 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.751e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.677e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.119e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.110e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.418e+00
  layer model_5__forward_module.module.conv2 act-std: mean=1.013e+00
  layer model_4__forward_module.module.conv1 act-std: mean=1.011e+00
  layer model_4__forward_module.module.conv2 act-std: mean=1.804e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.393e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.011e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.007e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.718e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.151e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.531e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.255e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.897e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.871e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=6.384e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.835e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=5.203e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.501e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.918e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.821e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=4.951e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=4.624e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=9.763e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.169e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=5.933e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=5.408e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.147e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.703e-01

  param model_3__forward_module.module.conv2.bias grad-norm: mean=7.355e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=4.796e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.007e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=5.036e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=6.934e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.698e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=5.418e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=3.197e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=5.364e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=5.421e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.103e-01Epoch 3/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it]
[A  param model_6__forward_module.module.conv2.weight grad-norm: mean=7.008e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=8.674e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=4.102e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=8.372e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.375e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=5.307e-02
Epoch 3/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.48s/it]

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.82it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Epoch 3/32 - Train Loss: 38.501658 - Test Loss: 34.830876

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Training epochs:   9%|â–‰         | 3/32 [01:20<12:07, 25.08s/it]Training epochs:   9%|â–‰         | 3/32 [01:20<12:07, 25.08s/it]
Epoch 4/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 4/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 4/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 4/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 4/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 4/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 4/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 4/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 4/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 4/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 4/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 4/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 4/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 4/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A

Epoch 4/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][AEpoch 4/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 4/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 4/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 4/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 4/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 4/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.51s/it][A
Epoch 4/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.51s/it][A
Epoch 4/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.51s/it][A
Epoch 4/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A

Epoch 4/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.51s/it][AEpoch 4/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.51s/it][A
Epoch 4/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][A
Epoch 4/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]
Epoch 4/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 4/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

[Î²=3.0] Epoch 4 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.738e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.710e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.121e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.111e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.425e+00
  layer model_5__forward_module.module.conv2 act-std: mean=1.039e+00
  layer model_4__forward_module.module.conv1 act-std: mean=1.007e+00
  layer model_4__forward_module.module.conv2 act-std: mean=1.874e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.409e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.029e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.007e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.712e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.154e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.560e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.260e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.934e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.378e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=2.719e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.067e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.077e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.159e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.151e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.884e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.719e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.112e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=6.163e-02

  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.850e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=4.507e-02Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  param model_3__forward_module.module.conv1.weight grad-norm: mean=4.444e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=9.320e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.498e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=6.446e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=4.339e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=9.087e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=4.544e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=6.222e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.683e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=5.056e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=3.178e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=5.218e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.713e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=6.909e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=5.597e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=6.755e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=4.585e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=8.897e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.493e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=5.838e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.86it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.84it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.86it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.82it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.85it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.82it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.98it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s]
Epoch 4/32 - Train Loss: 38.506792 - Test Loss: 34.815697
Training epochs:  12%|â–ˆâ–Ž        | 4/32 [01:42<11:02, 23.64s/it]
Epoch 5/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]
Training epochs:  12%|â–ˆâ–Ž        | 4/32 [01:42<11:02, 23.66s/it]
Epoch 5/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 5/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][A
Epoch 5/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 5/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 5/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.51s/it][A
Epoch 5/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 5/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.51s/it][A

Epoch 5/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.51s/it][AEpoch 5/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.51s/it][A
Epoch 5/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 5/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.51s/it][A
Epoch 5/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.51s/it][A
Epoch 5/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.51s/it][A

Epoch 5/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][AEpoch 5/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.51s/it][A

Epoch 5/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][AEpoch 5/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 5/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 5/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 5/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 5/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 5/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 5/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 5/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 5/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 5/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 5/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

Epoch 5/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 5/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

[Î²=3.0] Epoch 5 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.710e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.730e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.122e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.114e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.429e+00
  layer model_5__forward_module.module.conv2 act-std: mean=1.050e+00
  layer model_4__forward_module.module.conv1 act-std: mean=1.008e+00
  layer model_4__forward_module.module.conv2 act-std: mean=1.954e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.435e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.055e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.006e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.711e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.155e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.574e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.262e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.919e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.444e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=2.836e-02

  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.901e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.760e-02Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.057e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=1.878e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.816e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.431e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.354e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=6.824e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.920e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=4.814e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.190e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=6.380e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.236e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=5.112e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.813e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=5.395e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.366e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=4.026e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=4.456e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=9.532e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=4.822e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=8.645e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.842e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=7.385e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.956e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.646e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=4.879e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.020e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.794e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=6.388e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A

Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.86it/s][AEvaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.85it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.83it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.83it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.82it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.81it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.96it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s]
Epoch 5/32 - Train Loss: 38.486034 - Test Loss: 34.800064

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]
Training epochs:  16%|â–ˆâ–Œ        | 5/32 [02:03<10:17, 22.86s/it]
Epoch 6/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  16%|â–ˆâ–Œ        | 5/32 [02:03<10:17, 22.86s/it]
Epoch 6/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 6/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.50s/it][A
Epoch 6/32:   8%|â–Š         | 1/13 [00:01<00:17,  1.50s/it][A
Epoch 6/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 6/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 6/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 6/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A

Epoch 6/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][AEpoch 6/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 6/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it]
[AEpoch 6/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 6/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 6/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A

Epoch 6/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][AEpoch 6/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 6/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 6/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 6/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 6/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 6/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 6/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A

Epoch 6/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][AEpoch 6/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 6/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 6/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 6/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][A
Epoch 6/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=3.0] Epoch 6 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.693e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.800e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.124e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.117e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.429e+00
  layer model_5__forward_module.module.conv2 act-std: mean=1.070e+00
  layer model_4__forward_module.module.conv1 act-std: mean=1.005e+00
  layer model_4__forward_module.module.conv2 act-std: mean=2.028e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.450e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.077e-01
Epoch 6/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it]  layer model_2__forward_module.module.conv1 act-std: mean=1.011e+00[A
  layer model_2__forward_module.module.conv2 act-std: mean=4.713e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.162e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.604e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.271e+00
  layer model_0__forward_module.module.conv2 act-std: mean=8.994e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.057e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=4.337e-02Epoch 6/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.929e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.876e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.310e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.677e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.951e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.655e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=2.167e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=3.990e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.661e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.132e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.670e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=7.523e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.373e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=5.131e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=3.522e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=7.161e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=4.071e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=5.247e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=3.383e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=6.801e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=3.751e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=6.655e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=5.173e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.064e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=6.646e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=8.142e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=4.438e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=9.001e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.685e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=6.166e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A

Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.85it/s][AEvaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.84it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.84it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.84it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.83it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.83it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.97it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s]
Epoch 6/32 - Train Loss: 38.421484 - Test Loss: 34.787187

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.97it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s]
Training epochs:  19%|â–ˆâ–‰        | 6/32 [02:25<09:42, 22.42s/it]
Epoch 7/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  19%|â–ˆâ–‰        | 6/32 [02:25<09:42, 22.42s/it]
Epoch 7/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 7/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 7/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 7/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 7/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.51s/it][A

Epoch 7/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][AEpoch 7/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 7/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 7/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A

Epoch 7/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][AEpoch 7/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 7/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 7/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 7/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 7/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A

Epoch 7/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][AEpoch 7/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 7/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 7/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 7/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 7/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.52s/it][A
Epoch 7/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 7/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A
Epoch 7/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 7/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 7/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.40s/it][AEpoch 7/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]

[Î²=3.0] Epoch 7 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.694e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.815e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.126e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.135e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.434e+00

  layer model_5__forward_module.module.conv2 act-std: mean=1.087e+00
  layer model_4__forward_module.module.conv1 act-std: mean=1.004e+00
  layer model_4__forward_module.module.conv2 act-std: mean=2.101e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.477e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.096e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.009e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.739e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.163e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.617e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.273e+00
  layer model_0__forward_module.module.conv2 act-std: mean=9.013e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.784e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=3.710e-02Epoch 7/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it]
[A  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.865e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.739e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.526e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=3.360e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.127e-01
Epoch 7/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.250e-02

  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.935e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=8.481e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.044e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=5.534e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.920e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=8.182e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.402e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=5.938e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=3.048e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=6.328e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.536e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=4.573e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.582e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=4.981e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.777e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=4.528e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=5.176e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.031e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=7.031e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=8.646e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.656e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=7.090e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.109e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.588e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A

Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][AEvaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.81it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.81it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.96it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]
Epoch 7/32 - Train Loss: 38.426339 - Test Loss: 34.782802

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]
Training epochs:  22%|â–ˆâ–ˆâ–       | 7/32 [02:46<09:13, 22.12s/it]
Epoch 8/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  22%|â–ˆâ–ˆâ–       | 7/32 [02:46<09:12, 22.12s/it]
Epoch 8/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 8/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 8/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A

Epoch 8/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][AEpoch 8/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 8/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 8/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A

Epoch 8/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][AEpoch 8/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 8/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 8/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 8/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 8/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A

Epoch 8/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][AEpoch 8/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 8/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 8/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A

Epoch 8/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it]Epoch 8/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A[A
Epoch 8/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 8/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A

Epoch 8/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it]Epoch 8/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.52s/it][A[A
Epoch 8/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 8/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.52s/it][A
Epoch 8/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 8/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

Epoch 8/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 8/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=3.0] Epoch 8 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.677e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.864e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.129e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.135e-01

  layer model_5__forward_module.module.conv1 act-std: mean=1.435e+00
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  layer model_5__forward_module.module.conv2 act-std: mean=1.097e+00[A
  layer model_4__forward_module.module.conv1 act-std: mean=1.001e+00
  layer model_4__forward_module.module.conv2 act-std: mean=2.173e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.498e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.129e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.011e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.736e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.172e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.625e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.282e+00
  layer model_0__forward_module.module.conv2 act-std: mean=9.012e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.007e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=4.361e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.120e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.449e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.262e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.428e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.911e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.733e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=4.182e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=8.858e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.027e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=5.662e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.164e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=6.422e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.320e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=5.005e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=3.337e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=6.696e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.979e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=4.809e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=3.186e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=6.575e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=3.260e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=5.888e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.191e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=5.831e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=4.692e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.515e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=4.607e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=9.562e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.648e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=6.451e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.75it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.76it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.56it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Training epochs:  25%|â–ˆâ–ˆâ–Œ       | 8/32 [03:08<08:47, 21.96s/it]
Epoch 9/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.76it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.72it/s]
Epoch 8/32 - Train Loss: 38.439813 - Test Loss: 34.766232
Training epochs:  25%|â–ˆâ–ˆâ–Œ       | 8/32 [03:08<08:48, 22.02s/it]
Epoch 9/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 9/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][A
Epoch 9/32:   8%|â–Š         | 1/13 [00:01<00:20,  1.69s/it][A

Epoch 9/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:17,  1.59s/it][AEpoch 9/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 9/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.56s/it][A
Epoch 9/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A

Epoch 9/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][AEpoch 9/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 9/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 9/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 9/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 9/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 9/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 9/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.52s/it][A
Epoch 9/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 9/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.52s/it][A
Epoch 9/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 9/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.52s/it][A
Epoch 9/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 9/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 9/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 9/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 9/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 9/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A

Epoch 9/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 9/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.49s/it]
Epoch 9/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][A
[Î²=3.0] Epoch 9 summary:
  input  std: mean=1.814e+00
Epoch 9/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]  layer model_7__forward_module.module.conv1 act-std: mean=9.681e-01

  layer model_7__forward_module.module.conv2 act-std: mean=7.916e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.132e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.140e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.440e+00
  layer model_5__forward_module.module.conv2 act-std: mean=1.103e+00
  layer model_4__forward_module.module.conv1 act-std: mean=1.001e+00
  layer model_4__forward_module.module.conv2 act-std: mean=2.251e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.532e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.159e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.012e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.760e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.176e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.648e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.281e+00
  layer model_0__forward_module.module.conv2 act-std: mean=9.108e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.559e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=3.164e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.178e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.464e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.165e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.149e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.233e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.390e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.163e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=6.355e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.078e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=4.766e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.514e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=7.210e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.415e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=5.306e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.512e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=4.814e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.217e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.634e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.762e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=5.184e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=3.279e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=5.285e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=4.492e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=9.002e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=5.571e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=6.737e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=4.631e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=9.329e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.453e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=5.472e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.84it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.83it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.82it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.81it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.96it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]
Epoch 9/32 - Train Loss: 38.390751 - Test Loss: 34.753121

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.96it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]
Training epochs:  28%|â–ˆâ–ˆâ–Š       | 9/32 [03:30<08:23, 21.88s/it]
Epoch 10/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  28%|â–ˆâ–ˆâ–Š       | 9/32 [03:30<08:23, 21.89s/it]
Epoch 10/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 10/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][AEpoch 10/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 10/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 10/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 10/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 10/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A

Epoch 10/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:14,  1.59s/it][AEpoch 10/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:14,  1.59s/it][A
Epoch 10/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.57s/it][A
Epoch 10/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.57s/it][A
Epoch 10/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.55s/it][A
Epoch 10/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.56s/it][A
Epoch 10/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 10/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 10/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 10/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 10/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 10/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 10/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 10/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A

Epoch 10/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][AEpoch 10/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A

Epoch 10/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it]Epoch 10/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A[A
Epoch 10/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 10/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]


Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 10/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][A[AEpoch 10/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=3.0] Epoch 10 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.699e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.930e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.133e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.153e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.440e+00
  layer model_5__forward_module.module.conv2 act-std: mean=1.107e+00
  layer model_4__forward_module.module.conv1 act-std: mean=9.977e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.319e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.560e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.172e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.013e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.773e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.176e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.651e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.289e+00
  layer model_0__forward_module.module.conv2 act-std: mean=9.054e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.213e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=4.822e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.325e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.770e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.163e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.097e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.139e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.115e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=5.877e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.262e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.364e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=7.261e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=6.910e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.509e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=3.140e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=8.859e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.940e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=5.880e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.600e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=4.074e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=4.882e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.044e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=4.783e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=8.863e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=3.973e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=7.681e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=5.366e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=6.247e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=5.667e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.172e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.980e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=6.957e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]
Epoch 10/32 - Train Loss: 38.401573 - Test Loss: 34.749507

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Training epochs:  31%|â–ˆâ–ˆâ–ˆâ–      | 10/32 [03:51<08:00, 21.85s/it]
Epoch 11/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  31%|â–ˆâ–ˆâ–ˆâ–      | 10/32 [03:51<08:01, 21.87s/it]
Epoch 11/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 11/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 11/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 11/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 11/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 11/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 11/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 11/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 11/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A

Epoch 11/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][AEpoch 11/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.52s/it][A
Epoch 11/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 11/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.52s/it][A
Epoch 11/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 11/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A

Epoch 11/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][AEpoch 11/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 11/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 11/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 11/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 11/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 11/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 11/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 11/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 11/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A

Epoch 11/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 11/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]
Epoch 11/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 11/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=3.0] Epoch 11 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.661e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.970e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.137e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.161e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.444e+00
  layer model_5__forward_module.module.conv2 act-std: mean=1.110e+00
  layer model_4__forward_module.module.conv1 act-std: mean=9.998e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.392e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.599e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.195e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.019e+00

  layer model_2__forward_module.module.conv2 act-std: mean=4.780e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.188e+00Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  layer model_1__forward_module.module.conv2 act-std: mean=1.682e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.294e+00
  layer model_0__forward_module.module.conv2 act-std: mean=9.129e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.140e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=4.551e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.135e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.175e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.182e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.064e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.020e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.711e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=4.772e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.033e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.158e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=6.014e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=4.624e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=9.942e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.577e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=6.112e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=3.403e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=6.887e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.842e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=4.685e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.629e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=5.032e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.926e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=5.103e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=4.643e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=9.243e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=6.055e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=7.099e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.977e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=7.874e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.226e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.550e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.76it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.75it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.76it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Epoch 11/32 - Train Loss: 38.383962 - Test Loss: 34.735328

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.85it/s]
Training epochs:  34%|â–ˆâ–ˆâ–ˆâ–      | 11/32 [04:13<07:37, 21.79s/it]
Epoch 12/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  34%|â–ˆâ–ˆâ–ˆâ–      | 11/32 [04:13<07:37, 21.80s/it]
Epoch 12/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 12/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 12/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A

Epoch 12/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][AEpoch 12/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 12/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 12/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 12/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 12/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 12/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 12/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 12/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 12/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 12/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 12/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A

Epoch 12/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][AEpoch 12/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 12/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 12/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A

Epoch 12/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][AEpoch 12/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 12/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it]
[AEpoch 12/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 12/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 12/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 12/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][A
Epoch 12/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]
Epoch 12/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 12/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=3.0] Epoch 12 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.653e-01
  layer model_7__forward_module.module.conv2 act-std: mean=7.992e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.139e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.163e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.451e+00
  layer model_5__forward_module.module.conv2 act-std: mean=1.121e+00
  layer model_4__forward_module.module.conv1 act-std: mean=9.953e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.454e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.628e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.218e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.018e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.815e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.191e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.686e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.299e+00
  layer model_0__forward_module.module.conv2 act-std: mean=9.153e-01

  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.615e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=3.147e-02Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.849e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.707e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.169e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.156e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.851e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.491e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.267e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=6.541e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.929e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=4.741e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=2.734e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=5.342e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.260e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.343e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=4.024e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=8.376e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=4.365e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=5.592e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.802e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=5.538e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=3.005e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=5.104e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=6.403e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.329e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=7.338e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=8.855e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.436e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=6.635e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.068e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.722e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.82it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.82it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.82it/s][A

Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.81it/s][AEvaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]
Epoch 12/32 - Train Loss: 38.367240 - Test Loss: 34.718751

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]
Training epochs:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 12/32 [04:35<07:15, 21.78s/it]
Epoch 13/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 12/32 [04:35<07:15, 21.78s/it]
Epoch 13/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 13/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][AEpoch 13/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 13/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 13/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A

Epoch 13/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][AEpoch 13/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A

Epoch 13/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][AEpoch 13/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A

Epoch 13/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][AEpoch 13/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A

Epoch 13/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][AEpoch 13/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 13/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 13/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 13/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 13/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A

Epoch 13/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][AEpoch 13/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 13/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 13/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A

Epoch 13/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it]Epoch 13/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A[A
Epoch 13/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 13/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 13/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 13/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

Epoch 13/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 13/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]


[Î²=3.0] Epoch 13 summary:
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  input  std: mean=1.814e+00[A
  layer model_7__forward_module.module.conv1 act-std: mean=9.691e-01
  layer model_7__forward_module.module.conv2 act-std: mean=8.057e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.144e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.192e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.454e+00
  layer model_5__forward_module.module.conv2 act-std: mean=1.114e+00
  layer model_4__forward_module.module.conv1 act-std: mean=9.946e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.524e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.662e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.241e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.020e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.827e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.195e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.695e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.302e+00
  layer model_0__forward_module.module.conv2 act-std: mean=9.191e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.412e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=5.186e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.221e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.701e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.362e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.653e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.144e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.143e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.516e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=7.189e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.001e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=4.768e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.052e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=5.977e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.272e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.722e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=3.214e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=6.504e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.826e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=4.562e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.620e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=5.049e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.948e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=5.119e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=5.089e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.021e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=6.262e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=7.469e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.519e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=6.786e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.940e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.048e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A

Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][AEvaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.77it/s][A

Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A[A

Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][AEvaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Epoch 13/32 - Train Loss: 38.346030 - Test Loss: 34.709930
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Training epochs:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 13/32 [04:56<06:53, 21.74s/it]Training epochs:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 13/32 [04:56<06:53, 21.75s/it]
Epoch 14/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 14/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 14/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 14/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 14/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 14/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 14/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 14/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A

Epoch 14/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][AEpoch 14/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A

Epoch 14/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][AEpoch 14/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 14/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 14/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A

Epoch 14/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][AEpoch 14/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 14/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 14/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A

Epoch 14/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][AEpoch 14/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A

Epoch 14/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][AEpoch 14/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A

Epoch 14/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it]Epoch 14/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A[A
Epoch 14/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it]
[AEpoch 14/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A

Epoch 14/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it]Epoch 14/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][A[AEpoch 14/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]
Epoch 14/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=3.0] Epoch 14 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.670e-01
  layer model_7__forward_module.module.conv2 act-std: mean=8.053e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.146e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.173e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.458e+00
  layer model_5__forward_module.module.conv2 act-std: mean=1.118e+00
  layer model_4__forward_module.module.conv1 act-std: mean=9.959e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.593e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.691e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.281e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.024e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.857e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.199e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.701e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.304e+00
  layer model_0__forward_module.module.conv2 act-std: mean=9.226e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.052e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=4.355e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.141e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.472e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.296e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.484e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.216e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.015e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=2.234e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=4.221e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.858e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.817e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.062e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=5.956e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.391e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=5.225e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=3.536e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=7.311e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.975e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=4.954e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.573e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=5.073e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=3.482e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=5.383e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=4.376e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=8.288e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=5.644e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=6.314e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.161e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=6.026e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.148e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.626e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.77it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.76it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.96it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]
Epoch 14/32 - Train Loss: 38.328034 - Test Loss: 34.696601

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Training epochs:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 14/32 [05:18<06:31, 21.73s/it]
Epoch 15/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 14/32 [05:18<06:31, 21.73s/it]
Epoch 15/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 15/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 15/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A

Epoch 15/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][AEpoch 15/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 15/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 15/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 15/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 15/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A

Epoch 15/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][AEpoch 15/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A

Epoch 15/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][AEpoch 15/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 15/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 15/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 15/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 15/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 15/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 15/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A

Epoch 15/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][AEpoch 15/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 15/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 15/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A

Epoch 15/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][AEpoch 15/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A

Epoch 15/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 15/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]
Epoch 15/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][A
[Î²=3.0] Epoch 15 summary:
Epoch 15/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]  input  std: mean=1.814e+00

  layer model_7__forward_module.module.conv1 act-std: mean=9.714e-01
  layer model_7__forward_module.module.conv2 act-std: mean=8.103e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.148e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.199e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.459e+00
  layer model_5__forward_module.module.conv2 act-std: mean=1.110e+00
  layer model_4__forward_module.module.conv1 act-std: mean=9.936e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.653e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.739e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.285e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.026e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.882e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.208e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.729e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.309e+00
  layer model_0__forward_module.module.conv2 act-std: mean=9.275e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.776e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=3.608e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=1.898e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=2.669e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.256e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.481e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=1.981e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=2.728e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=2.421e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=4.703e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.845e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=3.693e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.587e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=7.599e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.378e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=5.404e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.856e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=5.694e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.671e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=4.311e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.119e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=3.627e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.803e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=4.176e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=4.086e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=7.495e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=5.197e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=5.781e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.042e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=5.754e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=2.900e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.267e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.83it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.81it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.81it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Epoch 15/32 - Train Loss: 38.298704 - Test Loss: 34.688287
Training epochs:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 15/32 [05:40<06:09, 21.74s/it]
Epoch 16/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.84it/s]
Training epochs:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 15/32 [05:40<06:09, 21.75s/it]
Epoch 16/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 16/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.57s/it][A
Epoch 16/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.55s/it][A
Epoch 16/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:17,  1.55s/it][A
Epoch 16/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 16/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:16,  1.61s/it][A
Epoch 16/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:16,  1.61s/it][A
Epoch 16/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:14,  1.58s/it][A
Epoch 16/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:14,  1.59s/it][A
Epoch 16/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.57s/it][A
Epoch 16/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.57s/it][A

Epoch 16/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.56s/it]Epoch 16/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.56s/it][A[A
Epoch 16/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.55s/it][A
Epoch 16/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.55s/it][A
Epoch 16/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.55s/it][A
Epoch 16/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.55s/it][A
Epoch 16/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 16/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:14<00:06,  1.54s/it][A
Epoch 16/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 16/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 16/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:17<00:03,  1.53s/it][A
Epoch 16/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:17<00:03,  1.53s/it][A
Epoch 16/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 16/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 16/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 16/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.52s/it]

Epoch 16/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 16/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.52s/it]

[Î²=3.0] Epoch 16 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.694e-01
  layer model_7__forward_module.module.conv2 act-std: mean=8.118e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.152e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.201e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.467e+00
  layer model_5__forward_module.module.conv2 act-std: mean=1.107e+00
  layer model_4__forward_module.module.conv1 act-std: mean=9.946e-01

  layer model_4__forward_module.module.conv2 act-std: mean=2.720e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.757e-01Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  layer model_3__forward_module.module.conv2 act-std: mean=4.323e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.030e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.881e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.212e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.725e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.311e+00
  layer model_0__forward_module.module.conv2 act-std: mean=9.288e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.136e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=4.676e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.290e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.718e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.451e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.930e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.673e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=4.306e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=4.395e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=9.336e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.141e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=5.667e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=4.914e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.041e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.697e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=6.477e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=2.952e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=5.935e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.608e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=3.948e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.532e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=4.633e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.974e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=4.813e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=7.527e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.612e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=7.865e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=9.239e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=4.318e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=8.572e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.421e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=5.293e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.76it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Epoch 16/32 - Train Loss: 38.307770 - Test Loss: 34.674143

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Training epochs:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 16/32 [06:02<05:48, 21.79s/it]
Epoch 17/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 16/32 [06:02<05:48, 21.79s/it]
Epoch 17/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 17/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][AEpoch 17/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.52s/it][A
Epoch 17/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 17/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A

Epoch 17/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][AEpoch 17/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.52s/it][A
Epoch 17/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A
Epoch 17/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.52s/it][A

Epoch 17/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][AEpoch 17/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 17/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 17/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 17/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 17/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A

Epoch 17/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][AEpoch 17/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 17/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 17/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 17/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 17/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 17/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 17/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 17/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 17/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A

Epoch 17/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 17/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]
Epoch 17/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 17/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=3.0] Epoch 17 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.729e-01
  layer model_7__forward_module.module.conv2 act-std: mean=8.142e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.157e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.202e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.467e+00

  layer model_5__forward_module.module.conv2 act-std: mean=1.102e+00
  layer model_4__forward_module.module.conv1 act-std: mean=9.935e-01
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  layer model_4__forward_module.module.conv2 act-std: mean=2.780e+00[A
  layer model_3__forward_module.module.conv1 act-std: mean=6.799e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.353e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.031e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.909e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.215e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.733e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.316e+00
  layer model_0__forward_module.module.conv2 act-std: mean=9.339e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.863e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=6.372e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.600e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=4.423e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.205e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.204e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.259e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.400e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=4.857e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.028e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.239e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=6.391e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=5.347e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.162e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.851e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=7.135e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=4.509e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=9.711e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=4.735e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=6.248e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.606e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=5.154e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.824e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=4.451e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=6.613e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.403e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=7.365e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=9.065e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.753e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=7.351e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.117e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.406e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A

Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][AEvaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A

Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][AEvaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]
Epoch 17/32 - Train Loss: 38.268762 - Test Loss: 34.664507

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Training epochs:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 17/32 [06:23<05:26, 21.77s/it]
Epoch 18/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 17/32 [06:23<05:26, 21.77s/it]
Epoch 18/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 18/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.55s/it][A
Epoch 18/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 18/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 18/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 18/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 18/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 18/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 18/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 18/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 18/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 18/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 18/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 18/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 18/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A

Epoch 18/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][AEpoch 18/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 18/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 18/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A

Epoch 18/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][AEpoch 18/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 18/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 18/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 18/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 18/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A

Epoch 18/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 18/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]
Epoch 18/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.41s/it][AEpoch 18/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=3.0] Epoch 18 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.723e-01
  layer model_7__forward_module.module.conv2 act-std: mean=8.171e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.160e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.216e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.475e+00
  layer model_5__forward_module.module.conv2 act-std: mean=1.091e+00
  layer model_4__forward_module.module.conv1 act-std: mean=9.959e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.839e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.845e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.353e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.036e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.930e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.220e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.742e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.321e+00
  layer model_0__forward_module.module.conv2 act-std: mean=9.427e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.962e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=4.200e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.398e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=4.260e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.371e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.745e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.609e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=4.100e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=5.103e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.093e-01

  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.480e-01
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  param model_2__forward_module.module.conv2.bias grad-norm: mean=6.923e-02[A
  param model_3__forward_module.module.conv1.weight grad-norm: mean=4.953e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.059e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.796e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=6.934e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=4.557e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=9.470e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=4.993e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=6.503e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.406e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=4.631e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.689e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=4.351e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=8.363e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.806e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=8.942e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.093e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.419e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=6.194e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.092e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.216e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A

Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][AEvaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Epoch 18/32 - Train Loss: 38.290340 - Test Loss: 34.659513

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Training epochs:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 18/32 [06:45<05:04, 21.75s/it]
Epoch 19/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 18/32 [06:45<05:04, 21.75s/it]
Epoch 19/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 19/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 19/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.55s/it][A
Epoch 19/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 19/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 19/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 19/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 19/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 19/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 19/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 19/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 19/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 19/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A

Epoch 19/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.59s/it][AEpoch 19/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.59s/it][A
Epoch 19/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.57s/it][A
Epoch 19/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.57s/it][A

Epoch 19/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.55s/it][AEpoch 19/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.55s/it][A

Epoch 19/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.55s/it][AEpoch 19/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.55s/it][A
Epoch 19/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:17<00:03,  1.55s/it][A
Epoch 19/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:17<00:03,  1.55s/it][A
Epoch 19/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.55s/it][A
Epoch 19/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.55s/it][A
Epoch 19/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.43s/it][AEpoch 19/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.52s/it]

[Î²=3.0] Epoch 19 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.774e-01
  layer model_7__forward_module.module.conv2 act-std: mean=8.220e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.163e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.227e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.480e+00
  layer model_5__forward_module.module.conv2 act-std: mean=1.079e+00
  layer model_4__forward_module.module.conv1 act-std: mean=9.952e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.896e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.876e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.390e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.039e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.949e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.226e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.749e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.327e+00

  layer model_0__forward_module.module.conv2 act-std: mean=9.392e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.651e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=3.336e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.146e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.584e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.720e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=3.645e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.759e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=4.290e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=5.340e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.155e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.457e-01Epoch 19/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.43s/it]
[A  param model_2__forward_module.module.conv2.bias grad-norm: mean=6.621e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=5.116e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.060e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.848e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=6.730e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=3.483e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=7.204e-02
Epoch 19/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.52s/it]  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.705e-01

  param model_4__forward_module.module.conv2.bias grad-norm: mean=4.928e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.360e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=4.471e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=3.139e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=4.660e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=5.000e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=9.761e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=6.424e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=7.393e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.378e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=6.480e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.001e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.104e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[AEvaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.77it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Epoch 19/32 - Train Loss: 38.300624 - Test Loss: 34.649746
Training epochs:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 19/32 [07:07<04:43, 21.80s/it]
Epoch 20/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Training epochs:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 19/32 [07:07<04:43, 21.80s/it]
Epoch 20/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 20/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.56s/it][AEpoch 20/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A

Epoch 20/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][AEpoch 20/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 20/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 20/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 20/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 20/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 20/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 20/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A

Epoch 20/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][AEpoch 20/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 20/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 20/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A

Epoch 20/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][AEpoch 20/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 20/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 20/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 20/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 20/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 20/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 20/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 20/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 20/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 20/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 20/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=3.0] Epoch 20 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.767e-01
  layer model_7__forward_module.module.conv2 act-std: mean=8.233e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.167e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.232e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.483e+00
  layer model_5__forward_module.module.conv2 act-std: mean=1.071e+00
  layer model_4__forward_module.module.conv1 act-std: mean=9.963e-01
  layer model_4__forward_module.module.conv2 act-std: mean=2.961e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.923e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.399e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.041e+00
  layer model_2__forward_module.module.conv2 act-std: mean=4.995e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.230e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.755e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.325e+00
  layer model_0__forward_module.module.conv2 act-std: mean=9.477e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.629e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=5.797e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.430e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.987e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.410e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.845e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.426e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.347e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=4.411e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=9.415e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.278e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=5.427e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.567e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=7.264e-02

  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.561e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=5.055e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=6.120e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.329e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=6.673e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=8.682e-02
Epoch 20/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it]  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.593e-01[A
  param model_5__forward_module.module.conv1.bias grad-norm: mean=4.973e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=2.895e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=4.471e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=6.470e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.310e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=9.130e-01Epoch 20/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.069e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=4.880e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.011e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.829e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=6.317e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.82it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.81it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]
Epoch 20/32 - Train Loss: 38.269072 - Test Loss: 34.638093

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Training epochs:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 20/32 [07:29<04:21, 21.77s/it]
Epoch 21/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 20/32 [07:29<04:21, 21.77s/it]
Epoch 21/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 21/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 21/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.55s/it][A
Epoch 21/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 21/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 21/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 21/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A

Epoch 21/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][AEpoch 21/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 21/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 21/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 21/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 21/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A

Epoch 21/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][AEpoch 21/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A

Epoch 21/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][AEpoch 21/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 21/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 21/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A

Epoch 21/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][AEpoch 21/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A

Epoch 21/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][AEpoch 21/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A

Epoch 21/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][AEpoch 21/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 21/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][A
Epoch 21/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]
Epoch 21/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][A
[Î²=3.0] Epoch 21 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.740e-01
  layer model_7__forward_module.module.conv2 act-std: mean=8.245e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.170e+00
Epoch 21/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]  layer model_6__forward_module.module.conv2 act-std: mean=3.241e-01

  layer model_5__forward_module.module.conv1 act-std: mean=1.488e+00
  layer model_5__forward_module.module.conv2 act-std: mean=1.051e+00
  layer model_4__forward_module.module.conv1 act-std: mean=9.971e-01
  layer model_4__forward_module.module.conv2 act-std: mean=3.004e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.952e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.438e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.041e+00
  layer model_2__forward_module.module.conv2 act-std: mean=5.015e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.233e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.765e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.330e+00
  layer model_0__forward_module.module.conv2 act-std: mean=9.510e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.799e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=6.020e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.572e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=4.284e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.382e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.752e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.260e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.214e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=4.180e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=8.782e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.183e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=5.618e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=5.948e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.279e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=3.184e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=8.086e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=4.898e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=1.045e-01
  param model_4__forward_module.module.conv2.weight grad-norm: mean=5.093e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=6.851e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=3.459e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=7.141e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=3.717e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=6.557e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=6.951e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.444e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=8.773e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.039e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.797e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=7.522e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.630e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=5.297e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A

Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][AEvaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.77it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.75it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Epoch 21/32 - Train Loss: 38.279693 - Test Loss: 34.626179

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Training epochs:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 21/32 [07:51<03:59, 21.76s/it]
Epoch 22/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 21/32 [07:51<03:59, 21.76s/it]
Epoch 22/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 22/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.55s/it][A
Epoch 22/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 22/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 22/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A

Epoch 22/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][AEpoch 22/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 22/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 22/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 22/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 22/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 22/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 22/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 22/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 22/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A

Epoch 22/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][AEpoch 22/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A

Epoch 22/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][AEpoch 22/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A

Epoch 22/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][AEpoch 22/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.53s/it][A
Epoch 22/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 22/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A

Epoch 22/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][AEpoch 22/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 22/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 22/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]


Epoch 22/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEvaluating:   0%|          | 0/4 [00:00<?, ?it/s][AEpoch 22/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=3.0] Epoch 22 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.775e-01
  layer model_7__forward_module.module.conv2 act-std: mean=8.275e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.172e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.241e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.491e+00
  layer model_5__forward_module.module.conv2 act-std: mean=1.044e+00
  layer model_4__forward_module.module.conv1 act-std: mean=9.987e-01
  layer model_4__forward_module.module.conv2 act-std: mean=3.054e+00
  layer model_3__forward_module.module.conv1 act-std: mean=6.996e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.443e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.048e+00
  layer model_2__forward_module.module.conv2 act-std: mean=5.021e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.240e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.767e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.336e+00
  layer model_0__forward_module.module.conv2 act-std: mean=9.545e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.417e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=5.170e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.398e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=4.091e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.323e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.485e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.368e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.593e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.526e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=7.477e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.107e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=5.149e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.300e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=6.939e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.300e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.933e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=3.346e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=6.917e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=4.034e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=5.013e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=3.806e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=7.856e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=3.955e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=6.873e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=4.191e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=8.089e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=5.595e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=6.123e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=5.475e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.104e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=4.023e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=6.875e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A

Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][AEvaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Epoch 22/32 - Train Loss: 38.229541 - Test Loss: 34.616605

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.85it/s]
Training epochs:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 22/32 [08:12<03:37, 21.76s/it]
Epoch 23/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 22/32 [08:12<03:37, 21.76s/it]
Epoch 23/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 23/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.55s/it][A
Epoch 23/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.55s/it][A

Epoch 23/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:17,  1.55s/it][AEpoch 23/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.55s/it][A

Epoch 23/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][AEpoch 23/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 23/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 23/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 23/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 23/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 23/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 23/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 23/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 23/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 23/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 23/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 23/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 23/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 23/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 23/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 23/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 23/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 23/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 23/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 23/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 23/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

Epoch 23/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 23/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=3.0] Epoch 23 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.776e-01

  layer model_7__forward_module.module.conv2 act-std: mean=8.276e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.176e+00
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  layer model_6__forward_module.module.conv2 act-std: mean=3.261e-01[A
  layer model_5__forward_module.module.conv1 act-std: mean=1.499e+00
  layer model_5__forward_module.module.conv2 act-std: mean=1.025e+00
  layer model_4__forward_module.module.conv1 act-std: mean=1.001e+00
  layer model_4__forward_module.module.conv2 act-std: mean=3.102e+00
  layer model_3__forward_module.module.conv1 act-std: mean=7.031e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.475e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.047e+00
  layer model_2__forward_module.module.conv2 act-std: mean=5.046e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.245e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.799e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.338e+00
  layer model_0__forward_module.module.conv2 act-std: mean=9.563e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=1.845e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=3.845e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.364e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.779e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.232e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.259e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.276e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.269e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=3.819e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=7.853e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.183e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=5.506e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=4.637e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=9.865e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.724e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=6.579e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=3.747e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=7.749e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=4.495e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=5.724e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=3.167e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=5.915e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=3.483e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=5.619e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=5.503e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.118e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=7.719e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=9.303e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=4.623e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=9.078e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.451e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=5.079e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A

Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][AEvaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.55it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.84it/s]
Training epochs:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 23/32 [08:34<03:16, 21.78s/it]
Epoch 24/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.76it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.73it/s]
Epoch 23/32 - Train Loss: 38.233643 - Test Loss: 34.609042
Training epochs:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 23/32 [08:34<03:16, 21.83s/it]
Epoch 24/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 24/32:   8%|â–Š         | 1/13 [00:01<00:19,  1.66s/it][A
Epoch 24/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.51s/it][A
Epoch 24/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:17,  1.58s/it][A
Epoch 24/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.52s/it][A
Epoch 24/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.57s/it][A
Epoch 24/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 24/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.55s/it][A
Epoch 24/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A

Epoch 24/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.55s/it][AEpoch 24/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 24/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.55s/it][A
Epoch 24/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A

Epoch 24/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][AEpoch 24/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.55s/it][A
Epoch 24/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.55s/it][A
Epoch 24/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 24/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.55s/it][A
Epoch 24/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 24/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 24/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.55s/it][A
Epoch 24/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:17<00:03,  1.54s/it][A
Epoch 24/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A

Epoch 24/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][AEpoch 24/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A

Epoch 24/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 24/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.52s/it]
Epoch 24/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 24/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=3.0] Epoch 24 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.789e-01
  layer model_7__forward_module.module.conv2 act-std: mean=8.302e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.181e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.255e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.502e+00
  layer model_5__forward_module.module.conv2 act-std: mean=1.014e+00
  layer model_4__forward_module.module.conv1 act-std: mean=9.992e-01
  layer model_4__forward_module.module.conv2 act-std: mean=3.171e+00
  layer model_3__forward_module.module.conv1 act-std: mean=7.066e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.512e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.052e+00
  layer model_2__forward_module.module.conv2 act-std: mean=5.088e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.251e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.794e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.341e+00
  layer model_0__forward_module.module.conv2 act-std: mean=9.653e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.286e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=4.807e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.258e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.805e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.605e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=3.387e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.300e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.182e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=2.889e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=5.816e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=1.980e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=4.041e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.242e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=6.613e-02
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.457e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=4.629e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=4.476e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=9.536e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=5.011e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=6.354e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=4.739e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=1.004e-01
  param model_5__forward_module.module.conv2.weight grad-norm: mean=4.621e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=8.460e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=5.371e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.100e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=6.611e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=7.739e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=5.323e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.097e-01

  param model_7__forward_module.module.conv2.weight grad-norm: mean=4.249e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=7.116e-02Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A

Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][AEvaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Epoch 24/32 - Train Loss: 38.215723 - Test Loss: 34.601079

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Training epochs:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 24/32 [08:56<02:54, 21.81s/it]
Epoch 25/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 24/32 [08:56<02:54, 21.82s/it]
Epoch 25/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 25/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][AEpoch 25/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 25/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 25/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 25/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 25/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A

Epoch 25/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][AEpoch 25/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A

Epoch 25/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][AEpoch 25/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 25/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 25/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 25/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 25/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 25/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 25/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 25/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 25/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 25/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 25/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A

Epoch 25/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][AEpoch 25/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 25/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 25/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 25/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 25/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

Epoch 25/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 25/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=3.0] Epoch 25 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.800e-01
  layer model_7__forward_module.module.conv2 act-std: mean=8.331e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.185e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.278e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.511e+00
  layer model_5__forward_module.module.conv2 act-std: mean=1.008e+00
  layer model_4__forward_module.module.conv1 act-std: mean=1.004e+00
  layer model_4__forward_module.module.conv2 act-std: mean=3.205e+00
  layer model_3__forward_module.module.conv1 act-std: mean=7.108e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.518e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.057e+00

  layer model_2__forward_module.module.conv2 act-std: mean=5.121e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.254e+00Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  layer model_1__forward_module.module.conv2 act-std: mean=1.812e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.343e+00
  layer model_0__forward_module.module.conv2 act-std: mean=9.659e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.181e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=4.734e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.372e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.783e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.409e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.632e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.509e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.597e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=4.817e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.052e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.487e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=6.879e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=5.297e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.134e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.977e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=7.511e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=3.859e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=8.128e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=4.120e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=5.215e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=3.860e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=7.882e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=3.926e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=6.726e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=7.710e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.637e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=8.841e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=1.083e-01
  param model_7__forward_module.module.conv1.weight grad-norm: mean=6.039e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.239e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=4.259e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=7.293e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.84it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.81it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.82it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.81it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.82it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.80it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.97it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s]
Epoch 25/32 - Train Loss: 38.215664 - Test Loss: 34.598047
Training epochs:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 25/32 [09:18<02:32, 21.78s/it]
Epoch 26/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]
Training epochs:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 25/32 [09:18<02:32, 21.78s/it]
Epoch 26/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 26/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 26/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 26/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 26/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A
Epoch 26/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 26/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 26/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 26/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 26/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 26/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.53s/it][A
Epoch 26/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 26/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A

Epoch 26/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][AEpoch 26/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A

Epoch 26/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][AEpoch 26/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 26/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 26/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 26/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 26/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A

Epoch 26/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][AEpoch 26/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 26/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 26/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A

Epoch 26/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 26/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]
Epoch 26/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 26/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.50s/it]

[Î²=3.0] Epoch 26 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.818e-01
  layer model_7__forward_module.module.conv2 act-std: mean=8.334e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.188e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.270e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.512e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.898e-01
  layer model_4__forward_module.module.conv1 act-std: mean=1.007e+00
  layer model_4__forward_module.module.conv2 act-std: mean=3.266e+00
  layer model_3__forward_module.module.conv1 act-std: mean=7.152e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.550e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.056e+00
  layer model_2__forward_module.module.conv2 act-std: mean=5.130e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.258e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.813e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.345e+00
  layer model_0__forward_module.module.conv2 act-std: mean=9.713e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.317e-01

  param model_0__forward_module.module.conv1.bias grad-norm: mean=5.103e-02
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.335e-01[A
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.729e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.414e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.813e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.300e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.256e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=4.483e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=9.636e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.185e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=5.649e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=5.569e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.207e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.928e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=7.186e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=3.469e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=6.923e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=4.075e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=4.818e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=4.324e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=8.881e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=4.286e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=7.832e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=4.807e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=9.315e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=6.283e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=7.036e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.808e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=7.342e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.458e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.920e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A

Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][AEvaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.82it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.76it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.76it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Epoch 26/32 - Train Loss: 38.204807 - Test Loss: 34.585340

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.85it/s]
Training epochs:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 26/32 [09:39<02:10, 21.76s/it]Training epochs:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 26/32 [09:39<02:10, 21.76s/it]
Epoch 27/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 27/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 27/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 27/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 27/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 27/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A

Epoch 27/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][AEpoch 27/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A

Epoch 27/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][AEpoch 27/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A

Epoch 27/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][AEpoch 27/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 27/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 27/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 27/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 27/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A

Epoch 27/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][AEpoch 27/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 27/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 27/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 27/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 27/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 27/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 27/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 27/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 27/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 27/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 27/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=3.0] Epoch 27 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.829e-01
  layer model_7__forward_module.module.conv2 act-std: mean=8.369e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.192e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.278e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.522e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.778e-01
  layer model_4__forward_module.module.conv1 act-std: mean=1.007e+00
  layer model_4__forward_module.module.conv2 act-std: mean=3.312e+00
  layer model_3__forward_module.module.conv1 act-std: mean=7.190e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.572e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.063e+00
  layer model_2__forward_module.module.conv2 act-std: mean=5.163e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.264e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.832e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.352e+00
  layer model_0__forward_module.module.conv2 act-std: mean=9.737e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=3.373e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=7.574e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.755e-01

  param model_0__forward_module.module.conv2.bias grad-norm: mean=5.016e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.286e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.524e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.389e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.402e-02
Epoch 27/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it]  param model_2__forward_module.module.conv1.weight grad-norm: mean=2.970e-01[A
  param model_2__forward_module.module.conv1.bias grad-norm: mean=6.020e-02
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.039e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=4.338e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=3.894e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=8.151e-02
Epoch 27/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.544e-01

  param model_3__forward_module.module.conv2.bias grad-norm: mean=5.508e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=3.383e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=6.837e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=3.956e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=4.813e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=3.815e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=8.013e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=3.725e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=6.831e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=5.144e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.025e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=6.917e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=8.020e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=4.113e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=8.073e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.596e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=5.226e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.77it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.79it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Epoch 27/32 - Train Loss: 38.181653 - Test Loss: 34.574887
Training epochs:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 27/32 [10:01<01:48, 21.76s/it]
Epoch 28/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Training epochs:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 27/32 [10:01<01:48, 21.76s/it]
Epoch 28/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 28/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.56s/it][AEpoch 28/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A

Epoch 28/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][AEpoch 28/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 28/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][A
Epoch 28/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A

Epoch 28/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][AEpoch 28/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.53s/it][A
Epoch 28/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 28/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 28/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.55s/it][A
Epoch 28/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 28/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 28/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 28/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.53s/it][A
Epoch 28/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 28/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 28/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 28/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.59s/it][A
Epoch 28/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.59s/it][A
Epoch 28/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:17<00:03,  1.57s/it][A
Epoch 28/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:17<00:03,  1.57s/it][A

Epoch 28/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.56s/it][AEpoch 28/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.56s/it][A

Epoch 28/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.44s/it][AEpoch 28/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.44s/it][AEpoch 28/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.52s/it]Epoch 28/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.52s/it]


[Î²=3.0] Epoch 28 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.846e-01
  layer model_7__forward_module.module.conv2 act-std: mean=8.383e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.197e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.298e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.525e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.699e-01
  layer model_4__forward_module.module.conv1 act-std: mean=1.009e+00
  layer model_4__forward_module.module.conv2 act-std: mean=3.354e+00
  layer model_3__forward_module.module.conv1 act-std: mean=7.218e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.605e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.061e+00
  layer model_2__forward_module.module.conv2 act-std: mean=5.186e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.269e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.847e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.351e+00
  layer model_0__forward_module.module.conv2 act-std: mean=9.795e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.793e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=6.321e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.560e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=4.597e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.558e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=3.132e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.665e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=4.102e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=6.366e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.361e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.713e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=8.005e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=6.970e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.486e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=3.355e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=8.713e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=4.468e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=9.587e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=4.951e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=6.194e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=3.222e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=6.545e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=3.257e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=5.734e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=6.530e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=1.324e-01
  param model_6__forward_module.module.conv2.weight grad-norm: mean=8.494e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=9.839e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.590e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=6.931e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.332e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.720e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.76it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.81it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.80it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.88it/s]
Epoch 28/32 - Train Loss: 38.169643 - Test Loss: 34.567531
Training epochs:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 28/32 [10:23<01:27, 21.81s/it]
Epoch 29/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Training epochs:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 28/32 [10:23<01:27, 21.82s/it]
Epoch 29/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 29/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.55s/it][AEpoch 29/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.57s/it][A

Epoch 29/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][AEpoch 29/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:17,  1.55s/it][A
Epoch 29/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 29/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 29/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.55s/it][A
Epoch 29/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 29/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 29/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A

Epoch 29/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][AEpoch 29/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A
Epoch 29/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A
Epoch 29/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A
Epoch 29/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 29/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 29/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A
Epoch 29/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.53s/it][A

Epoch 29/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][AEpoch 29/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A

Epoch 29/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][AEpoch 29/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.53s/it][A
Epoch 29/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A
Epoch 29/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.53s/it][A

Epoch 29/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 29/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]Epoch 29/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it]
[AEpoch 29/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=3.0] Epoch 29 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.837e-01
  layer model_7__forward_module.module.conv2 act-std: mean=8.424e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.199e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.295e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.531e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.628e-01
  layer model_4__forward_module.module.conv1 act-std: mean=1.011e+00
  layer model_4__forward_module.module.conv2 act-std: mean=3.403e+00
  layer model_3__forward_module.module.conv1 act-std: mean=7.267e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.631e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.067e+00
  layer model_2__forward_module.module.conv2 act-std: mean=5.201e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.272e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.837e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.358e+00
  layer model_0__forward_module.module.conv2 act-std: mean=9.865e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.526e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=5.644e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.496e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=4.034e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.509e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.965e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.547e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.568e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=7.283e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.609e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.848e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=8.251e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=6.868e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.493e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=3.218e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=7.957e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=3.218e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=6.370e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=4.179e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=4.823e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.900e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=5.163e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=3.094e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=4.967e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=5.010e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=9.932e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=6.340e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=7.149e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=4.194e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=8.210e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.336e-01

  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.861e-02
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.82it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.80it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.79it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.78it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Epoch 29/32 - Train Loss: 38.141124 - Test Loss: 34.556870

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]
Training epochs:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 29/32 [10:45<01:05, 21.80s/it]
Epoch 30/32:   0%|          | 0/13 [00:00<?, ?it/s][ATraining epochs:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 29/32 [10:45<01:05, 21.80s/it]
Epoch 30/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 30/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A
Epoch 30/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.53s/it][A

Epoch 30/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][AEpoch 30/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.53s/it][A

Epoch 30/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][AEpoch 30/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A

Epoch 30/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.55s/it][AEpoch 30/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.55s/it][A

Epoch 30/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.55s/it][AEpoch 30/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.55s/it][A
Epoch 30/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.55s/it][A
Epoch 30/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.55s/it][A

Epoch 30/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][AEpoch 30/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.54s/it][A

Epoch 30/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it]Epoch 30/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A[A
Epoch 30/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 30/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 30/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 30/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 30/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 30/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 30/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 30/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 30/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.43s/it][AEpoch 30/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=3.0] Epoch 30 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.855e-01
  layer model_7__forward_module.module.conv2 act-std: mean=8.409e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.203e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.313e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.539e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.536e-01
  layer model_4__forward_module.module.conv1 act-std: mean=1.016e+00

  layer model_4__forward_module.module.conv2 act-std: mean=3.449e+00
  layer model_3__forward_module.module.conv1 act-std: mean=7.317e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.631e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.068e+00
  layer model_2__forward_module.module.conv2 act-std: mean=5.217e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.276e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.854e+00
Epoch 30/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.43s/it]  layer model_0__forward_module.module.conv1 act-std: mean=1.357e+00[A
  layer model_0__forward_module.module.conv2 act-std: mean=9.844e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=3.690e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=8.467e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.876e-01
Epoch 30/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]  param model_0__forward_module.module.conv2.bias grad-norm: mean=5.243e-02

  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.572e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=3.211e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.785e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.975e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=5.422e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.175e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.527e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=6.426e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=7.137e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.545e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=3.267e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=8.384e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=3.164e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=6.410e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=4.133e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=4.869e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=3.328e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=6.696e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=3.527e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=6.120e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=4.146e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=8.021e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=6.105e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=6.824e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=3.981e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=7.764e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.616e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=5.311e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.79it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.78it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.75it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.75it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Epoch 30/32 - Train Loss: 38.144679 - Test Loss: 34.555229
Training epochs:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 30/32 [11:07<00:43, 21.80s/it]
Epoch 31/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.85it/s]
Training epochs:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 30/32 [11:07<00:43, 21.81s/it]
Epoch 31/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Epoch 31/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.57s/it][A
Epoch 31/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.55s/it][A
Epoch 31/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 31/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A

Epoch 31/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:16,  1.61s/it][AEpoch 31/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:16,  1.61s/it][A

Epoch 31/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:14,  1.58s/it]Epoch 31/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:14,  1.59s/it][A[A
Epoch 31/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.57s/it][A
Epoch 31/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.57s/it][A
Epoch 31/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.56s/it][A
Epoch 31/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.56s/it][A

Epoch 31/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.55s/it][AEpoch 31/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.55s/it][A
Epoch 31/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A
Epoch 31/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A

Epoch 31/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:14<00:06,  1.54s/it][AEpoch 31/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A
Epoch 31/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 31/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.55s/it][A
Epoch 31/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:17<00:03,  1.54s/it][A
Epoch 31/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:17<00:03,  1.54s/it][A
Epoch 31/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 31/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A

Epoch 31/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 31/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 31/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.52s/it]
Epoch 31/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.52s/it]

[Î²=3.0] Epoch 31 summary:
  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.859e-01
  layer model_7__forward_module.module.conv2 act-std: mean=8.427e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.211e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.323e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.545e+00
  layer model_5__forward_module.module.conv2 act-std: mean=9.491e-01
  layer model_4__forward_module.module.conv1 act-std: mean=1.017e+00
  layer model_4__forward_module.module.conv2 act-std: mean=3.510e+00
  layer model_3__forward_module.module.conv1 act-std: mean=7.350e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.660e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.072e+00
  layer model_2__forward_module.module.conv2 act-std: mean=5.254e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.280e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.869e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.362e+00
  layer model_0__forward_module.module.conv2 act-std: mean=9.926e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.248e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=4.818e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.408e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=4.041e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.488e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=2.812e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.712e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.911e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=5.277e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.130e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.401e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=6.377e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=5.577e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.212e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.976e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=6.844e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=3.173e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=6.529e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=4.060e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=4.504e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=2.869e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=5.259e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=3.071e-01

  param model_5__forward_module.module.conv2.bias grad-norm: mean=5.010e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=4.425e-01Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
[A  param model_6__forward_module.module.conv1.bias grad-norm: mean=8.322e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=6.347e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=6.981e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=4.051e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=7.971e-02
  param model_7__forward_module.module.conv2.weight grad-norm: mean=3.443e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=4.800e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.77it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.77it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.76it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.75it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.75it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.74it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.85it/s]
Epoch 31/32 - Train Loss: 38.130577 - Test Loss: 34.546960
Training epochs:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 31/32 [11:29<00:21, 21.84s/it]
Epoch 32/32:   0%|          | 0/13 [00:00<?, ?it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.84it/s]
Training epochs:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 31/32 [11:29<00:21, 21.85s/it]
Epoch 32/32:   0%|          | 0/13 [00:00<?, ?it/s][A

Epoch 32/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.55s/it][AEpoch 32/32:   8%|â–Š         | 1/13 [00:01<00:18,  1.54s/it][A
Epoch 32/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A
Epoch 32/32:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  1.54s/it][A

Epoch 32/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.53s/it][AEpoch 32/32:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:15,  1.54s/it][A
Epoch 32/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A
Epoch 32/32:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:06<00:13,  1.54s/it][A

Epoch 32/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][AEpoch 32/32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:12,  1.54s/it][A
Epoch 32/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.53s/it][A
Epoch 32/32:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:09<00:10,  1.54s/it][A

Epoch 32/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][AEpoch 32/32:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:09,  1.53s/it][A

Epoch 32/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it]Epoch 32/32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:12<00:07,  1.54s/it][A[A

Epoch 32/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it]Epoch 32/32:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:06,  1.54s/it][A[A
Epoch 32/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A
Epoch 32/32:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:15<00:04,  1.54s/it][A

Epoch 32/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][AEpoch 32/32:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:03,  1.54s/it][A
Epoch 32/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A
Epoch 32/32:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:18<00:01,  1.54s/it][A

Epoch 32/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it][AEpoch 32/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]

[Î²=3.0] Epoch 32 summary:Epoch 32/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.42s/it]
[A  input  std: mean=1.814e+00
  layer model_7__forward_module.module.conv1 act-std: mean=9.854e-01
  layer model_7__forward_module.module.conv2 act-std: mean=8.446e-01
  layer model_6__forward_module.module.conv1 act-std: mean=1.210e+00
  layer model_6__forward_module.module.conv2 act-std: mean=3.313e-01
  layer model_5__forward_module.module.conv1 act-std: mean=1.551e+00
Epoch 32/32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:19<00:00,  1.51s/it]  layer model_5__forward_module.module.conv2 act-std: mean=9.411e-01

  layer model_4__forward_module.module.conv1 act-std: mean=1.019e+00
  layer model_4__forward_module.module.conv2 act-std: mean=3.543e+00
  layer model_3__forward_module.module.conv1 act-std: mean=7.400e-01
  layer model_3__forward_module.module.conv2 act-std: mean=4.701e-01
  layer model_2__forward_module.module.conv1 act-std: mean=1.070e+00
  layer model_2__forward_module.module.conv2 act-std: mean=5.276e-01
  layer model_1__forward_module.module.conv1 act-std: mean=1.284e+00
  layer model_1__forward_module.module.conv2 act-std: mean=1.872e+00
  layer model_0__forward_module.module.conv1 act-std: mean=1.364e+00
  layer model_0__forward_module.module.conv2 act-std: mean=9.945e-01
  param model_0__forward_module.module.conv1.weight grad-norm: mean=2.073e-01
  param model_0__forward_module.module.conv1.bias grad-norm: mean=4.325e-02
  param model_0__forward_module.module.conv2.weight grad-norm: mean=2.222e-01
  param model_0__forward_module.module.conv2.bias grad-norm: mean=3.526e-02
  param model_1__forward_module.module.conv1.weight grad-norm: mean=1.559e-01
  param model_1__forward_module.module.conv1.bias grad-norm: mean=3.131e-02
  param model_1__forward_module.module.conv2.weight grad-norm: mean=2.494e-01
  param model_1__forward_module.module.conv2.bias grad-norm: mean=3.280e-02
  param model_2__forward_module.module.conv1.weight grad-norm: mean=5.041e-01
  param model_2__forward_module.module.conv1.bias grad-norm: mean=1.067e-01
  param model_2__forward_module.module.conv2.weight grad-norm: mean=2.461e-01
  param model_2__forward_module.module.conv2.bias grad-norm: mean=6.332e-02
  param model_3__forward_module.module.conv1.weight grad-norm: mean=5.151e-01
  param model_3__forward_module.module.conv1.bias grad-norm: mean=1.098e-01
  param model_3__forward_module.module.conv2.weight grad-norm: mean=2.916e-01
  param model_3__forward_module.module.conv2.bias grad-norm: mean=6.445e-02
  param model_4__forward_module.module.conv1.weight grad-norm: mean=3.061e-01
  param model_4__forward_module.module.conv1.bias grad-norm: mean=6.018e-02
  param model_4__forward_module.module.conv2.weight grad-norm: mean=4.167e-01
  param model_4__forward_module.module.conv2.bias grad-norm: mean=5.080e-02
  param model_5__forward_module.module.conv1.weight grad-norm: mean=3.636e-01
  param model_5__forward_module.module.conv1.bias grad-norm: mean=7.205e-02
  param model_5__forward_module.module.conv2.weight grad-norm: mean=3.621e-01
  param model_5__forward_module.module.conv2.bias grad-norm: mean=6.417e-02
  param model_6__forward_module.module.conv1.weight grad-norm: mean=4.754e-01
  param model_6__forward_module.module.conv1.bias grad-norm: mean=9.023e-02
  param model_6__forward_module.module.conv2.weight grad-norm: mean=5.888e-01
  param model_6__forward_module.module.conv2.bias grad-norm: mean=6.136e-02
  param model_7__forward_module.module.conv1.weight grad-norm: mean=5.781e-01
  param model_7__forward_module.module.conv1.bias grad-norm: mean=1.194e-01
  param model_7__forward_module.module.conv2.weight grad-norm: mean=4.316e-01
  param model_7__forward_module.module.conv2.bias grad-norm: mean=7.170e-02

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.78it/s][A
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.76it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.77it/s][A
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]
Epoch 32/32 - Train Loss: 38.176998 - Test Loss: 34.540783
Training epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [11:50<00:00, 21.82s/it]Training epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [11:50<00:00, 22.22s/it]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s][AEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.85it/s]
Training epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [11:50<00:00, 21.82s/it]Training epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [11:50<00:00, 22.22s/it]
Loaded best models from epoch 32 with loss 34.538502

>>> Completed beta = 3.0
>>> Time for this beta: 0:11:53
>>> Total elapsed time: 0:11:57
==================================================
End time: 2025-07-22 03:32:46
Total time: 0h 13m 21s
